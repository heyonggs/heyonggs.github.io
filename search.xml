<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Centos查看系统 CPU 个数、核心数、线程数</title>
    <url>/p/36110.html</url>
    <content><![CDATA[<p><escape><span id="more"></span></escape></p>
<p>CPU的核数表示CPU可以同时执行的任务数量，在支持超线程情况下，同时执行的任务数翻倍。CPU的线程数表示CPU可以同时执行的任务数量。两者的联系分两种：CPU支持超线程技术，那么线程数＝核心数＊2；不支持超线程，线程数＝核心数。</p>
<p>线程数和超线程技术是两个概念，线程数是实际存在的，而超线程是CPU的技术标准。</p>
<h3 id="优缺点">0.0.1. 优缺点</h3><h4 id="优点">0.0.1.1. 优点</h4><p>1、可以同时进行多任务处理工作，软件可以享有由超线程技术带来的性能提升；</p>
<p>2、用户同时运行两个以上软件的时候，可以充分发挥超线程技术的效率优势。</p>
<h4 id="缺点">0.0.1.2. 缺点</h4><p>1、运行单线程软件时，超线程技术会降低系统性能；</p>
<p>2、因为很多工作站软件为Windows2000操作系统进行过优化，所以使用Windows2000的工作站无法完全利用超线程技术的优势；</p>
<p>3、当两个线程同时需要某个资源时，其中一个线程必须让出资源暂时挂起，直到这些资源空闲以后才能继续。因此，超线程的性能并不等于两个CPU的性能。</p>
<h3 id="查看-CPU-物理个数">0.0.2. 查看 CPU 物理个数</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat /proc/cpuinfo | grep &quot;physical id&quot; | sort | uniq | wc -l</span><br><span class="line">或者</span><br><span class="line">grep &#x27;physical id&#x27; /proc/cpuinfo | sort -u | wc -l</span><br></pre></td></tr></table></figure>



<h3 id="查看-CPU-核心数量">0.0.3. 查看 CPU 核心数量</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat /proc/cpuinfo | grep &quot;core id&quot; | sort | uniq | wc -l</span><br><span class="line">或者</span><br><span class="line">grep &#x27;core id&#x27; /proc/cpuinfo | sort -u | wc -l</span><br></pre></td></tr></table></figure>



<h3 id="查看-CPU-线程数">0.0.4. 查看 CPU 线程数</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat /proc/cpuinfo | grep &quot;processor&quot; | sort | uniq | wc -l</span><br><span class="line">或者</span><br><span class="line">grep &#x27;processor&#x27; /proc/cpuinfo | sort -u | wc -l</span><br></pre></td></tr></table></figure>



<h3 id="查看-CPU-型号">0.0.5. 查看 CPU 型号</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat /proc/cpuinfo | grep name | sort | uniq</span><br><span class="line">或者</span><br><span class="line">dmidecode -s processor-version</span><br></pre></td></tr></table></figure>



<h3 id="查看-CPU-的详细信息：">0.0.6. 查看 CPU 的详细信息：</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat /proc/cpuinfo</span><br></pre></td></tr></table></figure>













]]></content>
      <categories>
        <category>System,cpu</category>
      </categories>
      <tags>
        <tag>System,cpu</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux常用命令汇总</title>
    <url>/p/61914.html</url>
    <content><![CDATA[<p><escape><span id="more"></span></escape></p>
<h1 id="ncdu">1. ncdu</h1><p>一个可以替代du命令的工具，ncdu命令是对传统du命令功能上的增强，不需要像du那样输入大量的命令，就可以计算文件及目录大小并可以按照大小或文件名进行排序。它是基于ncurses库开发的，因此还支持很多丰富的交互式命令。</p>
<h2 id="安装">1.1. 安装</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># CentOS</span><br><span class="line">yum -y install epel-release</span><br><span class="line">yum -y install ncdu</span><br><span class="line"></span><br><span class="line"># Ubuntu</span><br><span class="line">apt-get install ncdu</span><br></pre></td></tr></table></figure>

<h2 id="使用方法">1.2. 使用方法</h2><blockquote>
<p>执行ncdu命令，回车，即可列出当前目录下的文件及目录的大小，默认按照大小进行排序，并且使用斜杠和回车键进行目录切换十分方便。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@Linux /]# ncdu</span><br><span class="line"></span><br><span class="line">ncdu 1.16 ~ Use the arrow keys to navigate, press ? for help                                                                                                                                                      </span><br><span class="line">--- / ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">  316.3 GiB [##############################] /data                                                                                                                                                                </span><br><span class="line">   24.8 GiB [##                            ] /ssdimg</span><br><span class="line">    5.1 GiB [                              ] /samba</span><br><span class="line">    4.5 GiB [                              ] /usr</span><br><span class="line">    1.4 GiB [                              ] /var</span><br><span class="line">  149.3 MiB [                              ] /boot</span><br><span class="line">   45.7 MiB [                              ] /etc</span><br><span class="line">.  35.1 MiB [                              ] /run</span><br><span class="line">    5.4 MiB [                              ] /home</span><br><span class="line">    2.4 MiB [                              ] /root</span><br><span class="line">    1.8 MiB [                              ] /tmp</span><br><span class="line">  260.0 KiB [                              ]  .readahead</span><br><span class="line">.   0.0   B [                              ] /proc</span><br><span class="line">    0.0   B [                              ] /sys</span><br><span class="line">    0.0   B [                              ] /dev</span><br><span class="line">    0.0   B [                              ] /opt</span><br><span class="line">@   0.0   B [                              ]  lib64</span><br><span class="line">@   0.0   B [                              ]  sbin</span><br><span class="line">@   0.0   B [                              ]  lib</span><br><span class="line">@   0.0   B [                              ]  bin</span><br><span class="line">e   0.0   B [                              ] /srv</span><br><span class="line">e   0.0   B [                              ] /mnt</span><br><span class="line">e   0.0   B [                              ] /media</span><br><span class="line">    0.0   B [                              ]  .autorelabel</span><br></pre></td></tr></table></figure>

<h2 id="常用快捷键">1.3. 常用快捷键</h2><ul>
<li>up，k - 用于向上移动光标</li>
<li>down，j - 用于向下移动光标</li>
<li>右键，输入，l&gt; - 打开所选目录</li>
<li>left，&lt;，h - 这将打开父目录</li>
<li>n - 按名称排序（再次按降序排列）</li>
<li>s - 按文件大小排序（再次按降序排列）</li>
<li>d - 删除所选文件或目录</li>
<li>g - 显示百分比和/或图表</li>
<li>t - 排序时在文件之前切换dirs</li>
<li>c - 切换子项目计数的显示</li>
<li>b - 当前目录中的Spawn shell</li>
<li>i - 显示有关所选项目的信息</li>
<li>r - 刷新/重新计算当前目录</li>
<li>q - 退出ncdu</li>
</ul>
<h1 id="nmap">2. nmap</h1><p>Nmap用于在远程机器上探测网络，执行安全扫描，网络审计和搜寻开放端口。它会扫描远程在线主机，该主机的操作系统，包过滤器和开放的端口。</p>
<h2 id="安装-1">2.1. 安装</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># CentOS</span><br><span class="line">yum install -y nmap</span><br><span class="line"></span><br><span class="line"># Ubuntu</span><br><span class="line">apt-get install nmap</span><br></pre></td></tr></table></figure>

<h2 id="扫描类型">2.2. 扫描类型</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-sT    TCP connect() 扫描，这是最基本的 TCP 扫描方式。这种扫描很容易被检测到，在目标主机的日志中会记录大批的连接请求以及错误信息。</span><br><span class="line">-sS    TCP 同步扫描 (TCP SYN)，因为不必全部打开一个 TCP 连接，所以这项技术通常称为半开扫描 (half-open)。这项技术最大的好处是，很少有系统能够把这记入系统日志。不过，你需要 root 权限来定制 SYN 数据包。</span><br><span class="line">-sF,-sX,-sN    秘密 FIN 数据包扫描、圣诞树 (Xmas Tree)、空 (Null) 扫描模式。这些扫描方式的理论依据是：关闭的端口需要对你的探测包回应 RST 包，而打开的端口必需忽略有问题的包（参考 RFC 793 第 64 页）。</span><br><span class="line">-sP    ping 扫描，用 ping 方式检查网络上哪些主机正在运行。当主机阻塞 ICMP echo 请求包是 ping 扫描是无效的。nmap 在任何情况下都会进行 ping 扫描，只有目标主机处于运行状态，才会进行后续的扫描。</span><br><span class="line">-sU    UDP 的数据包进行扫描，如果你想知道在某台主机上提供哪些 UDP（用户数据报协议，RFC768) 服务，可以使用此选项。</span><br><span class="line">-sA    ACK 扫描，这项高级的扫描方法通常可以用来穿过防火墙。</span><br><span class="line">-sW    滑动窗口扫描，非常类似于 ACK 的扫描。</span><br><span class="line">-sR    RPC 扫描，和其它不同的端口扫描方法结合使用。</span><br><span class="line">-b    FTP 反弹攻击 (bounce attack)，连接到防火墙后面的一台 FTP 服务器做代理，接着进行端口扫描。</span><br></pre></td></tr></table></figure>

<h2 id="扫描参数">2.3. 扫描参数</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-P0    在扫描之前，不 ping 主机。</span><br><span class="line">-PT    扫描之前，使用 TCP ping 确定哪些主机正在运行。</span><br><span class="line">-PS    对于 root 用户，这个选项让 nmap 使用 SYN 包而不是 ACK 包来对目标主机进行扫描。</span><br><span class="line">-PI    设置这个选项，让 nmap 使用真正的 ping(ICMP echo 请求）来扫描目标主机是否正在运行。</span><br><span class="line">-PB    这是默认的 ping 扫描选项。它使用 ACK(-PT) 和 ICMP(-PI) 两种扫描类型并行扫描。如果防火墙能够过滤其中一种包，使用这种方法，你就能够穿过防火墙。</span><br><span class="line">-O    这个选项激活对 TCP/IP 指纹特征 (fingerprinting) 的扫描，获得远程主机的标志，也就是操作系统类型。</span><br><span class="line">-I    打开 nmap 的反向标志扫描功能。</span><br><span class="line">-f    使用碎片 IP 数据包发送 SYN、FIN、XMAS、NULL。包增加包过滤、入侵检测系统的难度，使其无法知道你的企图。</span><br><span class="line">-v    冗余模式。强烈推荐使用这个选项，它会给出扫描过程中的详细信息。</span><br><span class="line">-S &lt;IP&gt;    在一些情况下，nmap 可能无法确定你的源地址 (nmap 会告诉你）。在这种情况使用这个选项给出你的 IP 地址。</span><br><span class="line">-g port    设置扫描的源端口。一些天真的防火墙和包过滤器的规则集允许源端口为 DNS(53) 或者 FTP-DATA(20) 的包通过和实现连接。显然，如果攻击者把源端口修改为 20 或者 53，就可以摧毁防火墙的防护。</span><br><span class="line">-oN    把扫描结果重定向到一个可读的文件 logfilename 中。</span><br><span class="line">-oS    扫描结果输出到标准输出。</span><br><span class="line">--host_timeout    设置扫描一台主机的时间，以毫秒为单位。默认的情况下，没有超时限制。</span><br><span class="line">--max_rtt_timeout    设置对每次探测的等待时间，以毫秒为单位。如果超过这个时间限制就重传或者超时。默认值是大约 9000 毫秒。</span><br><span class="line">--min_rtt_timeout    设置 nmap 对每次探测至少等待你指定的时间，以毫秒为单位。</span><br><span class="line">-M count    置进行 TCP connect() 扫描时，最多使用多少个套接字进行并行的扫描。</span><br></pre></td></tr></table></figure>

<h2 id="example">2.4. example</h2><ul>
<li>获取远程主机系统类型和开放端口</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nmap -A IP</span><br><span class="line">或者 </span><br><span class="line">nmap -sS -P0 -sV -O IP</span><br></pre></td></tr></table></figure>

<ul>
<li>探测内网在线主机（使用IP地址）</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nmap -sP 192.168.0.0/24</span><br></pre></td></tr></table></figure>

<ul>
<li>扫描多台主机</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nmap 192.168.0.101 192.168.0.102 192.168.0.103 </span><br></pre></td></tr></table></figure>

<ul>
<li>使用IP地址的最后一个字节扫描多台服务器</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nmap 192.168.0.101,102,103 </span><br></pre></td></tr></table></figure>

<ul>
<li>扫描一个IP地址范围</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nmap 192.168.0.101-110</span><br></pre></td></tr></table></figure>

<ul>
<li><p>排除一些主机后再扫描</p>
<blockquote>
<p>在执行全网扫描或用通配符扫描时你可以使用“-<strong>exclude</strong>”选项来排除某些你不想要扫描的主机。</p>
</blockquote>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nmap 192.168.0.* --exclude 192.168.0.100</span><br></pre></td></tr></table></figure>

<ul>
<li><p>扫描操作系统信息和路由跟踪</p>
<blockquote>
<p>使用Nmap，你可以检测远程主机上运行的操作系统和版本。为了启用操作系统和版本检测，脚本扫描和路由跟踪功能，我们可以使用NMAP的“**-A**“选项。</p>
</blockquote>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nmap -A 192.168.0.101</span><br></pre></td></tr></table></figure>

<ul>
<li><p>启用Nmap的操作系统探测功能</p>
<blockquote>
<p>使用选项“**-O<strong>”和“</strong>-osscan-guess**”也帮助探测操作系统信息。</p>
</blockquote>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nmap -O www.example.com</span><br></pre></td></tr></table></figure>

<ul>
<li><p>扫描主机侦测防火墙</p>
<p>下面的命令将扫描远程主机以探测该主机是否使用了包过滤器或防火墙。</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nmap -sA 192.168.0.101</span><br></pre></td></tr></table></figure>

<ul>
<li><p>扫描主机检测是否有防火墙保护</p>
<blockquote>
<p>扫描主机检测其是否受到数据包过滤软件或防火墙的保护。</p>
</blockquote>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nmap -PN 192.168.0.101</span><br></pre></td></tr></table></figure>

<ul>
<li><p>执行快速扫描</p>
<blockquote>
<p>你可以使用“**-F**”选项执行一次快速扫描，仅扫描列在nmap-services文件中的端口而避开所有其它的端口。</p>
</blockquote>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nmap -F 192.168.0.101</span><br></pre></td></tr></table></figure>

<ul>
<li><p>顺序扫描端口</p>
<blockquote>
<p>使用“-r”选项表示不会随机的选择端口扫描。</p>
</blockquote>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nmap -r 192.168.0.101</span><br></pre></td></tr></table></figure>

<ul>
<li><p>打印主机接口和路由</p>
<blockquote>
<p>你可以使用nmap的“<strong>–iflist</strong>”选项检测主机接口和路由信息。</p>
</blockquote>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nmap --iflist</span><br></pre></td></tr></table></figure>

<ul>
<li><p>扫描特定的端口</p>
<blockquote>
<p>使用Nmap扫描远程机器的端口有各种选项，你可以使用“-<strong>P</strong>”选项指定你想要扫描的端口，默认情况下nmap只扫描<strong>TCP</strong>端口。</p>
</blockquote>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nmap -p 80 www.example.com</span><br></pre></td></tr></table></figure>

<ul>
<li><p>扫描多个端口</p>
<blockquote>
<p>你还可以使用选项“-<strong>P</strong>”来扫描多个端口。</p>
</blockquote>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nmap -p 80,443 192.168.0.101</span><br></pre></td></tr></table></figure>

<ul>
<li><p>扫描指定范围内的端口</p>
<blockquote>
<p>您可以使用表达式来扫描某个范围内的端口。</p>
</blockquote>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nmap -p 80-160 192.168.0.101</span><br></pre></td></tr></table></figure>





































]]></content>
      <categories>
        <category>Linux,命令</category>
      </categories>
      <tags>
        <tag>Linux,命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible Tower-安装配置及破解</title>
    <url>/p/31038.html</url>
    <content><![CDATA[<p><escape><span id="more"></span></escape></p>
<h1 id="Ansible-Tower-安装配置及破解">1. Ansible Tower-安装配置及破解</h1><blockquote>
<p><a href="https://www.cnblogs.com/hujinzhong/p/12172903.html">https://www.cnblogs.com/hujinzhong/p/12172903.html</a></p>
<p><a href="https://kionf.com/2018/11/21/tower-useage/">https://kionf.com/2018/11/21/tower-useage/</a></p>
</blockquote>
<h2 id="ansible-tower简介">1.1. ansible-tower简介</h2><p>1）公司中实现运维自动化的架构中主要用到ansible，ansible脚本在部署服务器指令行中显得不太直观。Ansible-Tower（之前叫做awx）是将ansible的指令界面化，简明直观，简单易用。</p>
<p>2）Ansibke-tower其实就是一个图形化的任务调度，复杂服务部署，IT自动化的一个管理平台，属于发布配置管理系统，支持Api及界面操作，Django编写。</p>
<p>3）Ansible-tower可以通过界面从github拉取最新playbook实施服务部署，提高生产效率。当然它也提供一个RESET API和命令行的CLI以供python脚本调用</p>
<p>官方网站：<a href="https://www.ansible.com/products/tower">https://www.ansible.com/products/tower</a><br>中文指南：<a href="http://www.ansible.com.cn/docs/tower.html">http://www.ansible.com.cn/docs/tower.html</a><br>官方安装文档：<a href="http://docs.ansible.com/ansible-tower/latest/html/quickinstall/index.html">http://docs.ansible.com/ansible-tower/latest/html/quickinstall/index.html</a><br>官方源地址：<a href="http://releases.ansible.com/ansible-tower/setup-bundle/">http://releases.ansible.com/ansible-tower/setup-bundle/</a></p>
<h2 id="ansible-tower安装及配置">1.2. ansible-tower安装及配置</h2><p>下载解压</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ~]# cd /opt/</span><br><span class="line">[root@mgmt2 opt]# wget https://releases.ansible.com/ansible-tower/setup-bundle/ansible-tower-setup-bundle-3.6.2-1.el7.tar.gz</span><br><span class="line">[root@mgmt2 opt]# tar xf ansible-tower-setup-bundle-3.6.2-1.el7.tar.gz</span><br><span class="line">[root@mgmt2 opt]# cd ansible-tower-setup-bundle-3.6.2-1/</span><br><span class="line">[root@mgmt2 ansible-tower-setup-bundle-3.6.2-1]# ls</span><br><span class="line">backup.yml  bundle  group_vars  install.yml  inventory  licenses  README.md  rekey.yml  restore.yml  roles  setup.sh</span><br></pre></td></tr></table></figure>

<p>修改inventory配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible-tower-setup-bundle-3.6.2-1]# vim inventory</span><br><span class="line">[tower]</span><br><span class="line">localhost ansible_connection=local</span><br><span class="line"> </span><br><span class="line">[database]</span><br><span class="line"> </span><br><span class="line">[all:vars]</span><br><span class="line">admin_password=&#x27;tower&#x27;   #tower登录密码</span><br><span class="line"> </span><br><span class="line">pg_host=&#x27;&#x27;</span><br><span class="line">pg_port=&#x27;&#x27;</span><br><span class="line"> </span><br><span class="line">pg_database=&#x27;awx&#x27;</span><br><span class="line">pg_username=&#x27;awx&#x27;</span><br><span class="line">pg_password=&#x27;tower&#x27;</span><br><span class="line">pg_sslmode=&#x27;prefer&#x27;  # set to &#x27;verify-full&#x27; for client-side enforced SSL</span><br><span class="line"> </span><br><span class="line">rabbitmq_username=tower</span><br><span class="line">rabbitmq_password=&#x27;tower&#x27;</span><br><span class="line">rabbitmq_cookie=cookiemonster</span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Isolated Tower nodes automatically generate an RSA key <span class="keyword">for</span> authentication;</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> To <span class="built_in">disable</span> this behavior, <span class="built_in">set</span> this value to <span class="literal">false</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> isolated_key_generation=<span class="literal">true</span></span></span><br><span class="line"> </span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> SSL-related variables</span></span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> If <span class="built_in">set</span>, this will install a custom CA certificate to the system trust store.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> custom_ca_cert=/path/to/ca.crt</span></span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Certificate and key to install <span class="keyword">in</span> nginx <span class="keyword">for</span> the web UI and API</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> web_server_ssl_cert=/path/to/tower.cert</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> web_server_ssl_key=/path/to/tower.key</span></span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Use SSL <span class="keyword">for</span> RabbitMQ inter-node communication.  Because RabbitMQ never</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> communicates outside the cluster, a private CA and certificates will be</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> created, and <span class="keyword">do</span> not need to be supplied.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> rabbitmq_use_ssl=False</span></span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Server-side SSL settings <span class="keyword">for</span> PostgreSQL (when we are installing it).</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> postgres_use_ssl=False</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> postgres_ssl_cert=/path/to/pgsql.crt</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> postgres_ssl_key=/path/to/pgsql.key</span></span><br></pre></td></tr></table></figure>

<p>开始安装</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible-tower-setup-bundle-3.6.2-1]# ./setup.sh</span><br></pre></td></tr></table></figure>

<p>浏览器访问</p>
<blockquote>
<p><a href="https://192.168.101.200/">https://192.168.101.200</a></p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/1.jpg" alt="ansible"></p>
<p>登陆后这里需要认证</p>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/2.jpg" alt="ansible"></p>
<h2 id="ansible-tower破解">1.3. ansible-tower破解</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ~]# cd /var/lib/awx/venv/awx/lib/python3.6/site-packages/tower_license</span><br><span class="line">[root@mgmt2 tower_license]# ll</span><br><span class="line">total 8</span><br><span class="line">-rw-r--r-- 1 root root 7764 Dec 14  2019 __init__.pyc</span><br><span class="line">drwxr-xr-x 2 root root   37 Sep  8 16:06 __pycache__</span><br></pre></td></tr></table></figure>

<p>安装pip</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 tower_license]# wget https://bootstrap.pypa.io/get-pip.py</span><br><span class="line">[root@mgmt2 tower_license]# python3 get-pip.py</span><br><span class="line">[root@mgmt2 tower_license]# pip -V</span><br><span class="line">pip 21.2.4 from /usr/local/lib/python3.6/site-packages/pip (python 3.6)</span><br><span class="line"></span><br><span class="line">[root@mgmt2 tower_license]# pip install uncompyle6</span><br></pre></td></tr></table></figure>

<p>反汇编init.pyc</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 tower_license]# uncompyle6 __init__.pyc &gt;__init__.py</span><br><span class="line">[root@mgmt2 tower_license]# ll</span><br><span class="line">total 1932</span><br><span class="line">-rw-r--r-- 1 root root 1957374 Aug  6 19:15 get-pip.py</span><br><span class="line">-rw-r--r-- 1 root root   11453 Sep  9 09:45 __init__.py</span><br><span class="line">-rw-r--r-- 1 root root    7764 Dec 14  2019 __init__.pyc</span><br><span class="line">drwxr-xr-x 2 root root      37 Sep  8 16:06 __pycache__</span><br></pre></td></tr></table></figure>

<p>修改__init__.py文件</p>
<p>[root@mgmt2 tower_license]# vim <code>__init__</code>.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_check_cloudforms_subscription</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span>    <span class="comment">#添加这一行</span></span><br><span class="line">        <span class="keyword">if</span> os.path.exists(<span class="string">&#x27;/var/lib/awx/i18n.db&#x27;</span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> os.path.isdir(<span class="string">&#x27;/opt/rh/cfme-appliance&#x27;</span>):</span><br><span class="line">                <span class="keyword">if</span> os.path.isdir(<span class="string">&#x27;/opt/rh/cfme-gemset&#x27;</span>):</span><br><span class="line">                    <span class="keyword">pass</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                has_rpms = subprocess.call([<span class="string">&#x27;rpm&#x27;</span>, <span class="string">&#x27;--quiet&#x27;</span>, <span class="string">&#x27;-q&#x27;</span>, <span class="string">&#x27;cfme&#x27;</span>, <span class="string">&#x27;cfme-appliance&#x27;</span>, <span class="string">&#x27;cfme-gemset&#x27;</span>])</span><br><span class="line">                <span class="keyword">if</span> has_rpms == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="keyword">except</span> OSError:</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line"> </span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">....</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改&quot;license_date=253370764800L&quot; 为 &quot;license_date=253370764800&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_generate_cloudforms_subscription</span>(<span class="params">self</span>):</span></span><br><span class="line">        self._attrs.update(<span class="built_in">dict</span>(company_name=<span class="string">&#x27;Red Hat CloudForms License&#x27;</span>, instance_count=MAX_INSTANCES,</span><br><span class="line">          license_date=<span class="number">253370764800</span>,  <span class="comment">#修改</span></span><br><span class="line">          license_key=<span class="string">&#x27;xxxx&#x27;</span>,</span><br><span class="line">          license_type=<span class="string">&#x27;enterprise&#x27;</span>,</span><br><span class="line">          subscription_name=<span class="string">&#x27;Red Hat CloudForms License&#x27;</span>))</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>修改完重新编译</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 tower_license]# python3 -m py_compile __init__.py</span><br><span class="line">[root@mgmt2 tower_license]# python3 -O -m py_compile __init__.py</span><br><span class="line">[root@mgmt2 tower_license]# ll</span><br><span class="line">total 1932</span><br><span class="line">-rw-r--r-- 1 root root 1957374 Aug  6 19:15 get-pip.py</span><br><span class="line">-rw-r--r-- 1 root root   11473 Sep  9 09:51 __init__.py</span><br><span class="line">-rw-r--r-- 1 root root    7764 Dec 14  2019 __init__.pyc</span><br><span class="line">drwxr-xr-x 2 root root      74 Sep  9 09:53 __pycache__</span><br></pre></td></tr></table></figure>

<p>重启服务</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 tower_license]# ansible-tower-service restart</span><br><span class="line">Restarting Tower</span><br><span class="line">Redirecting to /bin/systemctl stop postgresql.service</span><br><span class="line">Redirecting to /bin/systemctl stop rabbitmq-server.service</span><br><span class="line">Redirecting to /bin/systemctl stop nginx.service</span><br><span class="line">Redirecting to /bin/systemctl stop supervisord.service</span><br><span class="line">Redirecting to /bin/systemctl start postgresql.service</span><br><span class="line">Redirecting to /bin/systemctl start rabbitmq-server.service</span><br><span class="line">Redirecting to /bin/systemctl start nginx.service</span><br><span class="line">Redirecting to /bin/systemctl start supervisord.service</span><br></pre></td></tr></table></figure>

<p>再次访问</p>
<blockquote>
<p><a href="https://192.168.101.200/">https://192.168.101.200</a></p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/3.jpg" alt="ansible"></p>
<p><strong>另一种破解方法（未测试）</strong></p>
<blockquote>
<p> license 官方免费申请 <a href="https://www.ansible.com/license">https://www.ansible.com/license</a></p>
</blockquote>
<p>企业版无限node破解</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">先申请企业版使用30天license ,激活，再执行如下：</span><br><span class="line"> </span><br><span class="line">echo codyguo &gt; /var/lib/awx/i18n.db</span><br><span class="line">ansible-tower-service restart</span><br></pre></td></tr></table></figure>



<h2 id="面板介绍">1.4. 面板介绍</h2><table>
<thead>
<tr>
<th># viewes</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>Dashboard</td>
<td>仪表盘展示信息的</td>
</tr>
<tr>
<td>Jobs</td>
<td>跑过的任务记录</td>
</tr>
<tr>
<td>Schedules</td>
<td>计划任务</td>
</tr>
<tr>
<td>My View</td>
<td>查看用户的工作模版，和任务记录</td>
</tr>
<tr>
<td><strong># resources</strong></td>
<td></td>
</tr>
<tr>
<td>Templates</td>
<td>任务模版，配置调用playbook执行时的各种参数，  从此处添加计划任务</td>
</tr>
<tr>
<td>Credentials</td>
<td>配置连接 机器/云主机api Key/自定义的凭证类型  的账号密码等信息</td>
</tr>
<tr>
<td>Projects</td>
<td>这里配置项目对应的playbook，可以从Git上拉取  或从本地文件夹读取playbook</td>
</tr>
<tr>
<td>Inventories</td>
<td>资产清单</td>
</tr>
<tr>
<td>Inventory Scripts</td>
<td>自定义获取资产清单的脚本</td>
</tr>
<tr>
<td><strong># access</strong></td>
<td></td>
</tr>
<tr>
<td>Organizations</td>
<td>组织管理</td>
</tr>
<tr>
<td>Users</td>
<td>用户管理</td>
</tr>
<tr>
<td>Teams</td>
<td>用户组管理</td>
</tr>
<tr>
<td><strong># Administration</strong></td>
<td></td>
</tr>
<tr>
<td>Credential Types</td>
<td>自定义凭证类型，添加后可在Credentials中使用</td>
</tr>
<tr>
<td>Notifications</td>
<td>配置任务通知，支持电子邮件，Twillio电话等</td>
</tr>
<tr>
<td>Management Jobs</td>
<td>计划任务管理</td>
</tr>
<tr>
<td>Instance Groups</td>
<td>资产组管理</td>
</tr>
<tr>
<td>Applications</td>
<td>自定义应用</td>
</tr>
<tr>
<td>Settings</td>
<td>设置</td>
</tr>
</tbody></table>
<h2 id="运行测试项目">1.5. 运行测试项目</h2><p>playbook将在github上创建，Ansible Tower拉取执行，Ansible Tower的playbook默认存在 /var/lib/awx/projects/</p>
<p>创建host登录凭据</p>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/4.jpg" alt="ansible"></p>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/5.jpg" alt="ansible"></p>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/6.jpg" alt="ansible"></p>
<p>使用gitlab添加playbook项目</p>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/7.jpg" alt="ansible"></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">a</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Check</span> <span class="string">the</span> <span class="string">date</span> <span class="string">on</span> <span class="string">the</span> <span class="string">server</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">date</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Check</span> <span class="string">the</span> <span class="string">ip</span> <span class="string">on</span> <span class="string">the</span> <span class="string">server</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">ifconfig</span></span><br></pre></td></tr></table></figure>

<p>在Ansible Tower添加拉取gitlab项目的凭据</p>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/8.jpg" alt="ansible"></p>
<p>创建Projects</p>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/9.jpg" alt="ansible"></p>
<p>保存后Ansilble Tower会自动运行一次Update，如果要手动运行，点击列表中的刷新按钮。当gitlab上yml文件被更新或者新增后需要点击一下刷新按钮，否则JOB执行得还是原来的yml</p>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/10.jpg" alt="ansible"></p>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/11.jpg" alt="ansible"></p>
<p>此时在Ansible Tower服务器的/var/lib/awx/projects/目录下已经有git拉下来的完整文件结构</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 tower_license]# cd /var/lib/awx/projects/</span><br><span class="line">[root@mgmt2 projects]# ll</span><br><span class="line">total 0</span><br><span class="line">drwxr-xr-x 3 awx awx 34 Sep  9 11:06 _8__pull_gitlab</span><br><span class="line">-rwxr-xr-x 1 awx awx  0 Sep  9 11:06 _8__pull_gitlab.lock</span><br><span class="line"></span><br><span class="line">[root@mgmt2 projects]# cd _8__pull_gitlab/</span><br><span class="line">[root@mgmt2 _8__pull_gitlab]# ll</span><br><span class="line">total 4</span><br><span class="line">-rw-r--r-- 1 awx awx 170 Sep  9 11:06 test.yml</span><br><span class="line"></span><br><span class="line">[root@mgmt2 _8__pull_gitlab]# cat test.yml </span><br><span class="line">---</span><br><span class="line">- hosts: test</span><br><span class="line">  remote_user: root</span><br><span class="line">  tasks:</span><br><span class="line">    - name: Check the date on the server</span><br><span class="line">      command: date</span><br><span class="line">    - name: Check the ip on the server</span><br><span class="line">      command: ifconfig</span><br></pre></td></tr></table></figure>

<h2 id="创建主机清单">1.6. 创建主机清单</h2><p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/12.jpg" alt="ansible"></p>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/13.jpg" alt="ansible"></p>
<h2 id="创建任务模板">1.7. 创建任务模板</h2><p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/14.jpg" alt="ansible"></p>
<p>运行模板</p>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/15.jpg" alt="ansible"></p>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/16.jpg" alt="ansible"></p>
<p>点击右侧日志中change几行可以看到详细信息</p>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/17.jpg" alt="ansible"></p>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/ansible/18.jpg" alt="ansible"></p>
]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux用户登陆服务器微信告警</title>
    <url>/p/undefined.html</url>
    <content><![CDATA[<p><escape><span id="more"></span></escape></p>
<h3 id="告警脚本">0.0.1. 告警脚本</h3><p>cat /data/aimm/script/wechat.sh</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="bash"></span><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash">使用方法 sh ./send_message.sh <span class="string">&quot;发送内容&quot;</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">如       sh ./send_message.sh <span class="string">&quot;测试环境，正在更新&quot;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash">保存要发送人员的账号,在通讯录可获取，多个人员之间使用空格分隔，以下为展示数据</span></span><br><span class="line">user=&quot;HeYong&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash">企业微信ID:企业微信管理界面-’我的企业‘页面中获取</span></span><br><span class="line">corpid=&quot;ww0ba8cfd2924c614c&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash">应用秘钥:在‘自建应用’-‘创建应用’-‘应用管理’中获取</span></span><br><span class="line">corpsecret=&quot;xK-VerRCCCByHPqhe6-_jaFtMTuxDPPVueX9iYmohVs&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash">企业应用ID:在<span class="string">&#x27;自建应用&#x27;</span>-<span class="string">&#x27;创建应用&#x27;</span>-<span class="string">&#x27;应用管理&#x27;</span>中获取</span></span><br><span class="line">agentld=1000003</span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash">------------------------以上变量需要自行修改-----------------------------------</span></span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash">保存信息内容变量</span></span><br><span class="line">msg=&#x27;请检查服务器登录用户:\n主机名: &#x27;`hostname`&#x27;\n主机IP: &#x27;`ifconfig eth0|awk -F &#x27;[ :]+&#x27; &#x27;NR==2 &#123;print $3&#125;&#x27;`&#x27;\n登录用户: &#x27;`whoami`&#x27;\n登录IP: &#x27;`who am i |awk -F &#x27;[()]&#x27; &#x27;&#123;print $2&#125;&#x27;`&#x27;\n登录时间: &#x27;`date &#x27;+%Y-%m-%d-%H:%M:%S&#x27;`&#x27;&#x27;</span><br><span class="line"> </span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash">curl -s 静默模式，就是不显示错误和进度</span></span><br><span class="line">A=`curl -s https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=$corpid\&amp;corpsecret=$corpsecret`</span><br><span class="line"><span class="meta">#</span><span class="bash">解析json格式 并获取access_token值</span></span><br><span class="line">token=`echo $A | jq -c &#x27;.access_token&#x27;`</span><br><span class="line"><span class="meta">#</span><span class="bash">去除变量值两边的双引号</span></span><br><span class="line">token=$&#123;token#*\&quot;&#125;</span><br><span class="line">token=$&#123;token%*\&quot;&#125;</span><br><span class="line"><span class="meta">#</span><span class="bash">请求地址</span></span><br><span class="line">URL=&quot;https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=$token&quot;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">for I in $user;do</span><br><span class="line"><span class="meta">	#</span><span class="bash">发送的JSON内容</span></span><br><span class="line">	JSON=&quot;&#123;\&quot;touser\&quot;: \&quot;$I\&quot;,\&quot;msgtype\&quot;: \&quot;text\&quot;,\&quot;agentid\&quot;: \&quot;$agentld\&quot;,\&quot;text\&quot;: &#123;\&quot;content\&quot;: \&quot;$msg\&quot;&#125;,\&quot;safe\&quot;:0 &#125;&quot;</span><br><span class="line"><span class="meta">	#</span><span class="bash">以POST的方式请求</span></span><br><span class="line">	curl -d &quot;$JSON&quot; &quot;$URL&quot; &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">done</span><br><span class="line"> </span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure>

<p>脚本中还涉及jq命令，这里我们安装一下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@linux ~]# yum install -y jq</span><br></pre></td></tr></table></figure>

<p>在完善脚本之后，我们需要将脚本放置在<code>/etc/profile</code>这样用户在登陆的时候就会发送(前提是服务器可以访问外网，就是可以ping通百度)</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"> </span><br><span class="line">/bin/bash  /data/aimm/script/wechat.sh</span><br></pre></td></tr></table></figure>

<p>登陆测试结果如下</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx更换SSL证书</title>
    <url>/p/63588.html</url>
    <content><![CDATA[<p><escape><span id="more"></span></escape></p>
<p>申请SSL证书需要的CSR文件</p>
<blockquote>
<p><a href="https://www.chinassl.net/ssltools/generator-csr.html">https://www.chinassl.net/ssltools/generator-csr.html</a></p>
</blockquote>
<p>填写相关信息生成两个文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">*_csr.txt</span><br><span class="line">*_key.txt</span><br></pre></td></tr></table></figure>

<p>csr文件用来申请ssl证书，key文件用于nginx中使用</p>
<p>申请证书</p>
<blockquote>
<p><a href="https://cheapsslsecurity.com/">https://cheapsslsecurity.com/</a></p>
</blockquote>
<p>申请的证书目录如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">DigiCertCA.crt</span><br><span class="line">My_CA_Bundle.crt</span><br><span class="line">star_aimmcloud_com.crt</span><br><span class="line">TrustedRoot.crt</span><br></pre></td></tr></table></figure>

<p>将domain_name.crt 和 DigCertCA.crt写入bundle.crt</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat your_domain_name.crt DigiCertCA.crt &gt;&gt; bundle.crt</span><br></pre></td></tr></table></figure>

<p>此处应为</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat star_aimmcloud_com.crt DigiCertCA.crt &gt;&gt; bundle.crt</span><br></pre></td></tr></table></figure>

<p>nginx的配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line"></span><br><span class="line">listen   443;</span><br><span class="line"></span><br><span class="line">ssl    on;</span><br><span class="line">ssl_certificate    /etc/ssl/your_domain_name.pem; (or bundle.crt)</span><br><span class="line">ssl_certificate_key    /etc/ssl/your_domain_name.key;</span><br><span class="line"></span><br><span class="line">server_name your.domain.com;</span><br><span class="line">access_log /var/log/nginx/nginx.vhost.access.log;</span><br><span class="line">error_log /var/log/nginx/nginx.vhost.error.log;</span><br><span class="line">location / &#123;</span><br><span class="line">root   /home/www/public_html/your.domain.com/public/;</span><br><span class="line">index  index.html;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux磁盘满了解决方案</title>
    <url>/p/undefined.html</url>
    <content><![CDATA[<p><escape><span id="more"></span></escape></p>
<p>查看磁盘情况</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@iz2zebp5657k0fz0pvgcgnz ~]# df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs        909M     0  909M   0% /dev</span><br><span class="line">tmpfs           919M     0  919M   0% /dev/shm</span><br><span class="line">tmpfs           919M  8.6M  911M   1% /run</span><br><span class="line">tmpfs           919M     0  919M   0% /sys/fs/cgroup</span><br><span class="line">/dev/vda1        40G  8.4G   29G  23% /</span><br><span class="line">overlay          40G  8.4G   29G  23% /var/lib/docker/overlay2/e374b04682a79626e00aca70c896b2a9b5a46ae9730c3311dd774b1bc56bdb9d/merged</span><br><span class="line">overlay          40G  8.4G   29G  23% /var/lib/docker/overlay2/c59338b367886fefb1ff03641e25ad7a3800421f39652d43e08a51b51ac95009/merged</span><br><span class="line">tmpfs           184M     0  184M   0% /run/user/0</span><br></pre></td></tr></table></figure>

<p>df: 用于显示目前在Linux系统上的文件系统的磁盘使用情况统计。</p>
<p>-h：以K，M，G为单位，提高信息的可读性。</p>
<p>Size：总内存数</p>
<p>Used：使用内存数</p>
<p>Avail：剩余内存数</p>
<p>Mounted on：挂载点</p>
<p>查看文件夹下面的磁盘使用情况</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 进入根目录</span></span><br><span class="line">[root@iz2zebp5657k0fz0pvgcgnz ~]# cd /</span><br><span class="line">[root@iz2zebp5657k0fz0pvgcgnz /]# du --max-depth=1 -h</span><br><span class="line">44K	./home</span><br><span class="line">8.6M	./run</span><br><span class="line">24M	./tmp</span><br><span class="line">16K	./opt</span><br><span class="line">......</span><br><span class="line">0	./dev</span><br><span class="line">0	./sys</span><br><span class="line">101M	./root</span><br><span class="line">4.0K	./media</span><br><span class="line">48M	./etc</span><br><span class="line">4.9G	./var</span><br><span class="line">120M	./data</span><br><span class="line">11G	.</span><br></pre></td></tr></table></figure>

<p>du：会显示指定的目录或文件所占用的磁盘空间。</p>
<p>–max-depth-1：–max-depth=&lt;目录层数&gt; 超过指定层数的目录后，予以忽略。</p>
<p>-h：以K，M，G为单位，提高信息的可读性。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s部署nacos集群</title>
    <url>/p/20278.html</url>
    <content><![CDATA[<p><escape><span id="more"></span></escape></p>
<h1 id="k8s部署nacos集群">1. k8s部署nacos集群</h1><h2 id="Nacos集群部署的安装包准备">1.1. Nacos集群部署的安装包准备</h2><p>下载nacos安装包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master data]# pwd</span><br><span class="line">/data/nacos-server-2.0.2</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 下载安装包</span></span><br><span class="line">[root@k8s-master data]# wget https://github.com/alibaba/nacos/releases/download/2.0.2/nacos-server-2.0.2.zip</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 解压</span></span><br><span class="line">[root@k8s-master data]# unzip nacos-server-2.0.2.zip</span><br><span class="line">[root@k8s-master data]# mv nacos nacos-server-2.0.2</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入配置文件目录</span></span><br><span class="line">[root@k8s-master conf]# cd nacos-server-2.0.2/nacos/conf</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 备份配置文件</span></span><br><span class="line">[root@k8s-master conf]# mv application.properties application.properties.bak</span><br></pre></td></tr></table></figure>

<p>修改配置文件</p>
<p>[root@k8s-master conf]# cat application.properties</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># spring</span></span><br><span class="line"><span class="meta">server.servlet.contextPath</span>=<span class="string">$&#123;SERVER_SERVLET_CONTEXTPATH:/nacos&#125;</span></span><br><span class="line"><span class="meta">server.contextPath</span>=<span class="string">/nacos</span></span><br><span class="line"><span class="meta">server.port</span>=<span class="string">$&#123;NACOS_SERVER_PORT:8848&#125;</span></span><br><span class="line"><span class="meta">spring.datasource.platform</span>=<span class="string">$&#123;SPRING_DATASOURCE_PLATFORM:&quot;&quot;&#125;</span></span><br><span class="line"><span class="meta">nacos.cmdb.dumpTaskInterval</span>=<span class="string">3600</span></span><br><span class="line"><span class="meta">nacos.cmdb.eventTaskInterval</span>=<span class="string">10</span></span><br><span class="line"><span class="meta">nacos.cmdb.labelTaskInterval</span>=<span class="string">300</span></span><br><span class="line"><span class="meta">nacos.cmdb.loadDataAtStart</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">db.num</span>=<span class="string">$&#123;MYSQL_DATABASE_NUM:1&#125;</span></span><br><span class="line"><span class="meta">db.url.0</span>=<span class="string">jdbc:mysql://$&#123;MYSQL_SERVICE_HOST&#125;:$&#123;MYSQL_SERVICE_PORT:3306&#125;/$&#123;MYSQL_SERVICE_DB_NAME&#125;?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true</span></span><br><span class="line"><span class="meta">db.user</span>=<span class="string">$&#123;MYSQL_SERVICE_USER&#125;</span></span><br><span class="line"><span class="meta">db.password</span>=<span class="string">$&#123;MYSQL_SERVICE_PASSWORD&#125;</span></span><br><span class="line"><span class="comment">### The auth system to use, currently only &#x27;nacos&#x27; is supported:</span></span><br><span class="line"><span class="meta">nacos.core.auth.system.type</span>=<span class="string">$&#123;NACOS_AUTH_SYSTEM_TYPE:nacos&#125;</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment">### The token expiration in seconds:</span></span><br><span class="line"><span class="meta">nacos.core.auth.default.token.expire.seconds</span>=<span class="string">$&#123;NACOS_AUTH_TOKEN_EXPIRE_SECONDS:18000&#125;</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment">### The default token:</span></span><br><span class="line"><span class="meta">nacos.core.auth.default.token.secret.key</span>=<span class="string">$&#123;NACOS_AUTH_TOKEN:SecretKey012345678901234567890123456789012345678901234567890123456789&#125;</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment">### Turn on/off caching of auth information. By turning on this switch, the update of auth information would have a 15 seconds delay.</span></span><br><span class="line"><span class="meta">nacos.core.auth.caching.enabled</span>=<span class="string">$&#123;NACOS_AUTH_CACHE_ENABLE:false&#125;</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">server.tomcat.accesslog.enabled</span>=<span class="string">$&#123;TOMCAT_ACCESSLOG_ENABLED:false&#125;</span></span><br><span class="line"><span class="meta">server.tomcat.accesslog.pattern</span>=<span class="string">%h %l %u %t &quot;%r&quot; %s %b %D</span></span><br><span class="line"><span class="comment"># default current work dir</span></span><br><span class="line"><span class="meta">server.tomcat.basedir</span>=<span class="string"></span></span><br><span class="line"><span class="comment">## spring security config</span></span><br><span class="line"><span class="comment">### turn off security</span></span><br><span class="line"><span class="meta">nacos.security.ignore.urls</span>=<span class="string">/,/error,/**/*.css,/**/*.js,/**/*.html,/**/*.map,/**/*.svg,/**/*.png,/**/*.ico,/console-fe/public/**,/v1/auth/**,/v1/console/health/**,/actuator/**,/v1/console/server/**</span></span><br><span class="line"><span class="comment"># metrics for elastic search</span></span><br><span class="line"><span class="meta">management.metrics.export.elastic.enabled</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">management.metrics.export.influx.enabled</span>=<span class="string">false</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">nacos.naming.distro.taskDispatchThreadCount</span>=<span class="string">10</span></span><br><span class="line"><span class="meta">nacos.naming.distro.taskDispatchPeriod</span>=<span class="string">200</span></span><br><span class="line"><span class="meta">nacos.naming.distro.batchSyncKeyCount</span>=<span class="string">1000</span></span><br><span class="line"><span class="meta">nacos.naming.distro.initDataRatio</span>=<span class="string">0.9</span></span><br><span class="line"><span class="meta">nacos.naming.distro.syncRetryDelay</span>=<span class="string">5000</span></span><br><span class="line"><span class="meta">nacos.naming.data.warmup</span>=<span class="string">true</span></span><br></pre></td></tr></table></figure>

<p>添加docker-startup.sh脚本</p>
<p>容器里nacos集群模式的启动脚本必须使用docker-startup.sh，不能使用startup.sh启动脚本</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master conf]# cd ../bin/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@k8s-master bin]# cat docker-startup.sh</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Copyright 1999-2018 Alibaba Group Holding Ltd.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Licensed under the Apache License, Version 2.0 (the <span class="string">&quot;License&quot;</span>);</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> you may not use this file except <span class="keyword">in</span> compliance with the License.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> You may obtain a copy of the License at</span></span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash">      http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="bash"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> distributed under the License is distributed on an <span class="string">&quot;AS IS&quot;</span> BASIS,</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> See the License <span class="keyword">for</span> the specific language governing permissions and</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> limitations under the License.</span></span><br><span class="line">set -x</span><br><span class="line">export DEFAULT_SEARCH_LOCATIONS=&quot;classpath:/,classpath:/config/,file:./,file:./config/&quot;</span><br><span class="line">export CUSTOM_SEARCH_LOCATIONS=$&#123;DEFAULT_SEARCH_LOCATIONS&#125;,file:$&#123;BASE_DIR&#125;/conf/,$&#123;BASE_DIR&#125;/init.d/</span><br><span class="line">export CUSTOM_SEARCH_NAMES=&quot;application,custom&quot;</span><br><span class="line">PLUGINS_DIR=&quot;/home/nacos/plugins/peer-finder&quot;</span><br><span class="line">function print_servers()&#123;</span><br><span class="line">   if [[ ! -d &quot;$&#123;PLUGINS_DIR&#125;&quot; ]]; then</span><br><span class="line">    echo &quot;&quot; &gt; &quot;$CLUSTER_CONF&quot;</span><br><span class="line">    for server in $&#123;NACOS_SERVERS&#125;; do</span><br><span class="line">            echo &quot;$server&quot; &gt;&gt; &quot;$CLUSTER_CONF&quot;</span><br><span class="line">    done</span><br><span class="line">   else</span><br><span class="line">    bash $PLUGINS_DIR/plugin.sh</span><br><span class="line">   sleep 30</span><br><span class="line">        fi</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#</span><span class="bash">===========================================================================================</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> JVM Configuration</span></span><br><span class="line"><span class="meta">#</span><span class="bash">===========================================================================================</span></span><br><span class="line">if [[ &quot;$&#123;MODE&#125;&quot; == &quot;standalone&quot; ]]; then</span><br><span class="line"> </span><br><span class="line">    JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -Xms512m -Xmx512m -Xmn256m&quot;</span><br><span class="line">    JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -Dnacos.standalone=true&quot;</span><br><span class="line">else</span><br><span class="line"> </span><br><span class="line">  JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms$&#123;JVM_XMS&#125; -Xmx$&#123;JVM_XMX&#125; -Xmn$&#123;JVM_XMN&#125; -XX:MetaspaceSize=$&#123;JVM_MS&#125; -XX:MaxMetaspaceSize=$&#123;JVM_MMS&#125;&quot;</span><br><span class="line">  if [[ &quot;$&#123;NACOS_DEBUG&#125;&quot; == &quot;y&quot; ]]; then</span><br><span class="line">    JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -Xdebug -Xrunjdwp:transport=dt_socket,address=9555,server=y,suspend=n&quot;</span><br><span class="line">  fi</span><br><span class="line">  JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -XX:-OmitStackTraceInFastThrow -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=$&#123;BASE_DIR&#125;/logs/java_heapdump.hprof&quot;</span><br><span class="line">  JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -XX:-UseLargePages&quot;</span><br><span class="line">  print_servers</span><br><span class="line">fi</span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash">===========================================================================================</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Setting system properties</span></span><br><span class="line"><span class="meta">#</span><span class="bash">===========================================================================================</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">set</span>  mode that Nacos Server <span class="keyword">function</span> of split</span></span><br><span class="line">if [[ &quot;$&#123;FUNCTION_MODE&#125;&quot; == &quot;config&quot; ]]; then</span><br><span class="line">    JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -Dnacos.functionMode=config&quot;</span><br><span class="line">elif [[ &quot;$&#123;FUNCTION_MODE&#125;&quot; == &quot;naming&quot; ]]; then</span><br><span class="line">    JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -Dnacos.functionMode=naming&quot;</span><br><span class="line">fi</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">set</span> nacos server ip</span></span><br><span class="line">if [[ ! -z &quot;$&#123;NACOS_SERVER_IP&#125;&quot; ]]; then</span><br><span class="line">    JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -Dnacos.server.ip=$&#123;NACOS_SERVER_IP&#125;&quot;</span><br><span class="line">fi</span><br><span class="line"> </span><br><span class="line">if [[ ! -z &quot;$&#123;USE_ONLY_SITE_INTERFACES&#125;&quot; ]]; then</span><br><span class="line">    JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -Dnacos.inetutils.use-only-site-local-interfaces=$&#123;USE_ONLY_SITE_INTERFACES&#125;&quot;</span><br><span class="line">fi</span><br><span class="line"> </span><br><span class="line">if [[ ! -z &quot;$&#123;PREFERRED_NETWORKS&#125;&quot; ]]; then</span><br><span class="line">    JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -Dnacos.inetutils.preferred-networks=$&#123;PREFERRED_NETWORKS&#125;&quot;</span><br><span class="line">fi</span><br><span class="line"> </span><br><span class="line">if [[ ! -z &quot;$&#123;IGNORED_INTERFACES&#125;&quot; ]]; then</span><br><span class="line">    JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -Dnacos.inetutils.ignored-interfaces=$&#123;IGNORED_INTERFACES&#125;&quot;</span><br><span class="line">fi</span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## If turn on auth system:</span></span></span><br><span class="line">if [[ ! -z &quot;$&#123;NACOS_AUTH_ENABLE&#125;&quot; ]]; then</span><br><span class="line">    JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -Dnacos.core.auth.enabled=$&#123;NACOS_AUTH_ENABLE&#125;&quot;</span><br><span class="line">fi</span><br><span class="line"> </span><br><span class="line">if [[ &quot;$&#123;PREFER_HOST_MODE&#125;&quot; == &quot;hostname&quot; ]]; then</span><br><span class="line">    JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -Dnacos.preferHostnameOverIp=true&quot;</span><br><span class="line">fi</span><br><span class="line"> </span><br><span class="line">JAVA_MAJOR_VERSION=$($JAVA -version 2&gt;&amp;1 | sed -E -n &#x27;s/.* version &quot;([0-9]*).*$/\1/p&#x27;)</span><br><span class="line">if [[ &quot;$JAVA_MAJOR_VERSION&quot; -ge &quot;9&quot; ]] ; then</span><br><span class="line">  JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -cp .:$&#123;BASE_DIR&#125;/plugins/cmdb/*.jar:$&#123;BASE_DIR&#125;/plugins/mysql/*.jar&quot;</span><br><span class="line">  JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -Xlog:gc*:file=$&#123;BASE_DIR&#125;/logs/nacos_gc.log:time,tags:filecount=10,filesize=102400&quot;</span><br><span class="line">else</span><br><span class="line">  JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -Djava.ext.dirs=$&#123;JAVA_HOME&#125;/jre/lib/ext:$&#123;JAVA_HOME&#125;/lib/ext:$&#123;BASE_DIR&#125;/plugins/health:$&#123;BASE_DIR&#125;/plugins/cmdb:$&#123;BASE_DIR&#125;/plugins/mysql&quot;</span><br><span class="line">  JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -Xloggc:$&#123;BASE_DIR&#125;/logs/nacos_gc.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M&quot;</span><br><span class="line">fi</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -Dnacos.home=$&#123;BASE_DIR&#125;&quot;</span><br><span class="line">JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -jar $&#123;BASE_DIR&#125;/target/nacos-server.jar&quot;</span><br><span class="line">JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; $&#123;JAVA_OPT_EXT&#125;&quot;</span><br><span class="line">JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; --spring.config.location=$&#123;CUSTOM_SEARCH_LOCATIONS&#125;&quot;</span><br><span class="line">JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; --spring.config.name=$&#123;CUSTOM_SEARCH_NAMES&#125;&quot;</span><br><span class="line">JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; --logging.config=$&#123;BASE_DIR&#125;/conf/nacos-logback.xml&quot;</span><br><span class="line">JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; --server.max-http-header-size=524288&quot;</span><br><span class="line"> </span><br><span class="line">echo &quot;nacos is starting,you can check the $&#123;BASE_DIR&#125;/logs/start.out&quot;</span><br><span class="line">echo &quot;$JAVA $&#123;JAVA_OPT&#125;&quot; &gt; $&#123;BASE_DIR&#125;/logs/start.out 2&gt;&amp;1 &amp;</span><br><span class="line">nohup $JAVA $&#123;JAVA_OPT&#125; &gt; $&#123;BASE_DIR&#125;/logs/start.out 2&gt;&amp;1 &lt; /dev/null</span><br></pre></td></tr></table></figure>

<p>打包</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master bin]# cd /data</span><br><span class="line">[root@k8s-master data]# tar -zvcf nacos-server-2.0.2.tar.gz nacos-server-2.0.2</span><br><span class="line">[root@k8s-master data]# ls</span><br><span class="line">nacos-server-2.0.2  nacos-server-2.0.2.tar.gz  nacos-server-2.0.2.zip</span><br></pre></td></tr></table></figure>

<h2 id="Nacos镜像制作">1.2. Nacos镜像制作</h2><p>编写dockerfile</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line">[root@k8s-master data]<span class="comment"># cat Dockerfile</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> heyuze/jdk1.<span class="number">8.0</span>_301:latest</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> rm -f /etc/localtime \</span></span><br><span class="line"><span class="bash">&amp;&amp; ln -sv /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \</span></span><br><span class="line"><span class="bash">&amp;&amp; <span class="built_in">echo</span> <span class="string">&quot;Asia/Shanghai&quot;</span> &gt; /etc/timezone</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">ENV</span> LANG en_US.UTF-<span class="number">8</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">ENV</span> MODE cluster</span><br><span class="line"><span class="keyword">ENV</span> PREFER_HOST_MODE ip</span><br><span class="line"><span class="keyword">ENV</span> BASE_DIR /home/nacos</span><br><span class="line"><span class="keyword">ENV</span> CLASSPATH .:/home/nacos/conf:</span><br><span class="line"><span class="keyword">ENV</span> CLUSTER_CONF /home/nacos/conf/cluster.conf</span><br><span class="line"><span class="keyword">ENV</span> FUNCTION_MODE all</span><br><span class="line"><span class="keyword">ENV</span> JAVA_HOME /usr/local/jdk/jdk1.<span class="number">8.0</span>_301</span><br><span class="line"><span class="keyword">ENV</span> NACOS_USER nacos</span><br><span class="line"><span class="keyword">ENV</span> JAVA /usr/local/jdk/jdk1.<span class="number">8.0</span>_301/bin/java</span><br><span class="line"><span class="keyword">ENV</span> JVM_XMS <span class="number">2</span>g</span><br><span class="line"><span class="keyword">ENV</span> JVM_XMX <span class="number">2</span>g</span><br><span class="line"><span class="keyword">ENV</span> JVM_XMN <span class="number">1</span>g</span><br><span class="line"><span class="keyword">ENV</span> JVM_MS <span class="number">128</span>m</span><br><span class="line"><span class="keyword">ENV</span> JVM_MMS <span class="number">320</span>m</span><br><span class="line"><span class="keyword">ENV</span> NACOS_DEBUG n</span><br><span class="line"><span class="keyword">ENV</span> TOMCAT_ACCESSLOG_ENABLED false</span><br><span class="line"> </span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /home/nacos</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> nacos-server-2.0.2.tar.gz /home</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">set</span> -x &amp;&amp; mv /home/nacos-server-2.0.2/nacos/* /home/nacos/ &amp;&amp; rm -rf /home/nacos-server-2.0.2</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir -p logs &amp;&amp; <span class="built_in">cd</span> logs &amp;&amp; touch start.out &amp;&amp; ln -sf /dev/stdout start.out &amp;&amp; ln -sf /dev/stderr start.out</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> chmod 755 bin/docker-startup.sh</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">8848</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> [<span class="string">&quot;bin/docker-startup.sh&quot;</span>]</span></span><br></pre></td></tr></table></figure>

<p>制作镜像并上传</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master data]# docker build -t heyuze/nacos-cluster:v2.0.2 .</span><br><span class="line">[root@k8s-master data]# docker push heyuze/nacos-cluster:v2.0.2</span><br></pre></td></tr></table></figure>



<h2 id="部署Nacos集群">1.3. 部署Nacos集群</h2><p>这里采用了configmap存储卷，将mysql配置信息存到了configmap中</p>
<blockquote>
<p>注意：需要提前在mysql数据库中创建一个nacos库名！然后将上面nacos-server-2.0.2.tar.gz包中的conf/nacos-mysql.sql文件里的sql语句在mysql的nacos库下执行（source nacos-mysql.sql ）导入语句。</p>
</blockquote>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">[<span class="string">root@k8s-master</span> <span class="string">nacos_cluster</span>]<span class="comment"># pwd</span></span><br><span class="line"><span class="string">/data/k8s-yaml/test_yaml/nacos_cluster</span></span><br><span class="line"></span><br><span class="line">[<span class="string">root@k8s-master</span> <span class="string">nacos_cluster</span>]<span class="comment"># cat nacos-cluster.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">wise</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nacos-cluster</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nacos-cluster</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">8848</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">server</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">8848</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nacos-cluster</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">wise</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nacos-cluster-cm</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">mysql.host:</span> <span class="string">&quot;192.168.101.221&quot;</span></span><br><span class="line">  <span class="attr">mysql.db.name:</span> <span class="string">&quot;nacos&quot;</span></span><br><span class="line">  <span class="attr">mysql.port:</span> <span class="string">&quot;3306&quot;</span></span><br><span class="line">  <span class="attr">mysql.user:</span> <span class="string">&quot;nacos&quot;</span></span><br><span class="line">  <span class="attr">mysql.password:</span> <span class="string">&quot;nacos@123&quot;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">wise</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nacos-cluster</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">nacos-cluster</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nacos-cluster</span></span><br><span class="line">      <span class="attr">annotations:</span></span><br><span class="line">        <span class="attr">pod.alpha.kubernetes.io/initialized:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">podAntiAffinity:</span></span><br><span class="line">          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">labelSelector:</span></span><br><span class="line">                <span class="attr">matchExpressions:</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;app&quot;</span></span><br><span class="line">                    <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                    <span class="attr">values:</span></span><br><span class="line">                      <span class="bullet">-</span> <span class="string">nacos-cluster</span></span><br><span class="line">              <span class="attr">topologyKey:</span> <span class="string">&quot;kubernetes.io/hostname&quot;</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">k8snacos</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">heyuze/nacos-cluster:v2.0.2</span></span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">2048Mi</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">1000m</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">2048Mi</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">1000m</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8848</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">client</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NACOS_REPLICAS</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;3&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_SERVICE_HOST</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">configMapKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">nacos-cluster-cm</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">mysql.host</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_SERVICE_DB_NAME</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">configMapKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">nacos-cluster-cm</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">mysql.db.name</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_SERVICE_PORT</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">configMapKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">nacos-cluster-cm</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">mysql.port</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_SERVICE_USER</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">configMapKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">nacos-cluster-cm</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">mysql.user</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_SERVICE_PASSWORD</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">configMapKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">nacos-cluster-cm</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">mysql.password</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NACOS_SERVER_PORT</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;8848&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PREFER_HOST_MODE</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;hostname&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NACOS_SERVERS</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;nacos-cluster-0.nacos-cluster.wise.svc.cluster.local:8848 nacos-cluster-1.nacos-cluster.wise.svc.cluster.local:8848 nacos-cluster-2.nacos-cluster.wise.svc.cluster.local:8848&quot;</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nacos-cluster</span></span><br></pre></td></tr></table></figure>

<p>创建并查看</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master nacos_cluster]# kubectl create -f nacos-cluster.yaml </span><br><span class="line">service/nacos-cluster created</span><br><span class="line">configmap/nacos-cluster-cm created</span><br><span class="line">statefulset.apps/nacos-cluster created</span><br><span class="line"></span><br><span class="line">[root@k8s-master nacos_cluster]# kubectl get pods -n wise|grep nacos-cluster</span><br><span class="line">nacos-cluster-0   1/1     Running   0          12m</span><br><span class="line">nacos-cluster-1   1/1     Running   0          11m</span><br><span class="line">nacos-cluster-2   1/1     Running   0          10m</span><br><span class="line"></span><br><span class="line">[root@k8s-master nacos_cluster]# kubectl get svc -n wise|grep nacos-cluster</span><br><span class="line">nacos-cluster   ClusterIP   None         &lt;none&gt;        8848/TCP   12m</span><br><span class="line"></span><br><span class="line">[root@k8s-master nacos_cluster]# kubectl get statefulset -n wise</span><br><span class="line">NAME            READY   AGE</span><br><span class="line">nacos-cluster   3/3     13m</span><br><span class="line"></span><br><span class="line">[root@k8s-master nacos_cluster]# kubectl get configmap -n wise|grep nacos-cluster</span><br><span class="line">nacos-cluster-cm   5      13m</span><br></pre></td></tr></table></figure>

<p>创建ingress访问</p>
<p>vim nacos-ingress.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">---apiVersion:</span> <span class="attr">extensions/v1beta1kind: Ingressmetadata:  annotations:  name: nacos-cluster  namespace: wis  annotations:    kubernetes.io/ingress.class: traefik-v2.3     spec:  rules:  - host: nacos.heyonggs.com    http:      paths:      - backend:          serviceName: nacos-cluster          servicePort:</span> <span class="number">8848</span></span><br></pre></td></tr></table></figure>

<p>应用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kubectl apply -f nacos-ingress.yaml </span><br></pre></td></tr></table></figure>

<p>先做域名解析在访问查看集群：http://域名/nacos</p>
<blockquote>
<p>账号：nacos</p>
<p>密码：nacos</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/nacos/1.jpg" alt="traefik"></p>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>SaltStack安装及使用</title>
    <url>/p/59442.html</url>
    <content><![CDATA[<p><escape><span id="more"></span></escape></p>
<blockquote>
<p>官网：<a href="https://saltproject.io/">https://saltproject.io/</a></p>
</blockquote>
<h3 id="什么是SaltStack-Master">0.0.1. 什么是SaltStack Master</h3><p><a href="https://www.saltstack.com/">SaltStack</a>或Salt是基于Python的开源软件，用于基于事件的IT自动化，远程任务执行和配置管理。SaltStack支持“基础架构即代码”方法来进行数据中心系统和网络的部署和管理，配置自动化，SecOps编排，漏洞修复以及混合云控制。（<strong>由</strong><a href="https://en.wikipedia.org/wiki/Salt_(software)"><strong>维基百科提供</strong></a>）</p>
<p><strong>SaltStack Master</strong>是服务器节点，它是控制所有Salstack Minions的中央服务器。Saltstack Master拥有SaltStack奴才的清单和公钥，并对这些奴才执行远程执行。</p>
<h3 id="SaltStack-Master上安装Python">0.0.2. SaltStack Master上安装Python</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum install -y python3</span><br></pre></td></tr></table></figure>

<h3 id="安装SaltStack官方Yum存储库">0.0.3. 安装SaltStack官方Yum存储库</h3><blockquote>
<p><a href="https://repo.saltstack.com/#rhel">https://repo.saltstack.com/#rhel</a></p>
</blockquote>
<p>安装最新版本。更新将安装最新版本，即使它是一个新的主版本。</p>
<p>运行以下命令安装SaltStack存储库和密钥</p>
<p>centos7 </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo rpm --import https://repo.saltproject.io/py3/redhat/7/x86_64/latest/SALTSTACK-GPG-KEY.pub</span><br><span class="line">curl -fsSL https://repo.saltproject.io/py3/redhat/7/x86_64/latest.repo | sudo tee /etc/yum.repos.d/salt.repo</span><br></pre></td></tr></table></figure>

<p>centos8</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo rpm --import https://repo.saltproject.io/py3/redhat/8/x86_64/latest/SALTSTACK-GPG-KEY.pub</span><br><span class="line">curl -fsSL https://repo.saltproject.io/py3/redhat/8/x86_64/latest.repo | sudo tee /etc/yum.repos.d/salt.repo</span><br></pre></td></tr></table></figure>

<p>接着运行</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum clean expire-cache</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>安装，配置 master</strong></li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum install -y salt-master salt-minion salt-ssh salt-syndic salt-cloud salt-api</span><br><span class="line">或者</span><br><span class="line">sudo yum install salt-master</span><br><span class="line">sudo yum install salt-minion</span><br><span class="line">sudo yum install salt-ssh</span><br><span class="line">sudo yum install salt-syndic</span><br><span class="line">sudo yum install salt-cloud</span><br><span class="line">sudo yum install salt-api</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>安装，配置 slave</strong></li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装salt-minion</span></span><br><span class="line">yum install -y salt-minion</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改配置文件</span></span><br><span class="line">vim /etc/salt/minion</span><br><span class="line">master: 10.211.55.4 # master的地址</span><br><span class="line">	 或</span><br><span class="line">master:</span><br><span class="line">	  - 10.211.55.4</span><br><span class="line">	  - 10.211.55.5</span><br><span class="line">random_master: True</span><br><span class="line"></span><br><span class="line">id: slave_id # 客户端在salt-master中显示的唯一ID</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动</span></span><br><span class="line">service salt-minion start</span><br></pre></td></tr></table></figure>

<p>加入开机启动</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl enable --now salt-master </span><br><span class="line">systemctl enable --now salt-minion</span><br></pre></td></tr></table></figure>

<p>查看启动状态</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl status  salt-master salt-minion</span><br></pre></td></tr></table></figure>

<p>服务端口</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">4505 用于连接slave，发布订阅</span><br><span class="line">4506 接受响应，模式为zmq（消息队列）</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>在master上授权</strong></li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">salt-key -L                # 查看已授权和未授权的slave</span><br><span class="line">salt-key -a  salve_id      # 接受指定id的salve</span><br><span class="line">salt-key -r  salve_id      # 拒绝指定id的salve</span><br><span class="line">salt-key -d  salve_id      # 删除指定id的salve</span><br></pre></td></tr></table></figure>

<h3 id="常用命令">0.0.4. 常用命令</h3><ul>
<li><strong>在master服务器上对slave进行远程操作</strong></li>
</ul>
<p>1.salt简单使用</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">salt &#x27;*&#x27; cmd.run &#x27;ifconfig&#x27; # 对所有slave操作用 &quot; * &quot;</span><br><span class="line">salt &#x27;slave_id&#x27; cmd.run &#x27;ifconfig&#x27;  # 对指定slave操作用 &quot;slave_id&quot;</span><br><span class="line"></span><br><span class="line">salt可以直接让minion执行模块命令，也可以直接执行shell命令</span><br><span class="line">1.salt -C ‘wy-pe1 and wy-pe2 or wy-peN’ test.ping        -C表示多参数(表示在测试多台主机的存活状态)</span><br><span class="line"><span class="meta">#</span><span class="bash"> salt <span class="string">&#x27;*&#x27;</span> disk.usage                            查看磁盘使用情况(使用内建模块查看所有minion端的磁盘使用情况)</span></span><br><span class="line"><span class="meta">#</span><span class="bash">salt <span class="string">&#x27;*&#x27;</span> cmd.run <span class="string">&#x27;df -h&#x27;</span>                      使用cmd.run直接调用远程shell命令(功能同上)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> salt <span class="string">&#x27;*&#x27;</span> cmd.run <span class="string">&#x27;cat /root/lall&#x27;</span>              查看客户端主机的/root/lall文件</span></span><br></pre></td></tr></table></figure>

<p>2.nodegroup对minion进行分组</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nodegroups:</span><br><span class="line">group1: ‘L@foo.domain.com,bar.domain.com,baz.domain.com or bl*.domain.com’</span><br><span class="line">group2: ‘G@os :Debian and foo.domain.com’</span><br><span class="line">group3:’wy-pe2′</span><br><span class="line">进行分组测试：</span><br><span class="line"><span class="meta">#</span><span class="bash"> salt -N group3 test.ping</span></span><br><span class="line">wy-pe2:</span><br><span class="line">True</span><br></pre></td></tr></table></figure>

<p>3.grains对minion基本信息的管理：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">salt ‘wy-pe2′ grins.ls                                                            查看grains分类</span><br><span class="line">salt ‘wy-pe2′ grins.items                                                      查看minnon基本信息(硬件参数)</span><br></pre></td></tr></table></figure>

<p>4.pillar对敏感信息的管理，只有匹配到的节点才能获取和使用</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">默认pillar数据定义文件存储路径:/srv/pillar</span><br></pre></td></tr></table></figure>

<h3 id="debug排错">0.0.5. debug排错</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@pw-aimm-srv master]# salt-minion -l debug</span><br><span class="line">[DEBUG   ] Reading configuration from /etc/salt/minion</span><br><span class="line">[DEBUG   ] Including configuration from &#x27;/etc/salt/minion.d/_schedule.conf&#x27;</span><br><span class="line">[DEBUG   ] Reading configuration from /etc/salt/minion.d/_schedule.conf</span><br><span class="line">[DEBUG   ] Using cached minion ID from /etc/salt/minion_id: pw-aimm-srv</span><br><span class="line">[DEBUG   ] Using pkg_resources to load entry points</span><br><span class="line">[DEBUG   ] Override  __grains__: &lt;module &#x27;salt.loaded.int.log_handlers.sentry_mod&#x27; from &#x27;/usr/lib/python3.6/site-packages/salt/log/handlers/sentry_mod.py&#x27;&gt;</span><br><span class="line">[DEBUG   ] Configuration file path: /etc/salt/minion</span><br><span class="line">[WARNING ] Insecure logging configuration detected! Sensitive data may be logged.</span><br><span class="line">[INFO    ] Setting up the Salt Minion &quot;pw-aimm-srv&quot;</span><br><span class="line">[INFO    ] An instance is already running. Exiting the Salt Minion</span><br><span class="line">[INFO    ] Shutting down the Salt Minion</span><br><span class="line">[DEBUG   ] Stopping the multiprocessing logging queue listener</span><br><span class="line">[DEBUG   ] closing multiprocessing queue</span><br><span class="line">[DEBUG   ] joining multiprocessing queue thread</span><br><span class="line">[DEBUG   ] Stopped the multiprocessing logging queue listener</span><br><span class="line">The Salt Minion is shutdown.</span><br></pre></td></tr></table></figure>

<h3 id="Ubuntu-安装-saltstack">0.0.6. Ubuntu 安装 saltstack</h3><ul>
<li><strong>UBUNTU 20</strong></li>
</ul>
<p>运行以下命令以导入SaltStack存储库密钥，并创建/etc/apt/sources.list.d/salt.list：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Download key</span></span><br><span class="line">sudo curl -fsSL -o /usr/share/keyrings/salt-archive-keyring.gpg https://repo.saltproject.io/py3/ubuntu/20.04/amd64/latest/salt-archive-keyring.gpg</span><br><span class="line"><span class="meta">#</span><span class="bash"> Create apt sources list file</span></span><br><span class="line">echo &quot;deb [signed-by=/usr/share/keyrings/salt-archive-keyring.gpg] https://repo.saltproject.io/py3/ubuntu/20.04/amd64/latest focal main&quot; | sudo tee /etc/apt/sources.list.d/salt.list</span><br></pre></td></tr></table></figure>

<p>接着运行</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure>

<p>1.安装配置master</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install salt-master salt-minion salt-ssh salt-syndic salt-cloud salt-api</span><br><span class="line">或者</span><br><span class="line">sudo apt-get install salt-master</span><br><span class="line">sudo apt-get install salt-minion</span><br><span class="line">sudo apt-get install salt-ssh</span><br><span class="line">sudo apt-get install salt-syndic</span><br><span class="line">sudo apt-get install salt-cloud</span><br><span class="line">sudo apt-get install salt-api</span><br></pre></td></tr></table></figure>

<p>2.安装配置slave</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装salt-minion</span></span><br><span class="line">sudo apt-get install -y salt-minion</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改配置文件</span></span><br><span class="line">vim /etc/salt/minion</span><br><span class="line">master: 10.211.55.4 # master的地址</span><br><span class="line">	 或</span><br><span class="line">master:</span><br><span class="line">	  - 10.211.55.4</span><br><span class="line">	  - 10.211.55.5</span><br><span class="line">random_master: True</span><br><span class="line"></span><br><span class="line">id: slave_id # 客户端在salt-master中显示的唯一ID</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动</span></span><br><span class="line">sudo systemctl restart salt-minion</span><br></pre></td></tr></table></figure>











]]></content>
      <categories>
        <category>SaltStack</category>
      </categories>
      <tags>
        <tag>SaltStack</tag>
      </tags>
  </entry>
  <entry>
    <title>kubeadm修改证书时间为99年</title>
    <url>/p/23286.html</url>
    <content><![CDATA[<p><escape><span id="more"></span></escape></p>
<h1 id="kubeadm修改证书时间为99年">1. kubeadm修改证书时间为99年</h1><h2 id="查看当前证书时间">1.1. 查看当前证书时间</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]# kubeadm alpha certs check-expiration</span><br><span class="line">[check-expiration] Reading configuration from the cluster...</span><br><span class="line">[check-expiration] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -oyaml&#x27;</span><br><span class="line"></span><br><span class="line">CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED</span><br><span class="line">admin.conf                 Aug 30, 2022 07:53 UTC   363d                                    no      </span><br><span class="line">apiserver                  Aug 30, 2022 07:52 UTC   363d            ca                      no      </span><br><span class="line">apiserver-etcd-client      Aug 30, 2022 07:53 UTC   363d            etcd-ca                 no      </span><br><span class="line">apiserver-kubelet-client   Aug 30, 2022 07:52 UTC   363d            ca                      no      </span><br><span class="line">controller-manager.conf    Aug 30, 2022 07:53 UTC   363d                                    no      </span><br><span class="line">etcd-healthcheck-client    Aug 30, 2022 07:53 UTC   363d            etcd-ca                 no      </span><br><span class="line">etcd-peer                  Aug 30, 2022 07:53 UTC   363d            etcd-ca                 no      </span><br><span class="line">etcd-server                Aug 30, 2022 07:53 UTC   363d            etcd-ca                 no      </span><br><span class="line">front-proxy-client         Aug 30, 2022 07:53 UTC   363d            front-proxy-ca          no      </span><br><span class="line">scheduler.conf             Aug 30, 2022 07:53 UTC   363d                                    no      </span><br><span class="line"></span><br><span class="line">CERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED</span><br><span class="line">ca                      Aug 28, 2031 07:52 UTC   9y              no      </span><br><span class="line">etcd-ca                 Aug 28, 2031 07:53 UTC   9y              no      </span><br><span class="line">front-proxy-ca          Aug 28, 2031 07:53 UTC   9y              no      </span><br></pre></td></tr></table></figure>

<p>可以看到正常只有一年时间。</p>
<h2 id="下载源码">1.2. 下载源码</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/kubernetes/kubernetes.git</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：如果github下载慢可以用gitee下载地址：<a href="https://gitee.com/mirrors/Kubernetes.git">https://gitee.com/mirrors/Kubernetes.git</a></p>
</blockquote>
<p>查看k8s版本</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]# kubectl version</span><br><span class="line">Client Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;18&quot;, GitVersion:&quot;v1.18.0&quot;, GitCommit:&quot;9e991415386e4cf155a24b1da15becaa390438d8&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2020-03-25T14:58:59Z&quot;, GoVersion:&quot;go1.13.8&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;&#125;</span><br><span class="line">Server Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;18&quot;, GitVersion:&quot;v1.18.0&quot;, GitCommit:&quot;9e991415386e4cf155a24b1da15becaa390438d8&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2020-03-25T14:50:46Z&quot;, GoVersion:&quot;go1.13.8&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;&#125;</span><br></pre></td></tr></table></figure>

<p>切换到自己的版本，修改源码，比如我的是v1.18.0版本</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd kubernetes</span><br><span class="line">git checkout v1.18.0</span><br></pre></td></tr></table></figure>

<p>vim cmd/kubeadm/app/constants/constants.go，找到CertificateValidity，修改如下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">....</span><br><span class="line">const (</span><br><span class="line">        // KubernetesDir is the directory Kubernetes owns for storing various configuration files</span><br><span class="line">        KubernetesDir = &quot;/etc/kubernetes&quot;</span><br><span class="line">        // ManifestsSubDirName defines directory name to store manifests</span><br><span class="line">        ManifestsSubDirName = &quot;manifests&quot;</span><br><span class="line">        // TempDirForKubeadm defines temporary directory for kubeadm</span><br><span class="line">        // should be joined with KubernetesDir.</span><br><span class="line">        TempDirForKubeadm = &quot;tmp&quot;</span><br><span class="line"></span><br><span class="line">        // CertificateValidity defines the validity for all the signed certificates generated by kubeadm</span><br><span class="line">        CertificateValidity = time.Hour * 24 * 365 * 100</span><br><span class="line">....</span><br></pre></td></tr></table></figure>

<h2 id="安装编译软件">1.3. 安装编译软件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install gcc automake autoconf libtool make</span><br></pre></td></tr></table></figure>

<p>安装go编译环境，这里就直接使用yum安装</p>
<p>查看go是否安装过</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master kubernetes]# go env</span><br><span class="line">-bash: go: command not found</span><br></pre></td></tr></table></figure>

<p>查看yum的Golang</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master kubernetes]# yum info golang</span><br><span class="line">Last metadata expiration check: 0:06:47 ago on Wed 01 Sep 2021 10:07:23 AM CST.</span><br><span class="line">Available Packages</span><br><span class="line">Name         : golang</span><br><span class="line">Version      : 1.15.14</span><br><span class="line">Release      : 1.module_el8.4.0+882+ab13bcd9</span><br><span class="line">Architecture : x86_64</span><br><span class="line">Size         : 708 k</span><br><span class="line">Source       : golang-1.15.14-1.module_el8.4.0+882+ab13bcd9.src.rpm</span><br><span class="line">Repository   : AppStream</span><br><span class="line">Summary      : The Go Programming Language</span><br><span class="line">URL          : http://golang.org/</span><br><span class="line">License      : BSD and Public Domain</span><br><span class="line">Description  : The Go Programming Language.</span><br></pre></td></tr></table></figure>

<p>安装golang</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y golang</span><br></pre></td></tr></table></figure>

<p>再次查看go环境变量</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master kubernetes]# go env</span><br><span class="line">GO111MODULE=&quot;&quot;</span><br><span class="line">GOARCH=&quot;amd64&quot;</span><br><span class="line">GOBIN=&quot;&quot;</span><br><span class="line">GOCACHE=&quot;/root/.cache/go-build&quot;</span><br><span class="line">GOENV=&quot;/root/.config/go/env&quot;</span><br><span class="line">GOEXE=&quot;&quot;</span><br><span class="line">GOFLAGS=&quot;&quot;</span><br><span class="line">GOHOSTARCH=&quot;amd64&quot;</span><br><span class="line">GOHOSTOS=&quot;linux&quot;</span><br><span class="line">GOINSECURE=&quot;&quot;</span><br><span class="line">GOMODCACHE=&quot;/root/go/pkg/mod&quot;</span><br><span class="line">GONOPROXY=&quot;&quot;</span><br><span class="line">GONOSUMDB=&quot;&quot;</span><br><span class="line">GOOS=&quot;linux&quot;</span><br><span class="line">GOPATH=&quot;/root/go&quot;</span><br><span class="line">GOPRIVATE=&quot;&quot;</span><br><span class="line">GOPROXY=&quot;https://proxy.golang.org,direct&quot;</span><br><span class="line">GOROOT=&quot;/usr/lib/golang&quot;</span><br><span class="line">GOSUMDB=&quot;sum.golang.org&quot;</span><br><span class="line">GOTMPDIR=&quot;&quot;</span><br><span class="line">GOTOOLDIR=&quot;/usr/lib/golang/pkg/tool/linux_amd64&quot;</span><br><span class="line">GCCGO=&quot;gccgo&quot;</span><br><span class="line">AR=&quot;ar&quot;</span><br><span class="line">CC=&quot;gcc&quot;</span><br><span class="line">CXX=&quot;g++&quot;</span><br><span class="line">CGO_ENABLED=&quot;1&quot;</span><br><span class="line">GOMOD=&quot;/root/kubernetes/go.mod&quot;</span><br><span class="line">CGO_CFLAGS=&quot;-g -O2&quot;</span><br><span class="line">CGO_CPPFLAGS=&quot;&quot;</span><br><span class="line">CGO_CXXFLAGS=&quot;-g -O2&quot;</span><br><span class="line">CGO_FFLAGS=&quot;-g -O2&quot;</span><br><span class="line">CGO_LDFLAGS=&quot;-g -O2&quot;</span><br><span class="line">PKG_CONFIG=&quot;pkg-config&quot;</span><br><span class="line">GOGCCFLAGS=&quot;-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build406782294=/tmp/go-build -gno-record-gcc-switches&quot;</span><br></pre></td></tr></table></figure>

<h2 id="执行make-WHAT-cmd-kubeadm编译">1.4. 执行make WHAT=cmd/kubeadm编译</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master kubernetes]# make WHAT=cmd/kubeadm</span><br><span class="line">+++ [0901 10:20:55] Building go targets for linux/amd64:</span><br><span class="line">    ./vendor/k8s.io/code-generator/cmd/deepcopy-gen</span><br><span class="line">+++ [0901 10:21:08] Building go targets for linux/amd64:</span><br><span class="line">    ./vendor/k8s.io/code-generator/cmd/defaulter-gen</span><br><span class="line">+++ [0901 10:21:18] Building go targets for linux/amd64:</span><br><span class="line">    ./vendor/k8s.io/code-generator/cmd/conversion-gen</span><br><span class="line">+++ [0901 10:21:37] Building go targets for linux/amd64:</span><br><span class="line">    ./vendor/k8s.io/kube-openapi/cmd/openapi-gen</span><br><span class="line">+++ [0901 10:21:53] Building go targets for linux/amd64:</span><br><span class="line">    ./vendor/github.com/go-bindata/go-bindata/go-bindata</span><br><span class="line">warning: ignoring symlink /root/kubernetes/_output/local/go/src/k8s.io/kubernetes</span><br><span class="line">go: warning: &quot;k8s.io/kubernetes/vendor/github.com/go-bindata/go-bindata/...&quot; matched no packages</span><br><span class="line">+++ [0901 10:21:55] Building go targets for linux/amd64:</span><br><span class="line">    cmd/kubeadm</span><br></pre></td></tr></table></figure>

<p>编译完生成如下目录和二进制文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master kubernetes]# ll _output/bin/</span><br><span class="line">total 70380</span><br><span class="line">-rwxr-xr-x 1 root root  6242304 Sep  1 10:21 conversion-gen</span><br><span class="line">-rwxr-xr-x 1 root root  6234112 Sep  1 10:20 deepcopy-gen</span><br><span class="line">-rwxr-xr-x 1 root root  6205440 Sep  1 10:21 defaulter-gen</span><br><span class="line">-rwxr-xr-x 1 root root  3688610 Sep  1 10:20 go2make</span><br><span class="line">-rwxr-xr-x 1 root root  2023424 Sep  1 10:21 go-bindata</span><br><span class="line">-rwxr-xr-x 1 root root 37076992 Sep  1 10:23 kubeadm</span><br><span class="line">-rwxr-xr-x 1 root root 10596352 Sep  1 10:21 openapi-gen</span><br></pre></td></tr></table></figure>

<p>备份原kubeadm和证书文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp /usr/bin/kubeadm&#123;,.bak20210901&#125;</span><br><span class="line">cp -r /etc/kubernetes/pki&#123;,.bak20210901&#125;</span><br></pre></td></tr></table></figure>

<p>将新生成的kubeadm进行替换</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp _output/bin/kubeadm /usr/bin/kubeadm</span><br></pre></td></tr></table></figure>

<p>生成新的证书</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /etc/kubernetes/pki</span><br><span class="line">kubeadm alpha certs renew all</span><br></pre></td></tr></table></figure>

<p>输出如下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master kubernetes]# cd /etc/kubernetes/pki</span><br><span class="line">[root@k8s-master pki]# kubeadm alpha certs renew all</span><br><span class="line">[renew] Reading configuration from the cluster...</span><br><span class="line">[renew] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -oyaml&#x27;</span><br><span class="line"></span><br><span class="line">certificate embedded in the kubeconfig file for the admin to use and for kubeadm itself renewed</span><br><span class="line">certificate for serving the Kubernetes API renewed</span><br><span class="line">certificate the apiserver uses to access etcd renewed</span><br><span class="line">certificate for the API server to connect to kubelet renewed</span><br><span class="line">certificate embedded in the kubeconfig file for the controller manager to use renewed</span><br><span class="line">certificate for liveness probes to healthcheck etcd renewed</span><br><span class="line">certificate for etcd nodes to communicate with each other renewed</span><br><span class="line">certificate for serving etcd renewed</span><br><span class="line">certificate for the front proxy client renewed</span><br><span class="line">certificate embedded in the kubeconfig file for the scheduler manager to use renewed</span><br></pre></td></tr></table></figure>

<p>验证结果</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubeadm alpha certs check-expiration</span><br></pre></td></tr></table></figure>

<p>输出如下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master pki]# kubeadm alpha certs check-expiration</span><br><span class="line">[check-expiration] Reading configuration from the cluster...</span><br><span class="line">[check-expiration] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -oyaml&#x27;</span><br><span class="line"></span><br><span class="line">CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED</span><br><span class="line">admin.conf                 Aug 08, 2121 02:32 UTC   99y                                     no      </span><br><span class="line">apiserver                  Aug 08, 2121 02:32 UTC   99y             ca                      no      </span><br><span class="line">apiserver-etcd-client      Aug 08, 2121 02:32 UTC   99y             etcd-ca                 no      </span><br><span class="line">apiserver-kubelet-client   Aug 08, 2121 02:32 UTC   99y             ca                      no      </span><br><span class="line">controller-manager.conf    Aug 08, 2121 02:32 UTC   99y                                     no      </span><br><span class="line">etcd-healthcheck-client    Aug 08, 2121 02:32 UTC   99y             etcd-ca                 no      </span><br><span class="line">etcd-peer                  Aug 08, 2121 02:32 UTC   99y             etcd-ca                 no      </span><br><span class="line">etcd-server                Aug 08, 2121 02:32 UTC   99y             etcd-ca                 no      </span><br><span class="line">front-proxy-client         Aug 08, 2121 02:32 UTC   99y             front-proxy-ca          no      </span><br><span class="line">scheduler.conf             Aug 08, 2121 02:32 UTC   99y                                     no      </span><br><span class="line"></span><br><span class="line">CERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED</span><br><span class="line">ca                      Aug 28, 2031 07:52 UTC   9y              no      </span><br><span class="line">etcd-ca                 Aug 28, 2031 07:53 UTC   9y              no      </span><br><span class="line">front-proxy-ca          Aug 28, 2031 07:53 UTC   9y              no      </span><br></pre></td></tr></table></figure>

<p>查看集群状态是否OK。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master pki]# kubectl get node</span><br><span class="line">NAME         STATUS   ROLES    AGE   VERSION</span><br><span class="line">k8s-master   Ready    master   42h   v1.18.0</span><br><span class="line">k8s-node1    Ready    &lt;none&gt;   42h   v1.18.0</span><br><span class="line">k8s-node2    Ready    &lt;none&gt;   42h   v1.18.0</span><br></pre></td></tr></table></figure>

<p>查看pod</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master pki]# kubectl get pod -n kube-system</span><br><span class="line">NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class="line">coredns-7ff77c879f-6pwrg             1/1     Running   1          42h</span><br><span class="line">coredns-7ff77c879f-d6s95             1/1     Running   2          42h</span><br><span class="line">etcd-k8s-master                      1/1     Running   3          42h</span><br><span class="line">kube-apiserver-k8s-master            1/1     Running   2          42h</span><br><span class="line">kube-controller-manager-k8s-master   1/1     Running   3          42h</span><br><span class="line">kube-flannel-ds-fs8dj                1/1     Running   3          42h</span><br><span class="line">kube-flannel-ds-g6d4l                1/1     Running   2          42h</span><br><span class="line">kube-flannel-ds-tnrzq                1/1     Running   1          42h</span><br><span class="line">kube-proxy-dngh8                     1/1     Running   1          42h</span><br><span class="line">kube-proxy-nxb5q                     1/1     Running   2          42h</span><br><span class="line">kube-proxy-zz5xn                     1/1     Running   3          42h</span><br><span class="line">kube-scheduler-k8s-master            1/1     Running   2          42h</span><br></pre></td></tr></table></figure>

<p>如看到上面的Ready和Running，即表示证书修改成功。</p>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s部署treafik2.x</title>
    <url>/p/9854.html</url>
    <content><![CDATA[<p><escape><span id="more"></span></escape></p>
<h1 id="k8s部署treafik2-x">1. k8s部署treafik2.x</h1><blockquote>
<p><a href="https://blog.51cto.com/u_15329153/3371086?xiangguantuijian">https://blog.51cto.com/u_15329153/3371086?xiangguantuijian</a></p>
</blockquote>
<h2 id="创建-CRD-资源">1.1. 创建 CRD 资源</h2><p>在<code>Traefik v2.0</code>版本后，开始使用<code> CRD（Custom Resource Definition）</code>来完成路由配置等，所以需要提前创建<code>CRD</code>资源。</p>
<p>cat traefik-crd.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## IngressRoute</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apiextensions.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CustomResourceDefinition</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingressroutes.traefik.containo.us</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">scope:</span> <span class="string">Namespaced</span></span><br><span class="line">  <span class="attr">group:</span> <span class="string">traefik.containo.us</span></span><br><span class="line">  <span class="attr">version:</span> <span class="string">v1alpha1</span></span><br><span class="line">  <span class="attr">names:</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">IngressRoute</span></span><br><span class="line">    <span class="attr">plural:</span> <span class="string">ingressroutes</span></span><br><span class="line">    <span class="attr">singular:</span> <span class="string">ingressroute</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment">## IngressRouteTCP</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apiextensions.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CustomResourceDefinition</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingressroutetcps.traefik.containo.us</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">scope:</span> <span class="string">Namespaced</span></span><br><span class="line">  <span class="attr">group:</span> <span class="string">traefik.containo.us</span></span><br><span class="line">  <span class="attr">version:</span> <span class="string">v1alpha1</span></span><br><span class="line">  <span class="attr">names:</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">IngressRouteTCP</span></span><br><span class="line">    <span class="attr">plural:</span> <span class="string">ingressroutetcps</span></span><br><span class="line">    <span class="attr">singular:</span> <span class="string">ingressroutetcp</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment">## Middleware</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apiextensions.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CustomResourceDefinition</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">middlewares.traefik.containo.us</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">scope:</span> <span class="string">Namespaced</span></span><br><span class="line">  <span class="attr">group:</span> <span class="string">traefik.containo.us</span></span><br><span class="line">  <span class="attr">version:</span> <span class="string">v1alpha1</span></span><br><span class="line">  <span class="attr">names:</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">Middleware</span></span><br><span class="line">    <span class="attr">plural:</span> <span class="string">middlewares</span></span><br><span class="line">    <span class="attr">singular:</span> <span class="string">middleware</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apiextensions.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CustomResourceDefinition</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tlsoptions.traefik.containo.us</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">scope:</span> <span class="string">Namespaced</span></span><br><span class="line">  <span class="attr">group:</span> <span class="string">traefik.containo.us</span></span><br><span class="line">  <span class="attr">version:</span> <span class="string">v1alpha1</span></span><br><span class="line">  <span class="attr">names:</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">TLSOption</span></span><br><span class="line">    <span class="attr">plural:</span> <span class="string">tlsoptions</span></span><br><span class="line">    <span class="attr">singular:</span> <span class="string">tlsoption</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment">## TraefikService</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apiextensions.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CustomResourceDefinition</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">traefikservices.traefik.containo.us</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">scope:</span> <span class="string">Namespaced</span></span><br><span class="line">  <span class="attr">group:</span> <span class="string">traefik.containo.us</span></span><br><span class="line">  <span class="attr">version:</span> <span class="string">v1alpha1</span></span><br><span class="line">  <span class="attr">names:</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">TraefikService</span></span><br><span class="line">    <span class="attr">plural:</span> <span class="string">traefikservices</span></span><br><span class="line">    <span class="attr">singular:</span> <span class="string">traefikservice</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment">## TraefikTLSStore</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apiextensions.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CustomResourceDefinition</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tlsstores.traefik.containo.us</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">scope:</span> <span class="string">Namespaced</span></span><br><span class="line">  <span class="attr">group:</span> <span class="string">traefik.containo.us</span></span><br><span class="line">  <span class="attr">version:</span> <span class="string">v1alpha1</span></span><br><span class="line">  <span class="attr">names:</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">TLSStore</span></span><br><span class="line">    <span class="attr">plural:</span> <span class="string">tlsstores</span></span><br><span class="line">    <span class="attr">singular:</span> <span class="string">tlsstore</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment">## IngressRouteUDP</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apiextensions.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CustomResourceDefinition</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingressrouteudps.traefik.containo.us</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">scope:</span> <span class="string">Namespaced</span></span><br><span class="line">  <span class="attr">group:</span> <span class="string">traefik.containo.us</span></span><br><span class="line">  <span class="attr">version:</span> <span class="string">v1alpha1</span></span><br><span class="line">  <span class="attr">names:</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">IngressRouteUDP</span></span><br><span class="line">    <span class="attr">plural:</span> <span class="string">ingressrouteudps</span></span><br><span class="line">    <span class="attr">singular:</span> <span class="string">ingressrouteudp</span></span><br></pre></td></tr></table></figure>

<p>创建traefik crd 资源</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kubectl apply -f traefik-crd.yaml</span><br></pre></td></tr></table></figure>

<h2 id="创建-RBAC-权限">1.2. 创建 RBAC 权限</h2><p>Kubernetes 在 1.6 版本中引入了基于角色的访问控制（RBAC）策略，方便对 Kubernetes 资源和 API 进行细粒度控制。Traefik 需要一定的权限，所以，这里提前创建好<code>Traefik ServiceAccount</code>并分配一定的权限。</p>
<p>cat traefik-rbac.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat traefik-rbac.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">traefik-ingress-controller</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">traefik-ingress-controller</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">services</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">endpoints</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">secrets</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">extensions</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">networking.k8s.io</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ingresses</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ingressclasses</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">extensions</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ingresses/status</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">update</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">traefik.containo.us</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">middlewares</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ingressroutes</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">traefikservices</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ingressroutetcps</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ingressrouteudps</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">tlsoptions</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">tlsstores</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">traefik-ingress-controller</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">traefik-ingress-controller</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">traefik-ingress-controller</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br></pre></td></tr></table></figure>

<p>创建 Traefik RBAC 资源</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kubectl apply -f traefik-rbac.yaml</span><br></pre></td></tr></table></figure>

<h2 id="创建-Traefik-配置文件">1.3. 创建 Traefik 配置文件</h2><p>由于 Traefik 配置很多，通过 CLI 定义不是很方便，一般时候都会通过配置文件配置 Traefik 参数，然后存入<code>ConfigMap</code>，将其挂入 Traefik 中。</p>
<p>下面配置中可以通过配置<code>kubernetesCRD</code>与<code>kubernetesIngress</code>和<code>kubernetesGateway</code>三项参数，让 Traefik 支持<code> CRD</code>、<code>Ingress</code>与<code>kubernetesGateway</code>三种路由配置方式。</p>
<p>cat traefik-config.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat traefik-config.yaml</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">traefik-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">traefik.yaml:</span> <span class="string">|-</span></span><br><span class="line"><span class="string">    serversTransport:</span></span><br><span class="line"><span class="string">      insecureSkipVerify: true  ## Traefik 忽略验证代理服务的 TLS 证书</span></span><br><span class="line"><span class="string">    api:</span></span><br><span class="line"><span class="string">      insecure: true            ## 允许 HTTP 方式访问 API</span></span><br><span class="line"><span class="string">      dashboard: true           ## 启用 Dashboard</span></span><br><span class="line"><span class="string">      debug: true               ## 启用 Debug 调试模式</span></span><br><span class="line"><span class="string">    metrics:</span></span><br><span class="line"><span class="string">      prometheus: metrics       ## 配置 Prometheus 监控指标数据，并使用默认配置</span></span><br><span class="line"><span class="string">    entryPoints:</span></span><br><span class="line"><span class="string">      web:</span></span><br><span class="line"><span class="string">        address: &quot;:80&quot;          ## 配置 80 端口，并设置入口名称为 web</span></span><br><span class="line"><span class="string">      websecure:</span></span><br><span class="line"><span class="string">        address: &quot;:443&quot;         ## 配置 443 端口，并设置入口名称为 websecure</span></span><br><span class="line"><span class="string">      traefik:</span></span><br><span class="line"><span class="string">        address: &quot;:8090&quot;        ## 配置 8090 端口，并设置入口名称为 dashboard</span></span><br><span class="line"><span class="string">      metrics:</span></span><br><span class="line"><span class="string">        address: &quot;:8082&quot;        ## 配置 8082 端口，作为metrics收集入口</span></span><br><span class="line"><span class="string">      tcpep:</span></span><br><span class="line"><span class="string">        address: &quot;:8000&quot;        ## 配置 8000 端口，作为tcp入口</span></span><br><span class="line"><span class="string">      udpep:</span></span><br><span class="line"><span class="string">        address: &quot;:9000/udp&quot;    ## 配置 9000 端口，作为udp入口</span></span><br><span class="line"><span class="string">    providers:</span></span><br><span class="line"><span class="string">      kubernetescrd:            ## 启用 Kubernetes CRD 方式来配置路由规则</span></span><br><span class="line"><span class="string">        ingressclass: traefik-v2.3</span></span><br><span class="line"><span class="string">      kubernetesingress:        ## 启动 Kubernetes Ingress 方式来配置路由规则</span></span><br><span class="line"><span class="string">        ingressclass: traefik-v2.3</span></span><br><span class="line"><span class="string">    log:</span></span><br><span class="line"><span class="string">      filePath: &quot;/etc/traefik/logs/traefik.log&quot;              ## 设置调试日志文件存储路径，如果为空则输出到控制台</span></span><br><span class="line"><span class="string">      level: error              ## 设置调试日志级别</span></span><br><span class="line"><span class="string">      format: json                ## 设置调试日志格式</span></span><br><span class="line"><span class="string">    accessLog:</span></span><br><span class="line"><span class="string">      filePath: &quot;/etc/traefik/logs/access.log&quot;              ## 设置访问日志文件存储路径，如果为空则输出到控制台</span></span><br><span class="line"><span class="string">      format: json                ## 设置访问调试日志格式</span></span><br><span class="line"><span class="string">      bufferingSize: 0          ## 设置访问日志缓存行数</span></span><br><span class="line"><span class="string">      filters:</span></span><br><span class="line"><span class="string">        #statusCodes: [&quot;200&quot;]   ## 设置只保留指定状态码范围内的访问日志</span></span><br><span class="line"><span class="string">        retryAttempts: true     ## 设置代理访问重试失败时，保留访问日志</span></span><br><span class="line"><span class="string">        minDuration: 20         ## 设置保留请求时间超过指定持续时间的访问日志</span></span><br><span class="line"><span class="string">      fields:                   ## 设置访问日志中的字段是否保留（keep 保留、drop 不保留）</span></span><br><span class="line"><span class="string">        defaultMode: keep       ## 设置默认保留访问日志字段</span></span><br><span class="line"><span class="string">        names:                  ## 针对访问日志特别字段特别配置保留模式</span></span><br><span class="line"><span class="string">          ClientUsername: drop  </span></span><br><span class="line"><span class="string">        headers:                ## 设置 Header 中字段是否保留</span></span><br><span class="line"><span class="string">          defaultMode: keep     ## 设置默认保留 Header 中字段</span></span><br><span class="line"><span class="string">          names:                ## 针对 Header 中特别字段特别配置保留模式</span></span><br><span class="line"><span class="string">            User-Agent: redact</span></span><br><span class="line"><span class="string">            Authorization: drop</span></span><br><span class="line"><span class="string">            Content-Type: keep</span></span><br></pre></td></tr></table></figure>

<p>创建Traefik configmap 资源</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kubectl apply -f traefik-config.yaml</span><br></pre></td></tr></table></figure>

<h2 id="设置节点-Label-标签">1.4. 设置节点 Label 标签</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master traefik]# kubectl label nodes k8s-master IngressProxy=traefik2.3</span><br><span class="line">node/k8s-master labeled</span><br><span class="line"></span><br><span class="line">[root@k8s-master traefik]# kubectl label nodes k8s-node1 IngressProxy=traefik2.3</span><br><span class="line">node/k8s-node1 labeled</span><br><span class="line"></span><br><span class="line">[root@k8s-master traefik]# kubectl label nodes k8s-node2 IngressProxy=traefik2.3</span><br><span class="line">node/k8s-node2 labeled</span><br></pre></td></tr></table></figure>

<p>验证节点标签是否成功</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-master traefik]# kubectl get node --show-labels</span><br><span class="line">NAME         STATUS   ROLES    AGE   VERSION   LABELS</span><br><span class="line">k8s-master   Ready    master   46h   v1.18.0   IngressProxy=traefik2.3,beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-master,kubernetes.io/os=linux,node-role.kubernetes.io/master=</span><br><span class="line">k8s-node1    Ready    &lt;none&gt;   46h   v1.18.0   IngressProxy=traefik2.3,beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node1,kubernetes.io/os=linux</span><br><span class="line">k8s-node2    Ready    &lt;none&gt;   46h   v1.18.0   IngressProxy=traefik2.3,beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node2,kubernetes.io/os=linux</span><br></pre></td></tr></table></figure>

<p>节点删除Label标签</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># kubectl label nodes k8s-master IngressProxy-</span><br><span class="line"># kubectl label nodes k8s-node1 IngressProxy-</span><br><span class="line"># kubectl label nodes k8s-node2 IngressProxy-</span><br></pre></td></tr></table></figure>



<h2 id="创建-Traefik">1.5. 创建 Traefik</h2><p>下面将用<code>DaemonSet</code>方式部署 Traefik，便于在多服务器间扩展，用 hostport 方式绑定服务器 80、443 端口，方便流量通过物理机进入 Kubernetes 内部。</p>
<p>cat traefik-deploy.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat traefik-deploy.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">traefik-v2</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">traefik-v2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">traefik-v2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">traefik-v2</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">traefik-ingress-controller</span></span><br><span class="line">      <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">traefik-v2</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">traefik:v2.3</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--configfile=/config/traefik.yaml</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">              <span class="attr">hostPort:</span> <span class="number">80</span>           <span class="comment">#hostPort方式，将端口暴露到集群节点</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">websecure</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">443</span></span><br><span class="line">              <span class="attr">hostPort:</span> <span class="number">443</span>          <span class="comment">#hostPort方式，将端口暴露到集群节点</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">admin</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">8090</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tcpep</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">8000</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">udpep</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">9000</span></span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">500m</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">1024Mi</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">300m</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">1024Mi</span></span><br><span class="line">          <span class="attr">securityContext:</span></span><br><span class="line">            <span class="attr">capabilities:</span>              <span class="comment">## 只开放网络权限    </span></span><br><span class="line">              <span class="attr">drop:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">ALL</span></span><br><span class="line">              <span class="attr">add:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">NET_BIND_SERVICE</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">&quot;/config&quot;</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">&quot;config&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/etc/traefik/logs</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">logdir</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/etc/localtime</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">timezone</span></span><br><span class="line">            <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">traefik-config</span> </span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logdir</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/data/traefik/logs</span></span><br><span class="line">            <span class="attr">type:</span> <span class="string">&quot;DirectoryOrCreate&quot;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">timezone</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/etc/localtime</span></span><br><span class="line">            <span class="attr">type:</span> <span class="string">File</span></span><br><span class="line">      <span class="attr">tolerations:</span>            </span><br><span class="line">        <span class="bullet">-</span> <span class="attr">operator:</span> <span class="string">&quot;Exists&quot;</span>        <span class="comment">## 设置容忍所有污点，防止节点被设置污点</span></span><br><span class="line">      <span class="attr">hostNetwork:</span> <span class="literal">true</span>             <span class="comment">## 开启host网络，提高网络入口的网络性能</span></span><br><span class="line">      <span class="attr">nodeSelector:</span>                 <span class="comment">## 设置node筛选器，在特定label的节点上启动</span></span><br><span class="line">        <span class="attr">IngressProxy:</span> <span class="string">&quot;traefik2.3&quot;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">traefik-v2</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">LoadBalancer</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">traefik-v2</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">websecure</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">443</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">8090</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">admin</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">8090</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">8000</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">tcpep</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">8000</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">traefikudp-v2</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">LoadBalancer</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">traefik-v2</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">UDP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">9000</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">udpep</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9000</span></span><br></pre></td></tr></table></figure>

<p>创建 Traefik</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kubectl apply -f traefik-deploy.yaml</span><br></pre></td></tr></table></figure>

<p>使用Deployment类型部署，以便于在多服务器间扩展，使用 hostport 方式占用服务器 80、443 端口，方便流量进入。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 部署 Traefik</span><br><span class="line"># kubectl apply -f traefik-deploy.yaml </span><br><span class="line">deployment.apps/traefik-v2 created</span><br><span class="line">service/traefik-v2 created</span><br><span class="line">service/traefikudp-v2 created</span><br></pre></td></tr></table></figure>

<p>到此 Traefik v2.3 应用已经部署完成。<br>这时候就可以通过节点<a href="http://IP:8090,可以看到dashboard相关信息">http://IP:8090,可以看到dashboard相关信息</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/traefik/1.jpg" alt="traefik"></p>
<h2 id="路由配置">1.6. 路由配置</h2><h3 id="配置-HTTP-路由规则-（Traefik-Dashboard-为例）">1.6.1. 配置 HTTP 路由规则 （Traefik Dashboard 为例）</h3><p>Traefik 应用已经部署完成，但是想让外部访问 Kubernetes 内部服务，还需要配置路由规则，这里开启了 Traefik Dashboard 配置，所以首先配置 Traefik Dashboard 看板的路由规则，使外部能够访问 Traefik Dashboard。</p>
<p>创建 Traefik Dashboard 路由规则文件 traefik-dashboard-route.yaml</p>
<p>因为静态配置文件指定了ingressclass，所以这里的annotations 要指定，否则访问会404</p>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/traefik/2.jpg" alt="traefik"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># cat traefik-dashboard-route.yaml</span><br><span class="line">apiVersion: traefik.containo.us/v1alpha1</span><br><span class="line">kind: IngressRoute</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik-v2.3     </span><br><span class="line">spec:</span><br><span class="line">  entryPoints:</span><br><span class="line">    - web</span><br><span class="line">  routes:</span><br><span class="line">  - match: Host(`traefik.heyonggs.com`) </span><br><span class="line">    kind: Rule</span><br><span class="line">    services:</span><br><span class="line">    - name: api@internal</span><br><span class="line">      kind: TraefikService</span><br></pre></td></tr></table></figure>

<p>部署Traefik Dashboard 路由规则对象</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># kubectl apply -f traefik-dashboard-route.yaml</span><br><span class="line">ingressroute.traefik.containo.us/traefik-dashboard created</span><br></pre></td></tr></table></figure>

<p>客户端通过域名访问服务，必须要进行 DNS 解析，可以通过 DNS 服务器进行域名解析，也可以修改 hosts 文件将 Traefik 指定节点的 IP 和自定义 host 绑定</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"># cat hosts</span><br><span class="line">192.168.101.202 traefik.heyonggs.com</span><br></pre></td></tr></table></figure>

<p>打开任意浏览器输入地址： <a href="http://traefik.heyonggs.com进行访问,打开/">http://traefik.heyonggs.com进行访问，打开</a> Traefik Dashboard.</p>
<p>此处没有配置验证登录，如果想配置验证登录，使用middleware即可。</p>
<p><img src="https://cdn.jsdelivr.net/gh/heyonggs/images@master/wp/2021/traefik/3.jpg" alt="traefik"></p>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>kubeadm平滑升级集群</title>
    <url>/p/23481.html</url>
    <content><![CDATA[<p><escape><span id="more"></span></escape></p>
<h1 id="kubeadm平滑升级群集">1. kubeadm平滑升级群集</h1><p>我们安装的版本为<code>1.18.0</code>，但是最新的版本为<code>1.18.20</code>想要升级为最新的版本又不影响业务的访问。</p>
<h2 id="检查群集">1.1. 检查群集</h2><p>检查群集可用于升级的版本和当前群集是否可升级</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kubeadm upgrade plan</span><br></pre></td></tr></table></figure>

<p>执行结果如下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]# kubeadm upgrade plan</span><br><span class="line">[upgrade/config] Making sure the configuration is correct:</span><br><span class="line">[upgrade/config] Reading configuration from the cluster...</span><br><span class="line">[upgrade/config] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -oyaml&#x27;</span><br><span class="line">[preflight] Running pre-flight checks.</span><br><span class="line">[upgrade] Running cluster health checks</span><br><span class="line">[upgrade] Fetching available versions to upgrade to</span><br><span class="line">[upgrade/versions] Cluster version: v1.18.0</span><br><span class="line">[upgrade/versions] kubeadm version: v1.18.0-dirty</span><br><span class="line">I0906 09:48:57.817361 3822642 version.go:252] remote version is much newer: v1.22.1; falling back to: stable-1.18</span><br><span class="line">[upgrade/versions] Latest stable version: v1.18.20</span><br><span class="line">[upgrade/versions] Latest stable version: v1.18.20</span><br><span class="line">[upgrade/versions] Latest version in the v1.18 series: v1.18.20</span><br><span class="line">[upgrade/versions] Latest version in the v1.18 series: v1.18.20</span><br><span class="line"></span><br><span class="line">Components that must be upgraded manually after you have upgraded the control plane with &#x27;kubeadm upgrade apply&#x27;:</span><br><span class="line">COMPONENT   CURRENT       AVAILABLE</span><br><span class="line">Kubelet     3 x v1.18.0   v1.18.20</span><br><span class="line"></span><br><span class="line">Upgrade to the latest version in the v1.18 series:</span><br><span class="line"></span><br><span class="line">COMPONENT            CURRENT   AVAILABLE</span><br><span class="line">API Server           v1.18.0   v1.18.20</span><br><span class="line">Controller Manager   v1.18.0   v1.18.20</span><br><span class="line">Scheduler            v1.18.0   v1.18.20</span><br><span class="line">Kube Proxy           v1.18.0   v1.18.20</span><br><span class="line">CoreDNS              1.6.7     1.6.7</span><br><span class="line">Etcd                 3.4.3     3.4.3-0</span><br><span class="line"></span><br><span class="line">You can now apply the upgrade by executing the following command:</span><br><span class="line"></span><br><span class="line">	kubeadm upgrade apply v1.18.20</span><br><span class="line"></span><br><span class="line">Note: Before you can perform this upgrade, you have to update kubeadm to v1.18.20.</span><br><span class="line"></span><br><span class="line">_____________________________________________________________________</span><br></pre></td></tr></table></figure>

<p>这里需要先升级<code>kubeadm``kubelet``kubectl</code></p>
<h2 id="升级kubelet-kubeadm-kubectl">1.2. 升级kubelet kubeadm kubectl</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y kubelet-1.18.20 kubeadm-1.18.20 kubectl-1.18.20</span><br></pre></td></tr></table></figure>

<blockquote>
<p>其他节点也需要执行</p>
</blockquote>
<h2 id="升级群集组件">1.3. 升级群集组件</h2><p>过程会稍微有点慢，因需要下载新版本的镜像</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubeadm upgrade apply v1.18.20</span><br></pre></td></tr></table></figure>

<p>执行之后输出如下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]# kubeadm upgrade apply v1.18.20</span><br><span class="line">[upgrade/config] Making sure the configuration is correct:</span><br><span class="line">[upgrade/config] Reading configuration from the cluster...</span><br><span class="line">[upgrade/config] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -oyaml&#x27;</span><br><span class="line">[preflight] Running pre-flight checks.</span><br><span class="line">[upgrade] Running cluster health checks</span><br><span class="line">[upgrade/version] You have chosen to change the cluster version to &quot;v1.18.20&quot;</span><br><span class="line">[upgrade/versions] Cluster version: v1.18.0</span><br><span class="line">[upgrade/versions] kubeadm version: v1.18.20</span><br><span class="line">[upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y</span><br><span class="line">[upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd]</span><br><span class="line">[upgrade/prepull] Prepulling image for component etcd.</span><br><span class="line">[upgrade/prepull] Prepulling image for component kube-apiserver.</span><br><span class="line">[upgrade/prepull] Prepulling image for component kube-controller-manager.</span><br><span class="line">[upgrade/prepull] Prepulling image for component kube-scheduler.</span><br><span class="line">[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver</span><br><span class="line">[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler</span><br><span class="line">[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager</span><br><span class="line">[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-etcd</span><br><span class="line">[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler</span><br><span class="line">[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd</span><br><span class="line">[upgrade/prepull] Prepulled image for component etcd.</span><br><span class="line">[upgrade/prepull] Prepulled image for component kube-controller-manager.</span><br><span class="line">[upgrade/prepull] Prepulled image for component kube-scheduler.</span><br><span class="line">[upgrade/prepull] Prepulled image for component kube-apiserver.</span><br><span class="line">[upgrade/prepull] Successfully prepulled the images for all the control plane components</span><br><span class="line">[upgrade/apply] Upgrading your Static Pod-hosted control plane to version &quot;v1.18.20&quot;...</span><br><span class="line">Static pod: kube-apiserver-k8s-master hash: 19d5d1ced032267ed77feb4529dd89b6</span><br><span class="line">Static pod: kube-controller-manager-k8s-master hash: c99654aba4d0627786d6f7f6ca3cf8a4</span><br><span class="line">Static pod: kube-scheduler-k8s-master hash: b901723f22729fcf965378cb64525117</span><br><span class="line">[upgrade/etcd] Upgrading to TLS for etcd</span><br><span class="line">[upgrade/etcd] Non fatal issue encountered during upgrade: the desired etcd version for this Kubernetes version &quot;v1.18.20&quot; is &quot;3.4.3-0&quot;, but the current etcd version is &quot;3.4.3&quot;. Won&#x27;t downgrade etcd, instead just continue</span><br><span class="line">[upgrade/staticpods] Writing new Static Pod manifests to &quot;/etc/kubernetes/tmp/kubeadm-upgraded-manifests350292254&quot;</span><br><span class="line">W0906 12:02:13.995741 3880622 manifests.go:225] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[upgrade/staticpods] Preparing for &quot;kube-apiserver&quot; upgrade</span><br><span class="line">[upgrade/staticpods] Renewing apiserver certificate</span><br><span class="line">[upgrade/staticpods] Renewing apiserver-kubelet-client certificate</span><br><span class="line">[upgrade/staticpods] Renewing front-proxy-client certificate</span><br><span class="line">[upgrade/staticpods] Renewing apiserver-etcd-client certificate</span><br><span class="line">[upgrade/staticpods] Moved new manifest to &quot;/etc/kubernetes/manifests/kube-apiserver.yaml&quot; and backed up old manifest to &quot;/etc/kubernetes/tmp/kubeadm-backup-manifests-2021-09-06-12-02-12/kube-apiserver.yaml&quot;</span><br><span class="line">[upgrade/staticpods] Waiting for the kubelet to restart the component</span><br><span class="line">[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)</span><br><span class="line">Static pod: kube-apiserver-k8s-master hash: 19d5d1ced032267ed77feb4529dd89b6</span><br><span class="line">Static pod: kube-apiserver-k8s-master hash: 4b88bf8fbacc7b265a069eb9c4b66b28</span><br><span class="line">[apiclient] Found 1 Pods for label selector component=kube-apiserver</span><br><span class="line">[upgrade/staticpods] Component &quot;kube-apiserver&quot; upgraded successfully!</span><br><span class="line">[upgrade/staticpods] Preparing for &quot;kube-controller-manager&quot; upgrade</span><br><span class="line">[upgrade/staticpods] Renewing controller-manager.conf certificate</span><br><span class="line">[upgrade/staticpods] Moved new manifest to &quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&quot; and backed up old manifest to &quot;/etc/kubernetes/tmp/kubeadm-backup-manifests-2021-09-06-12-02-12/kube-controller-manager.yaml&quot;</span><br><span class="line">[upgrade/staticpods] Waiting for the kubelet to restart the component</span><br><span class="line">[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)</span><br><span class="line">Static pod: kube-controller-manager-k8s-master hash: c99654aba4d0627786d6f7f6ca3cf8a4</span><br><span class="line">Static pod: kube-controller-manager-k8s-master hash: 36c14c513b299c15f058e6c085d03822</span><br><span class="line">[apiclient] Found 1 Pods for label selector component=kube-controller-manager</span><br><span class="line">[upgrade/staticpods] Component &quot;kube-controller-manager&quot; upgraded successfully!</span><br><span class="line">[upgrade/staticpods] Preparing for &quot;kube-scheduler&quot; upgrade</span><br><span class="line">[upgrade/staticpods] Renewing scheduler.conf certificate</span><br><span class="line">[upgrade/staticpods] Moved new manifest to &quot;/etc/kubernetes/manifests/kube-scheduler.yaml&quot; and backed up old manifest to &quot;/etc/kubernetes/tmp/kubeadm-backup-manifests-2021-09-06-12-02-12/kube-scheduler.yaml&quot;</span><br><span class="line">[upgrade/staticpods] Waiting for the kubelet to restart the component</span><br><span class="line">[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)</span><br><span class="line">Static pod: kube-scheduler-k8s-master hash: b901723f22729fcf965378cb64525117</span><br><span class="line">Static pod: kube-scheduler-k8s-master hash: f8fbdc8109ec0a5dd59acbd52a6c05ca</span><br><span class="line">[apiclient] Found 1 Pods for label selector component=kube-scheduler</span><br><span class="line">[upgrade/staticpods] Component &quot;kube-scheduler&quot; upgraded successfully!</span><br><span class="line">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.18&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class="line">[kubelet-start] Downloading configuration for the kubelet from the &quot;kubelet-config-1.18&quot; ConfigMap in the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">[upgrade/successful] SUCCESS! Your cluster was upgraded to &quot;v1.18.20&quot;. Enjoy!</span><br><span class="line"></span><br><span class="line">[upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven&#x27;t already done so.</span><br></pre></td></tr></table></figure>

<p>在其他master节点升级</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubeadm upgrade node</span><br></pre></td></tr></table></figure>

<p>执行后输出如下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]# kubeadm upgrade node</span><br><span class="line">[upgrade] Reading configuration from the cluster...</span><br><span class="line">[upgrade] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -oyaml&#x27;</span><br><span class="line">[upgrade] Upgrading your Static Pod-hosted control plane instance to version &quot;v1.18.20&quot;...</span><br><span class="line">Static pod: kube-apiserver-k8s-master hash: 4b88bf8fbacc7b265a069eb9c4b66b28</span><br><span class="line">Static pod: kube-controller-manager-k8s-master hash: 36c14c513b299c15f058e6c085d03822</span><br><span class="line">Static pod: kube-scheduler-k8s-master hash: f8fbdc8109ec0a5dd59acbd52a6c05ca</span><br><span class="line">[upgrade/etcd] Upgrading to TLS for etcd</span><br><span class="line">[upgrade/etcd] Non fatal issue encountered during upgrade: the desired etcd version for this Kubernetes version &quot;v1.18.20&quot; is &quot;3.4.3-0&quot;, but the current etcd version is &quot;3.4.3&quot;. Won&#x27;t downgrade etcd, instead just continue</span><br><span class="line">[upgrade/staticpods] Writing new Static Pod manifests to &quot;/etc/kubernetes/tmp/kubeadm-upgraded-manifests324894338&quot;</span><br><span class="line">W0906 13:40:16.646872 3923374 manifests.go:225] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[upgrade/staticpods] Preparing for &quot;kube-apiserver&quot; upgrade</span><br><span class="line">[upgrade/staticpods] Current and new manifests of kube-apiserver are equal, skipping upgrade</span><br><span class="line">[upgrade/staticpods] Preparing for &quot;kube-controller-manager&quot; upgrade</span><br><span class="line">[upgrade/staticpods] Current and new manifests of kube-controller-manager are equal, skipping upgrade</span><br><span class="line">[upgrade/staticpods] Preparing for &quot;kube-scheduler&quot; upgrade</span><br><span class="line">[upgrade/staticpods] Current and new manifests of kube-scheduler are equal, skipping upgrade</span><br><span class="line">[upgrade] The control plane instance for this node was successfully updated!</span><br><span class="line">[kubelet-start] Downloading configuration for the kubelet from the &quot;kubelet-config-1.18&quot; ConfigMap in the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[upgrade] The configuration for this node was successfully updated!</span><br><span class="line">[upgrade] Now you should go ahead and upgrade the kubelet package using your package manager.</span><br></pre></td></tr></table></figure>

<h2 id="升级flannel-可选">1.4. 升级flannel (可选)</h2><p>这个根据实际情况升级，如不是使用的<code>flannel</code>请参考官网</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure>

<h2 id="验证群集升级">1.5. 验证群集升级</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]# kubectl get nodes</span><br><span class="line">NAME         STATUS   ROLES    AGE     VERSION</span><br><span class="line">k8s-master   Ready    master   6d19h   v1.18.0</span><br><span class="line">k8s-node1    Ready    &lt;none&gt;   6d19h   v1.18.0</span><br><span class="line">k8s-node2    Ready    &lt;none&gt;   6d19h   v1.18.0</span><br></pre></td></tr></table></figure>

<p>kubectl版本</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]# kubectl version</span><br><span class="line">Client Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;18&quot;, GitVersion:&quot;v1.18.20&quot;, GitCommit:&quot;632ed300f2c34f6d6d15ca4cef3d3c7073412212&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2021-08-19T15:45:37Z&quot;, GoVersion:&quot;go1.16.7&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;&#125;</span><br><span class="line">Server Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;18&quot;, GitVersion:&quot;v1.18.0&quot;, GitCommit:&quot;9e991415386e4cf155a24b1da15becaa390438d8&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2020-03-25T14:50:46Z&quot;, GoVersion:&quot;go1.13.8&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;&#125;</span><br><span class="line">WARNING: version difference between client (1.18) and server (1.18) exceeds the supported minor version skew of +/-1</span><br></pre></td></tr></table></figure>

<p>这里发现<code>version</code>还是<code>1.18.0</code>, kubectl的server还是<code>1.18.0</code>，只需要重启一下kubelet即可</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload;systemctl restart kubelet.service</span><br></pre></td></tr></table></figure>

<blockquote>
<p>所有节点都需要执行</p>
</blockquote>
<p>再次查看</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]# kubeadm upgrade plan</span><br><span class="line">[upgrade/config] Making sure the configuration is correct:</span><br><span class="line">[upgrade/config] Reading configuration from the cluster...</span><br><span class="line">[upgrade/config] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -oyaml&#x27;</span><br><span class="line">[preflight] Running pre-flight checks.</span><br><span class="line">[upgrade] Running cluster health checks</span><br><span class="line">[upgrade] Fetching available versions to upgrade to</span><br><span class="line">[upgrade/versions] Cluster version: v1.18.20</span><br><span class="line">[upgrade/versions] kubeadm version: v1.18.20</span><br><span class="line">I0906 13:48:20.988439 3926779 version.go:255] remote version is much newer: v1.22.1; falling back to: stable-1.18</span><br><span class="line">[upgrade/versions] Latest stable version: v1.18.20</span><br><span class="line">[upgrade/versions] Latest stable version: v1.18.20</span><br><span class="line">[upgrade/versions] Latest version in the v1.18 series: v1.18.20</span><br><span class="line">[upgrade/versions] Latest version in the v1.18 series: v1.18.20</span><br><span class="line"></span><br><span class="line">Awesome, you&#x27;re up-to-date! Enjoy!</span><br></pre></td></tr></table></figure>

<p>最后发现群集已经为1.18.20</p>
<h2 id="更新群集证书">1.6. 更新群集证书</h2><ul>
<li>更新所有证书</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubeadm alpha certs renew all</span><br></pre></td></tr></table></figure>

<p>输出如下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]# kubeadm alpha certs renew all</span><br><span class="line">[renew] Reading configuration from the cluster...</span><br><span class="line">[renew] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -oyaml&#x27;</span><br><span class="line"></span><br><span class="line">certificate embedded in the kubeconfig file for the admin to use and for kubeadm itself renewed</span><br><span class="line">certificate for serving the Kubernetes API renewed</span><br><span class="line">certificate the apiserver uses to access etcd renewed</span><br><span class="line">certificate for the API server to connect to kubelet renewed</span><br><span class="line">certificate embedded in the kubeconfig file for the controller manager to use renewed</span><br><span class="line">certificate for liveness probes to healthcheck etcd renewed</span><br><span class="line">certificate for etcd nodes to communicate with each other renewed</span><br><span class="line">certificate for serving etcd renewed</span><br><span class="line">certificate for the front proxy client renewed</span><br><span class="line">certificate embedded in the kubeconfig file for the scheduler manager to use renewed</span><br></pre></td></tr></table></figure>

<ul>
<li>更新其他单个证书请参考官方文档<a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-alpha/#cmd-certs-renew">https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-alpha/#cmd-certs-renew</a></li>
</ul>
<p>查看当前证书时间</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]# kubeadm alpha certs check-expiration</span><br><span class="line">[check-expiration] Reading configuration from the cluster...</span><br><span class="line">[check-expiration] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -oyaml&#x27;</span><br><span class="line"></span><br><span class="line">CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED</span><br><span class="line">admin.conf                 Sep 06, 2022 05:51 UTC   364d                                    no      </span><br><span class="line">apiserver                  Sep 06, 2022 05:51 UTC   364d            ca                      no      </span><br><span class="line">apiserver-etcd-client      Sep 06, 2022 05:51 UTC   364d            etcd-ca                 no      </span><br><span class="line">apiserver-kubelet-client   Sep 06, 2022 05:51 UTC   364d            ca                      no      </span><br><span class="line">controller-manager.conf    Sep 06, 2022 05:51 UTC   364d                                    no      </span><br><span class="line">etcd-healthcheck-client    Sep 06, 2022 05:51 UTC   364d            etcd-ca                 no      </span><br><span class="line">etcd-peer                  Sep 06, 2022 05:51 UTC   364d            etcd-ca                 no      </span><br><span class="line">etcd-server                Sep 06, 2022 05:51 UTC   364d            etcd-ca                 no      </span><br><span class="line">front-proxy-client         Sep 06, 2022 05:51 UTC   364d            front-proxy-ca          no      </span><br><span class="line">scheduler.conf             Sep 06, 2022 05:51 UTC   364d                                    no      </span><br><span class="line"></span><br><span class="line">CERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED</span><br><span class="line">ca                      Aug 28, 2031 07:52 UTC   9y              no      </span><br><span class="line">etcd-ca                 Aug 28, 2031 07:53 UTC   9y              no      </span><br><span class="line">front-proxy-ca          Aug 28, 2031 07:53 UTC   9y              no      </span><br></pre></td></tr></table></figure>







]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>常用工具汇总</title>
    <url>/p/24997.html</url>
    <content><![CDATA[<p><escape><span id="more"></span></escape></p>
<h3 id="Adobe-Acrobat-Pro-DC2021破解直装版">0.0.1. Adobe Acrobat Pro DC2021破解直装版</h3><p>   Adobe Acrobat Pro DC是Adobe公司的一款PDF编辑和阅读软件。它将全球最佳的PDF解决方案提升到新的高度，配有直观触控式界面，通过开发强大的新功能，使用户能在任何地方完成工作。新工具中心可更简单迅速的访问最常使用的工具。Acrobat DC可利用Photoshop强大的图像编辑功能，将任何纸质文件转换为可编辑的电子文件，用于传输、签字。Acrobat DC 是完全重塑的全球最佳 PDF 解决方案的桌面版。它包括一个移动应用程序，因此您可以在任何设备上填写、签署以及共享 PDF。</p>
<blockquote>
<p>[大小]：868MB</p>
<p>[操作系统]：32/64位</p>
<p>[安装环境]：Win7/Win8/Win10</p>
<p>[安装包下载地址]：<a href="https://pan.baidu.com/s/1Eqwu72Y-VPJKY806UonVjg">https://pan.baidu.com/s/1Eqwu72Y-VPJKY806UonVjg</a> </p>
<p>提取码：r72k</p>
<p>解压密码：dzrjk8</p>
</blockquote>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql导入数据慢解决方法</title>
    <url>/p/1525.html</url>
    <content><![CDATA[<p><escape><span id="more"></span></escape></p>
<p>mysql导入慢，添加两个参数：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">max_allowed_packet   客户端/服务器之间通信的缓存区的最大大小</span><br><span class="line">net_buffer_length    TCP/IP和套接字通信缓冲区大小，创建长度达net_buffer_length行。</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注：max_allowed_packet; net_buffer_length 这两个参数不能比目标数据度配置大，否则会报错。</p>
</blockquote>
<p>先查看目标库的参数值 如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> show variables like <span class="string">&#x27;max_allowed_packet&#x27;</span>;</span></span><br><span class="line">+--------------------+----------+</span><br><span class="line">| Variable_name      | Value    |</span><br><span class="line">+--------------------+----------+</span><br><span class="line">| max_allowed_packet | 67108864 |</span><br><span class="line">+--------------------+----------+</span><br><span class="line">1 row in set (0.22 sec)</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> show variables like <span class="string">&#x27;net_buffer_length&#x27;</span>;</span></span><br><span class="line">+-------------------+-------+</span><br><span class="line">| Variable_name     | Value |</span><br><span class="line">+-------------------+-------+</span><br><span class="line">| net_buffer_length | 16384 |</span><br><span class="line">+-------------------+-------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<p>命令行加上两个参数执行</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -h127.0.0.1 -uroot -p&#x27;Pass!234&#x27; data_base_name --max_allowed_packet=67108864 --net_buffer_length=16384&lt;your_sql_script.sql</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>自动化运维工具-Ansible</title>
    <url>/p/28124.html</url>
    <content><![CDATA[<p><escape><span id="more"></span></escape></p>
<h1 id="Ansible详解">1. Ansible详解</h1><p>ansible是新出现的自动化运维工具，基于Python开发，集合了众多运维工具（puppet、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能。<br>　　ansible是基于 paramiko 开发的,并且基于模块化工作，本身没有批量部署的能力。真正具有批量部署的是ansible所运行的模块，ansible只是提供一种框架。ansible不需要在远程主机上安装client/agents，因为它们是基于ssh来和远<br>程主机通讯的。ansible目前已经已经被红帽官方收购，是自动化运维工具中大家认可度最高的，并且上手容易，学习简单。是每位运维工程师必须掌握的技能之一。</p>
<p>ansible特点</p>
<ol>
<li>部署简单，只需在主控端部署Ansible环境，被控端无需做任何操作；</li>
<li>默认使用SSH协议对设备进行管理；</li>
<li>有大量常规运维操作模块，可实现日常绝大部分操作；</li>
<li>配置简单、功能强大、扩展性强；</li>
<li>支持API及自定义模块，可通过Python轻松扩展；</li>
<li>通过Playbooks来定制强大的配置、状态管理；</li>
<li>轻量级，无需在客户端安装agent，更新时，只需在操作机上进行一次更新即可；</li>
<li>提供一个功能强大、操作性强的Web管理界面和REST API接口——AWX平台。</li>
</ol>
<h2 id="ansible-配置公私钥">1.1. ansible 配置公私钥</h2><p>上面我们已经提到过 ansible 是基于 ssh 协议实现的，所以其配置公私钥的方式与 ssh 协议的方式相同，具体操作步骤如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">1.生成私钥</span></span><br><span class="line">[root@server ~]# ssh-keygen </span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">2.向主机分发私钥</span></span><br><span class="line">[root@mgmt2 ~]# ssh-copy-id root@192.168.101.201</span><br><span class="line">[root@mgmt2 ~]# ssh-copy-id root@192.168.101.202</span><br><span class="line">[root@mgmt2 ~]# ssh-copy-id root@192.168.101.203</span><br></pre></td></tr></table></figure>

<p>这样就实现了无密码登陆</p>
<p>注意：如果出现如下报错</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-bash: ssh-copy-id: command not found</span><br></pre></td></tr></table></figure>

<p>我们需要安装一个包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install openssh-clientsansible</span><br></pre></td></tr></table></figure>

<p>再次执行即可</p>
<h2 id="ansible常用模块">1.2. ansible常用模块</h2><h3 id="主机连通性测试">1.2.1. 主机连通性测试</h3><p>我们使用<code>ansible k8s -m ping</code>命令来进行主机连通性测试，效果如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible k8s -m ping</span><br><span class="line">192.168.101.201 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;changed&quot;: false,</span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">192.168.101.203 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;changed&quot;: false,</span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">192.168.101.202 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;changed&quot;: false,</span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="command-模块">1.2.2. command 模块</h3><p>这个模块可以直接在远程主机上执行命令，并将结果返回本主机。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible k8s -m command -a &#x27;free -h&#x27;</span><br><span class="line">192.168.101.202 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:          7.6Gi       2.1Gi       2.2Gi        33Mi       3.4Gi       5.3Gi</span><br><span class="line">Swap:            0B          0B          0B</span><br><span class="line"></span><br><span class="line">192.168.101.203 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:          7.6Gi       2.4Gi       1.8Gi        25Mi       3.4Gi       5.3Gi</span><br><span class="line">Swap:            0B          0B          0B</span><br><span class="line"></span><br><span class="line">192.168.101.201 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:          3.7Gi       2.3Gi       121Mi        25Mi       1.3Gi       1.3Gi</span><br><span class="line">Swap:            0B          0B          0B</span><br></pre></td></tr></table></figure>

<p>命令模块接受命令名称，后面是空格分隔的列表参数。给定的命令将在所有选定的节点上执行。它不会通过shell进行处理，比如$HOME和操作如”&lt;”，”&gt;”，”|”，”;”，”&amp;” 工作（需要使用（shell）模块实现这些功能）。注意，该命令不支持<code>| 管道命令</code>。<br>下面来看一看该模块下常用的几个命令：</p>
<blockquote>
<p>chdir　　　　　　 # 在执行命令之前，先切换到该目录<br>executable # 切换shell来执行命令，需要使用命令的绝对路径<br>free_form 　 # 要执行的Linux指令，一般使用Ansible的-a参数代替。<br>creates 　# 一个文件名，当这个文件存在，则该命令不执行,可以<br>用来做判断<br>removes # 一个文件名，这个文件不存在，则该命令不执行</p>
</blockquote>
<p>下面我们来看看这些命令的执行效果：</p>
<ul>
<li>chdir</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible k8s -m command -a &#x27;chdir=/opt/ ls&#x27;  #先切换到/data/ 目录，再执行“ls”命令</span><br><span class="line">192.168.101.201 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">cni</span><br><span class="line">containerd</span><br><span class="line"></span><br><span class="line">192.168.101.202 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">cni</span><br><span class="line">containerd</span><br><span class="line"></span><br><span class="line">192.168.101.203 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">cni</span><br><span class="line">containerd</span><br></pre></td></tr></table></figure>

<ul>
<li>creates</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible k8s -m command -a &#x27;creates=/data/Dockerfile ls&#x27;  #如果/data/Dockerfile存在，则不执行“ls”命令</span><br><span class="line">192.168.101.202 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">anaconda-ks.cfg</span><br><span class="line">docker</span><br><span class="line">docker-19.03.9.tgz</span><br><span class="line">yq</span><br><span class="line"></span><br><span class="line">192.168.101.201 | SUCCESS | rc=0 &gt;&gt;</span><br><span class="line">skipped, since /data/Dockerfile exists</span><br><span class="line"></span><br><span class="line">192.168.101.203 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">anaconda-ks.cfg</span><br><span class="line">docker</span><br><span class="line">docker-19.03.9.tgz</span><br><span class="line">yq</span><br></pre></td></tr></table></figure>

<ul>
<li>removes</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible k8s -m command -a &#x27;removes=/data/Dockerfile free -h&#x27;  #如果/data/Dockerfile存在，则执行“free -h”命令</span><br><span class="line">192.168.101.202 | SUCCESS | rc=0 &gt;&gt;</span><br><span class="line">skipped, since /data/Dockerfile does not exist</span><br><span class="line"></span><br><span class="line">192.168.101.203 | SUCCESS | rc=0 &gt;&gt;</span><br><span class="line">skipped, since /data/Dockerfile does not exist</span><br><span class="line"></span><br><span class="line">192.168.101.201 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:          3.7Gi       2.3Gi       116Mi        25Mi       1.3Gi       1.3Gi</span><br><span class="line">Swap:            0B          0B          0B</span><br></pre></td></tr></table></figure>



<h3 id="shell-模块">1.2.3. shell 模块</h3><p>shell模块可以在远程主机上调用shell解释器运行命令，支持shell的各种功能，例如管道等。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible k8s -m shell -a &#x27;cat /etc/passwd |grep &quot;root&quot;&#x27;</span><br><span class="line">192.168.101.201 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">root:x:0:0:root:/root:/bin/bash</span><br><span class="line">operator:x:11:0:operator:/root:/sbin/nologin</span><br><span class="line"></span><br><span class="line">192.168.101.202 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">root:x:0:0:root:/root:/bin/bash</span><br><span class="line">operator:x:11:0:operator:/root:/sbin/nologin</span><br><span class="line"></span><br><span class="line">192.168.101.203 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">root:x:0:0:root:/root:/bin/bash</span><br><span class="line">operator:x:11:0:operator:/root:/sbin/nologin</span><br></pre></td></tr></table></figure>

<p>只要是我们的shell命令，都可以通过这个模块在远程主机上运行</p>
<h3 id="copy模块">1.2.4. copy模块</h3><p>这个模块用于将文件复制到远程主机，同时支持给定内容生成文件和修改权限等。<br>其相关选项如下：</p>
<blockquote>
<p><code>src</code>　　　　#被复制到远程主机的本地文件。可以是绝对路径，也可以是相对路径。如果路径是一个目录，则会递归复制，用法类似于”rsync”<br><code>content</code>　　　#用于替换”src”，可以直接指定文件的值<br><code>dest</code>　　　　#必选项，将源文件复制到的远程主机的<strong>绝对路径</strong><br><code>backup</code>　　　#当文件内容发生改变后，在覆盖之前把源文件备份，备份文件包含时间信息<br><code>directory_mode</code>　　　　#递归设定目录的权限，默认为系统默认权限<br><code>force</code>　　　　#当目标主机包含该文件，但内容不同时，设为yes，表示强制覆盖；设为no，表示目标主机的目标位置不存在该文件才复制。默认为yes<br><code>others</code>　　　　#所有的 file 模块中的选项可以在这里使用</p>
</blockquote>
<p>用法举例如下：</p>
<ul>
<li>复制文件：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible web -m copy -a &#x27;src=./ansible.cfg dest=/data/&#x27;</span><br><span class="line">192.168.101.202 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;changed&quot;: false,</span><br><span class="line">    &quot;checksum&quot;: &quot;a2a782df5d7bd49afb0971fc6be21cd825daaaa3&quot;,</span><br><span class="line">    &quot;dest&quot;: &quot;/data/ansible.cfg&quot;,</span><br><span class="line">    &quot;gid&quot;: 0,</span><br><span class="line">    &quot;group&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;mode&quot;: &quot;0644&quot;,</span><br><span class="line">    &quot;owner&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;path&quot;: &quot;/data/ansible.cfg&quot;,</span><br><span class="line">    &quot;size&quot;: 20012,</span><br><span class="line">    &quot;state&quot;: &quot;file&quot;,</span><br><span class="line">    &quot;uid&quot;: 0</span><br><span class="line">&#125;</span><br><span class="line">192.168.101.201 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;changed&quot;: false,</span><br><span class="line">    &quot;checksum&quot;: &quot;a2a782df5d7bd49afb0971fc6be21cd825daaaa3&quot;,</span><br><span class="line">    &quot;dest&quot;: &quot;/data/ansible.cfg&quot;,</span><br><span class="line">    &quot;gid&quot;: 0,</span><br><span class="line">    &quot;group&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;mode&quot;: &quot;0644&quot;,</span><br><span class="line">    &quot;owner&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;path&quot;: &quot;/data/ansible.cfg&quot;,</span><br><span class="line">    &quot;size&quot;: 20012,</span><br><span class="line">    &quot;state&quot;: &quot;file&quot;,</span><br><span class="line">    &quot;uid&quot;: 0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>给定内容生成文件，并制定权限</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible web -m copy -a &#x27;content=&quot;I love you&quot; dest=/data/love mode=666&#x27;</span><br><span class="line">192.168.101.202 | CHANGED =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;changed&quot;: true,</span><br><span class="line">    &quot;checksum&quot;: &quot;ce48c9870c7ae19796438aed65458c8bdc335157&quot;,</span><br><span class="line">    &quot;dest&quot;: &quot;/data/love&quot;,</span><br><span class="line">    &quot;gid&quot;: 0,</span><br><span class="line">    &quot;group&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;md5sum&quot;: &quot;e4f58a805a6e1fd0f6bef58c86f9ceb3&quot;,</span><br><span class="line">    &quot;mode&quot;: &quot;0666&quot;,</span><br><span class="line">    &quot;owner&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;size&quot;: 10,</span><br><span class="line">    &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1631174440.548185-142417634763846/source&quot;,</span><br><span class="line">    &quot;state&quot;: &quot;file&quot;,</span><br><span class="line">    &quot;uid&quot;: 0</span><br><span class="line">&#125;</span><br><span class="line">192.168.101.201 | CHANGED =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;changed&quot;: true,</span><br><span class="line">    &quot;checksum&quot;: &quot;ce48c9870c7ae19796438aed65458c8bdc335157&quot;,</span><br><span class="line">    &quot;dest&quot;: &quot;/data/love&quot;,</span><br><span class="line">    &quot;gid&quot;: 0,</span><br><span class="line">    &quot;group&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;md5sum&quot;: &quot;e4f58a805a6e1fd0f6bef58c86f9ceb3&quot;,</span><br><span class="line">    &quot;mode&quot;: &quot;0666&quot;,</span><br><span class="line">    &quot;owner&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;size&quot;: 10,</span><br><span class="line">    &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1631174440.5443904-137441252807840/source&quot;,</span><br><span class="line">    &quot;state&quot;: &quot;file&quot;,</span><br><span class="line">    &quot;uid&quot;: 0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们现在去查看一下我们生成的文件及其权限：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible web -m shell -a &#x27;ls -la /data/&#x27;</span><br><span class="line">192.168.101.202 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">total 24</span><br><span class="line">-rw-r--r--   1 root root 20012 Sep  9 15:54 ansible.cfg</span><br><span class="line">-rw-rw-rw-   1 root root    10 Sep  9 16:00 love</span><br><span class="line"></span><br><span class="line">192.168.101.201 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">total 230280</span><br><span class="line">-rw-r--r--   1 root root     20012 Sep  9 15:54 ansible.cfg</span><br><span class="line">-rw-rw-rw-   1 root root        10 Sep  9 16:00 love</span><br></pre></td></tr></table></figure>

<p>可以看出我们的love文件已经生成，并且权限为666</p>
<ul>
<li>关于覆盖</li>
</ul>
<p>我们把文件的内容修改一下，然后选择覆盖备份：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible web -m copy -a &#x27;content=&quot;I love you today&quot; backup=yes dest=/data/love mode=666&#x27;</span><br><span class="line">192.168.101.201 | CHANGED =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;backup_file&quot;: &quot;/data/love.1710731.2021-09-09@16:08:11~&quot;,</span><br><span class="line">    &quot;changed&quot;: true,</span><br><span class="line">    &quot;checksum&quot;: &quot;aae6d5443c11825389059f97953a5596f52472d0&quot;,</span><br><span class="line">    &quot;dest&quot;: &quot;/data/love&quot;,</span><br><span class="line">    &quot;gid&quot;: 0,</span><br><span class="line">    &quot;group&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;md5sum&quot;: &quot;ca125268f92d23fbb2ba11b5033d97a6&quot;,</span><br><span class="line">    &quot;mode&quot;: &quot;0666&quot;,</span><br><span class="line">    &quot;owner&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;size&quot;: 16,</span><br><span class="line">    &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1631174889.8834162-86186609378458/source&quot;,</span><br><span class="line">    &quot;state&quot;: &quot;file&quot;,</span><br><span class="line">    &quot;uid&quot;: 0</span><br><span class="line">&#125;</span><br><span class="line">192.168.101.202 | CHANGED =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;backup_file&quot;: &quot;/data/love.2458311.2021-09-09@16:08:11~&quot;,</span><br><span class="line">    &quot;changed&quot;: true,</span><br><span class="line">    &quot;checksum&quot;: &quot;aae6d5443c11825389059f97953a5596f52472d0&quot;,</span><br><span class="line">    &quot;dest&quot;: &quot;/data/love&quot;,</span><br><span class="line">    &quot;gid&quot;: 0,</span><br><span class="line">    &quot;group&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;md5sum&quot;: &quot;ca125268f92d23fbb2ba11b5033d97a6&quot;,</span><br><span class="line">    &quot;mode&quot;: &quot;0666&quot;,</span><br><span class="line">    &quot;owner&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;size&quot;: 16,</span><br><span class="line">    &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1631174889.8911483-24337496953154/source&quot;,</span><br><span class="line">    &quot;state&quot;: &quot;file&quot;,</span><br><span class="line">    &quot;uid&quot;: 0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>现在我们可以去查看一下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible web -m shell -a &#x27;ls -la /data&#x27;</span><br><span class="line">192.168.101.201 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">total 230288</span><br><span class="line">-rw-r--r--   1 root root     20012 Sep  9 15:54 ansible.cfg</span><br><span class="line">-rw-rw-rw-   1 root root        16 Sep  9 16:08 love</span><br><span class="line">-rw-rw-rw-   1 root root        10 Sep  9 16:00 love.1710731.2021-09-09@16:08:11~</span><br><span class="line"></span><br><span class="line">192.168.101.202 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">total 32</span><br><span class="line">-rw-r--r--   1 root root 20012 Sep  9 15:54 ansible.cfg</span><br><span class="line">-rw-rw-rw-   1 root root    16 Sep  9 16:08 love</span><br><span class="line">-rw-rw-rw-   1 root root    10 Sep  9 16:00 love.2458311.2021-09-09@16:08:11~</span><br></pre></td></tr></table></figure>

<p>可以看出，我们的源文件已经被备份，我们还可以查看一下<code>love</code>文件的内容：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible web -m shell -a &#x27;cat /data/love&#x27;</span><br><span class="line">192.168.101.201 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">I love you today</span><br><span class="line"></span><br><span class="line">192.168.101.202 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">I love you today</span><br></pre></td></tr></table></figure>

<p>证明，这正是我们新导入的文件的内容。</p>
<h3 id="file模块">1.2.5. file模块</h3><blockquote>
<p>该模块主要用于设置文件的属性，比如创建文件、创建链接文件、删除文件等。<br>下面是一些常见的命令：</p>
<p><code>force</code>　　#需要在两种情况下强制创建软链接，一种是源文件不存在，但之后会建立的情况下；另一种是目标软链接已存在，需要先取消之前的软链，然后创建新的软链，有两个选项：yes|no<br><code>group</code>　　#定义文件/目录的属组。后面可以加上<code>mode</code>：定义文件/目录的权限<br><code>owner</code>　　#定义文件/目录的属主。后面必须跟上<code>path</code>：定义文件/目录的路径<br><code>recurse</code>　　#递归设置文件的属性，只对目录有效，后面跟上<code>src</code>：被链接的源文件路径，只应用于<code>state=link</code>的情况<br><code>dest</code>　　#被链接到的路径，只应用于<code>state=link</code>的情况<br><code>state</code>　　#状态，有以下选项：</p>
<blockquote>
<p><code>directory</code>：如果目录不存在，就创建目录<br><code>file</code>：即使文件不存在，也不会被创建<br><code>link</code>：创建软链接<br><code>hard</code>：创建硬链接<br><code>touch</code>：如果文件不存在，则会创建一个新的文件，如果文件或目录已存在，则更新其最后修改时间<br><code>absent</code>：删除目录、文件或者取消链接文件</p>
</blockquote>
</blockquote>
<p>用法举例如下：</p>
<ul>
<li>创建目录</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible web -m file -a &#x27;path=/data/app state=directory&#x27;</span><br><span class="line">192.168.101.202 | CHANGED =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;changed&quot;: true,</span><br><span class="line">    &quot;gid&quot;: 0,</span><br><span class="line">    &quot;group&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;mode&quot;: &quot;0755&quot;,</span><br><span class="line">    &quot;owner&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;path&quot;: &quot;/data/app&quot;,</span><br><span class="line">    &quot;size&quot;: 6,</span><br><span class="line">    &quot;state&quot;: &quot;directory&quot;,</span><br><span class="line">    &quot;uid&quot;: 0</span><br><span class="line">&#125;</span><br><span class="line">192.168.101.201 | CHANGED =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;changed&quot;: true,</span><br><span class="line">    &quot;gid&quot;: 0,</span><br><span class="line">    &quot;group&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;mode&quot;: &quot;0755&quot;,</span><br><span class="line">    &quot;owner&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;path&quot;: &quot;/data/app&quot;,</span><br><span class="line">    &quot;size&quot;: 6,</span><br><span class="line">    &quot;state&quot;: &quot;directory&quot;,</span><br><span class="line">    &quot;uid&quot;: 0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们可以查看一下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible web -m shell -a &#x27;ls -l /data&#x27;</span><br><span class="line">192.168.101.202 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">total 32</span><br><span class="line">drwxr-xr-x 2 root root     6 Sep  9 16:13 app</span><br><span class="line"></span><br><span class="line">192.168.101.201 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">total 230288</span><br><span class="line">drwxr-xr-x 2 root root         6 Sep  9 16:13 app</span><br></pre></td></tr></table></figure>

<p>可以看出，我们的目录已经创建完成</p>
<ul>
<li>创建链接文件</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible web -m file -a &#x27;path=/data/hhh.cfg src=ansible.cfg state=link&#x27;</span><br><span class="line">192.168.101.202 | CHANGED =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;changed&quot;: true,</span><br><span class="line">    &quot;dest&quot;: &quot;/data/hhh.cfg&quot;,</span><br><span class="line">    &quot;gid&quot;: 0,</span><br><span class="line">    &quot;group&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;mode&quot;: &quot;0777&quot;,</span><br><span class="line">    &quot;owner&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;size&quot;: 11,</span><br><span class="line">    &quot;src&quot;: &quot;ansible.cfg&quot;,</span><br><span class="line">    &quot;state&quot;: &quot;link&quot;,</span><br><span class="line">    &quot;uid&quot;: 0</span><br><span class="line">&#125;</span><br><span class="line">192.168.101.201 | CHANGED =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;changed&quot;: true,</span><br><span class="line">    &quot;dest&quot;: &quot;/data/hhh.cfg&quot;,</span><br><span class="line">    &quot;gid&quot;: 0,</span><br><span class="line">    &quot;group&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;mode&quot;: &quot;0777&quot;,</span><br><span class="line">    &quot;owner&quot;: &quot;root&quot;,</span><br><span class="line">    &quot;size&quot;: 11,</span><br><span class="line">    &quot;src&quot;: &quot;ansible.cfg&quot;,</span><br><span class="line">    &quot;state&quot;: &quot;link&quot;,</span><br><span class="line">    &quot;uid&quot;: 0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们可以去查看一下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible web -m shell -a &#x27;ls -l /data&#x27;</span><br><span class="line">192.168.101.202 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">total 32</span><br><span class="line">-rw-r--r-- 1 root root 20012 Sep  9 15:54 ansible.cfg</span><br><span class="line">lrwxrwxrwx 1 root root    11 Sep  9 16:19 hhh.cfg -&gt; ansible.cfg</span><br><span class="line"></span><br><span class="line">192.168.101.201 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">total 230288</span><br><span class="line">-rw-r--r-- 1 root root     20012 Sep  9 15:54 ansible.cfg</span><br><span class="line">lrwxrwxrwx 1 root root        11 Sep  9 16:19 hhh.cfg -&gt; ansible.cfg</span><br></pre></td></tr></table></figure>

<p>我们的链接文件已经创建成功</p>
<ul>
<li>删除文件</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible web -m file -a &#x27;path=/data/ansible.cfg state=absent&#x27;</span><br><span class="line">192.168.101.201 | CHANGED =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;changed&quot;: true,</span><br><span class="line">    &quot;path&quot;: &quot;/data/ansible.cfg&quot;,</span><br><span class="line">    &quot;state&quot;: &quot;absent&quot;</span><br><span class="line">&#125;</span><br><span class="line">192.168.101.202 | CHANGED =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;changed&quot;: true,</span><br><span class="line">    &quot;path&quot;: &quot;/data/ansible.cfg&quot;,</span><br><span class="line">    &quot;state&quot;: &quot;absent&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们可以查看一下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# ansible web -m shell -a &#x27;ls /data/ansible.cfg&#x27;</span><br><span class="line">192.168.101.201 | FAILED | rc=2 &gt;&gt;</span><br><span class="line">ls: cannot access &#x27;/data/ansible.cfg&#x27;: No such file or directorynon-zero return code</span><br><span class="line"></span><br><span class="line">192.168.101.202 | FAILED | rc=2 &gt;&gt;</span><br><span class="line">ls: cannot access &#x27;/data/ansible.cfg&#x27;: No such file or directorynon-zero return code</span><br></pre></td></tr></table></figure>

<p>已经没有这个文件</p>
<h3 id="fetch">1.2.6. fetch</h3><p>该模块用于从远程某主机获取（复制）文件到本地。<br>有两个选项：</p>
<blockquote>
<p><code>dest</code>：用来存放文件的目录<br><code>src</code>：在远程拉取的文件，并且必须是一个<strong>file</strong>，不能是<strong>目录</strong></p>
</blockquote>
<p>具体举例如下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@mgmt2 ansible]# ansible web -m fetch -a &#x27;src=/data/love dest=/data&#x27;</span><br><span class="line">192.168.101.202 | CHANGED =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: true,</span><br><span class="line">    &quot;checksum&quot;: &quot;aae6d5443c11825389059f97953a5596f52472d0&quot;,</span><br><span class="line">    &quot;dest&quot;: &quot;/data/192.168.101.202/data/love&quot;,</span><br><span class="line">    &quot;md5sum&quot;: &quot;ca125268f92d23fbb2ba11b5033d97a6&quot;,</span><br><span class="line">    &quot;remote_checksum&quot;: &quot;aae6d5443c11825389059f97953a5596f52472d0&quot;,</span><br><span class="line">    &quot;remote_md5sum&quot;: null</span><br><span class="line">&#125;</span><br><span class="line">192.168.101.201 | CHANGED =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: true,</span><br><span class="line">    &quot;checksum&quot;: &quot;aae6d5443c11825389059f97953a5596f52472d0&quot;,</span><br><span class="line">    &quot;dest&quot;: &quot;/data/192.168.101.201/data/love&quot;,</span><br><span class="line">    &quot;md5sum&quot;: &quot;ca125268f92d23fbb2ba11b5033d97a6&quot;,</span><br><span class="line">    &quot;remote_checksum&quot;: &quot;aae6d5443c11825389059f97953a5596f52472d0&quot;,</span><br><span class="line">    &quot;remote_md5sum&quot;: null</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们可以在本机上查看一下文件是否复制成功。要注意，文件保存的路径是我们设置的接收目录下的<code>被管制主机ip</code>目录下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ansible]# cd /data/</span><br><span class="line">[root@mgmt2 data]# ls</span><br><span class="line">192.168.101.201  192.168.101.202</span><br><span class="line">[root@mgmt2 data]# cd 192.168.101.201</span><br><span class="line">[root@mgmt2 192.168.101.201]# ls</span><br><span class="line">data</span><br><span class="line">[root@mgmt2 192.168.101.201]# cd data/</span><br><span class="line">[root@mgmt2 data]# ls</span><br><span class="line">love</span><br><span class="line">[root@mgmt2 data]# pwd</span><br><span class="line">/data/192.168.101.201/data</span><br></pre></td></tr></table></figure>



<h3 id="cron模块">1.2.7. cron模块</h3><p>该模块适用于管理<code>cron</code>计划任务的。<br>其使用的语法跟我们的<code>crontab</code>文件中的语法一致，同时，可以指定以下选项：</p>
<blockquote>
<p><code>day=</code> #日应该运行的工作( 1-31, *, */2, )<br><code>hour=</code> # 小时 ( 0-23, *, */2, )<br><code>minute=</code> #分钟( 0-59, *, */2, )<br><code>month=</code> # 月( 1-12, *, /2, )<br><code>weekday=</code> # 周 ( 0-6 for Sunday-Saturday,, )<br><code>job=</code> #指明运行的命令是什么<br><code>name=</code> #定时任务描述<br><code>reboot</code> # 任务在重启时运行，不建议使用，建议使用special_time<br><code>special_time</code> #特殊的时间范围，参数：reboot（重启时），annually（每年），monthly（每月），weekly（每周），daily（每天），hourly（每小时）<br><code>state</code> #指定状态，present表示添加定时任务，也是默认设置，absent表示删除定时任务<br><code>user</code> # 以哪个用户的身份执行</p>
</blockquote>
<p>举例如下</p>
<ul>
<li>添加计划任务</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@mgmt2 ~]# ansible web -m cron -a &#x27;name=&quot;ntp update every 5 min&quot; minute=*/5 job=&quot;/sbin/ntpdate 172.17.0.1 &amp;&gt; /dev/null&quot;&#x27;</span><br><span class="line">192.168.101.202 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: true, </span><br><span class="line">    &quot;envs&quot;: [], </span><br><span class="line">    &quot;jobs&quot;: [</span><br><span class="line">        &quot;ntp update every 5 min&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">192.168.101.201 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: true, </span><br><span class="line">    &quot;envs&quot;: [], </span><br><span class="line">    &quot;jobs&quot;: [</span><br><span class="line">        &quot;ntp update every 5 min&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们可以去查看一下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@server ~]# ansible web -m shell -a &#x27;crontab -l&#x27;</span><br><span class="line">192.168.37.122 | SUCCESS | rc=0 &gt;&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash">Ansible: ntp update every 5 min</span></span><br><span class="line">*/5 * * * * /sbin/ntpdate 172.17.0.1 &amp;&gt; /dev/null</span><br><span class="line"></span><br><span class="line">192.168.37.133 | SUCCESS | rc=0 &gt;&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash">Ansible: ntp update every 5 min</span></span><br><span class="line">*/5 * * * * /sbin/ntpdate 172.17.0.1 &amp;&gt; /dev/null</span><br></pre></td></tr></table></figure>

<p>可以看出，我们的计划任务已经设置成功了。</p>
]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s面试题</title>
    <url>/p/30445.html</url>
    <content><![CDATA[<p><escape><span id="more"></span></escape></p>
<h3 id="简述ETCD及其特点？">0.0.1. 简述ETCD及其特点？</h3><p>etcd 是 CoreOS 团队发起的开源项目，是一个管理配置信息和服务发现（service discovery）的项目，它的目标是构建一个高可用的分布式键值（key-value）数据库，基于 Go 语言实现。</p>
<p>特点：</p>
<ul>
<li><p>简单：支持 REST 风格的 HTTP+JSON API</p>
</li>
<li><p>安全：支持 HTTPS 方式的访问</p>
</li>
<li><p>快速：支持并发 1k/s 的写操作</p>
</li>
<li><p>可靠：支持分布式结构，基于 Raft 的一致性算法，Raft 是一套通过选举主节点来实现分布式系统一致性的算法。</p>
</li>
</ul>
<h3 id="简述ETCD适应的场景？">0.0.2. 简述ETCD适应的场景？</h3><p>etcd基于其优秀的特点，可广泛的应用于以下场景：</p>
<ul>
<li><p>服务发现(Service Discovery)：服务发现主要解决在同一个分布式集群中的进程或服务，要如何才能找到对方并建立连接。本质上来说，服务发现就是想要了解集群中是否有进程在监听udp或tcp端口，并且通过名字就可以查找和连接。</p>
</li>
<li><p>消息发布与订阅：在分布式系统中，最适用的一种组件间通信方式就是消息发布与订阅。即构建一个配置共享中心，数据提供者在这个配置中心发布消息，而消息使用者则订阅他们关心的主题，一旦主题有消息发布，就会实时通知订阅者。通过这种方式可以做到分布式系统配置的集中式管理与动态更新。应用中用到的一些配置信息放到etcd上进行集中管理。</p>
</li>
<li><p>负载均衡：在分布式系统中，为了保证服务的高可用以及数据的一致性，通常都会把数据和服务部署多份，以此达到对等服务，即使其中的某一个服务失效了，也不影响使用。etcd本身分布式架构存储的信息访问支持负载均衡。etcd集群化以后，每个etcd的核心节点都可以处理用户的请求。所以，把数据量小但是访问频繁的消息数据直接存储到etcd中也可以实现负载均衡的效果。</p>
</li>
<li><p>分布式通知与协调：与消息发布和订阅类似，都用到了etcd中的Watcher机制，通过注册与异步通知机制，实现分布式环境下不同系统之间的通知与协调，从而对数据变更做到实时处理。</p>
</li>
<li><p>分布式锁：因为etcd使用Raft算法保持了数据的强一致性，某次操作存储到集群中的值必然是全局一致的，所以很容易实现分布式锁。锁服务有两种使用方式，一是保持独占，二是控制时序。</p>
</li>
<li><p>集群监控与Leader竞选：通过etcd来进行监控实现起来非常简单并且实时性强。</p>
</li>
</ul>
<h3 id="简述什么是Kubernetes？">0.0.3. 简述什么是Kubernetes？</h3><p>Kubernetes是一个全新的基于容器技术的分布式系统支撑平台。是Google开源的容器集群管理系统（谷歌内部:Borg）。在Docker技术的基础上，为容器化的应用提供部署运行、资源调度、服务发现和动态伸缩等一系列完整功能，提高了大规模容器集群管理的便捷性。并且具有完备的集群管理能力，多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和发现机制、內建智能负载均衡器、强大的故障发现和自我修复能力、服务滚动升级和在线扩容能力、可扩展的资源自动调度机制以及多粒度的资源配额管理能力。</p>
<h3 id="简述Kubernetes和Docker的关系？">0.0.4. 简述Kubernetes和Docker的关系？</h3><p>Docker 提供容器的生命周期管理和，Docker 镜像构建运行时容器。它的主要优点是将将软件/应用程序运行所需的设置和依赖项打包到一个容器中，从而实现了可移植性等优点。</p>
<p>Kubernetes 用于关联和编排在多个主机上运行的容器。</p>
<h3 id="简述Kubernetes中什么是Minikube、Kubectl、Kubelet？">0.0.5. 简述Kubernetes中什么是Minikube、Kubectl、Kubelet？</h3><p>Minikube 是一种可以在本地轻松运行一个单节点 Kubernetes 群集的工具。</p>
<p>Kubectl 是一个命令行工具，可以使用该工具控制Kubernetes集群管理器，如检查群集资源，创建、删除和更新组件，查看应用程序。</p>
<p>Kubelet 是一个代理服务，它在每个节点上运行，并使从服务器与主服务器通信。</p>
<h3 id="简述Kubernetes常见的部署方式？">0.0.6. 简述Kubernetes常见的部署方式？</h3><p>常见的Kubernetes部署方式有：</p>
<ul>
<li><p>kubeadm：也是推荐的一种部署方式；</p>
</li>
<li><p>二进制：</p>
</li>
<li><p>minikube：在本地轻松运行一个单节点 Kubernetes 群集的工具。</p>
</li>
</ul>
<h3 id="简述Kubernetes如何实现集群管理？">0.0.7. 简述Kubernetes如何实现集群管理？</h3><p>在集群管理方面，Kubernetes将集群中的机器划分为一个Master节点和一群工作节点Node。其中，在Master节点运行着集群管理相关的一组进程kube-apiserver、kube-controller-manager和kube-scheduler，这些进程实现了整个集群的资源管理、Pod调度、弹性伸缩、安全控制、系统监控和纠错等管理能力，并且都是全自动完成的。</p>
<h3 id="简述Kubernetes的优势、适应场景及其特点？">0.0.8. 简述Kubernetes的优势、适应场景及其特点？</h3><p>Kubernetes作为一个完备的分布式系统支撑平台，其主要优势：</p>
<ul>
<li><p>容器编排</p>
</li>
<li><p>轻量级</p>
</li>
<li><p>开源</p>
</li>
<li><p>弹性伸缩</p>
</li>
<li><p>负载均衡</p>
</li>
</ul>
<p>Kubernetes常见场景：</p>
<ul>
<li><p>快速部署应用</p>
</li>
<li><p>快速扩展应用</p>
</li>
<li><p>无缝对接新的应用功能</p>
</li>
<li><p>节省资源，优化硬件资源的使用</p>
</li>
</ul>
<p>Kubernetes相关特点：</p>
<ul>
<li><p>可移植: 支持公有云、私有云、混合云、多重云（multi-cloud）。</p>
</li>
<li><p>可扩展: 模块化,、插件化、可挂载、可组合。</p>
</li>
<li><p>自动化: 自动部署、自动重启、自动复制、自动伸缩/扩展。</p>
</li>
</ul>
<h3 id="简述Kubernetes的缺点或当前的不足之处？">0.0.9. 简述Kubernetes的缺点或当前的不足之处？</h3><p>Kubernetes当前存在的缺点（不足）如下：</p>
<ul>
<li><p>安装过程和配置相对困难复杂。</p>
</li>
<li><p>管理服务相对繁琐。</p>
</li>
<li><p>运行和编译需要很多时间。</p>
</li>
<li><p>它比其他替代品更昂贵。</p>
</li>
<li><p>对于简单的应用程序来说，可能不需要涉及Kubernetes即可满足。</p>
</li>
</ul>
<h3 id="简述Kubernetes相关基础概念？">0.0.10. 简述Kubernetes相关基础概念？</h3><ul>
<li><p>master：k8s集群的管理节点，负责管理集群，提供集群的资源数据访问入口。拥有Etcd存储服务（可选），运行Api Server进程，Controller Manager服务进程及Scheduler服务进程。</p>
</li>
<li><p>node（worker）：Node（worker）是Kubernetes集群架构中运行Pod的服务节点，是Kubernetes集群操作的单元，用来承载被分配Pod的运行，是Pod运行的宿主机。运行docker eninge服务，守护进程kunelet及负载均衡器kube-proxy。</p>
</li>
<li><p>pod：运行于Node节点上，若干相关容器的组合。Pod内包含的容器运行在同一宿主机上，使用相同的网络命名空间、IP地址和端口，能够通过localhost进行通信。Pod是Kurbernetes进行创建、调度和管理的最小单位，它提供了比容器更高层次的抽象，使得部署和管理更加灵活。一个Pod可以包含一个容器或者多个相关容器。</p>
</li>
<li><p>label：Kubernetes中的Label实质是一系列的Key/Value键值对，其中key与value可自定义。Label可以附加到各种资源对象上，如Node、Pod、Service、RC等。一个资源对象可以定义任意数量的Label，同一个Label也可以被添加到任意数量的资源对象上去。Kubernetes通过Label Selector（标签选择器）查询和筛选资源对象。</p>
</li>
<li><p>Replication Controller：Replication Controller用来管理Pod的副本，保证集群中存在指定数量的Pod副本。集群中副本的数量大于指定数量，则会停止指定数量之外的多余容器数量。反之，则会启动少于指定数量个数的容器，保证数量不变。Replication Controller是实现弹性伸缩、动态扩容和滚动升级的核心。</p>
</li>
<li><p>Deployment：Deployment在内部使用了RS来实现目的，Deployment相当于RC的一次升级，其最大的特色为可以随时获知当前Pod的部署进度。</p>
</li>
<li><p>HPA（Horizontal Pod Autoscaler）：Pod的横向自动扩容，也是Kubernetes的一种资源，通过追踪分析RC控制的所有Pod目标的负载变化情况，来确定是否需要针对性的调整Pod副本数量。</p>
</li>
<li><p>Service：Service定义了Pod的逻辑集合和访问该集合的策略，是真实服务的抽象。Service提供了一个统一的服务访问入口以及服务代理和发现机制，关联多个相同Label的Pod，用户不需要了解后台Pod是如何运行。</p>
</li>
<li><p>Volume：Volume是Pod中能够被多个容器访问的共享目录，Kubernetes中的Volume是定义在Pod上，可以被一个或多个Pod中的容器挂载到某个目录下。</p>
</li>
<li><p>Namespace：Namespace用于实现多租户的资源隔离，可将集群内部的资源对象分配到不同的Namespace中，形成逻辑上的不同项目、小组或用户组，便于不同的Namespace在共享使用整个集群的资源的同时还能被分别管理。</p>
</li>
</ul>
<h3 id="简述Kubernetes集群相关组件？">0.0.11. 简述Kubernetes集群相关组件？</h3><p>Kubernetes Master控制组件，调度管理整个系统（集群），包含如下组件:</p>
<ul>
<li><p>Kubernetes API Server：作为Kubernetes系统的入口，其封装了核心对象的增删改查操作，以RESTful API接口方式提供给外部客户和内部组件调用，集群内各个功能模块之间数据交互和通信的中心枢纽。</p>
</li>
<li><p>Kubernetes Scheduler：为新建立的Pod进行节点(node)选择(即分配机器)，负责集群的资源调度。</p>
</li>
<li><p>Kubernetes Controller：负责执行各种控制器，目前已经提供了很多控制器来保证Kubernetes的正常运行。</p>
</li>
<li><p>Replication Controller：管理维护Replication Controller，关联Replication Controller和Pod，保证Replication Controller定义的副本数量与实际运行Pod数量一致。</p>
</li>
<li><p>Node Controller：管理维护Node，定期检查Node的健康状态，标识出(失效|未失效)的Node节点。</p>
</li>
<li><p>Namespace Controller：管理维护Namespace，定期清理无效的Namespace，包括Namesapce下的API对象，比如Pod、Service等。</p>
</li>
<li><p>Service Controller：管理维护Service，提供负载以及服务代理。</p>
</li>
<li><p>EndPoints Controller：管理维护Endpoints，关联Service和Pod，创建Endpoints为Service的后端，当Pod发生变化时，实时更新Endpoints。</p>
</li>
<li><p>Service Account Controller：管理维护Service Account，为每个Namespace创建默认的Service Account，同时为Service Account创建Service Account Secret。</p>
</li>
<li><p>Persistent Volume Controller：管理维护Persistent Volume和Persistent Volume Claim，为新的Persistent Volume Claim分配Persistent Volume进行绑定，为释放的Persistent Volume执行清理回收。</p>
</li>
<li><p>Daemon Set Controller：管理维护Daemon Set，负责创建Daemon Pod，保证指定的Node上正常的运行Daemon Pod。</p>
</li>
<li><p>Deployment Controller：管理维护Deployment，关联Deployment和Replication Controller，保证运行指定数量的Pod。当Deployment更新时，控制实现Replication Controller和Pod的更新。</p>
</li>
<li><p>Job Controller：管理维护Job，为Jod创建一次性任务Pod，保证完成Job指定完成的任务数目</p>
</li>
<li><p>Pod Autoscaler Controller：实现Pod的自动伸缩，定时获取监控数据，进行策略匹配，当满足条件时执行Pod的伸缩动作。</p>
</li>
</ul>
<h3 id="简述Kubernetes-RC的机制？">0.0.12. 简述Kubernetes RC的机制？</h3><p>Replication Controller用来管理Pod的副本，保证集群中存在指定数量的Pod副本。当定义了RC并提交至Kubernetes集群中之后，Master节点上的Controller Manager组件获悉，并同时巡检系统中当前存活的目标Pod，并确保目标Pod实例的数量刚好等于此RC的期望值，若存在过多的Pod副本在运行，系统会停止一些Pod，反之则自动创建一些Pod。</p>
<h3 id="简述Kubernetes-Replica-Set-和-Replication-Controller-之间有什么区别？">0.0.13. 简述Kubernetes Replica Set 和 Replication Controller 之间有什么区别？</h3><p>Replica Set 和 Replication Controller 类似，都是确保在任何给定时间运行指定数量的 Pod 副本。不同之处在于RS 使用基于集合的选择器，而 Replication Controller 使用基于权限的选择器。</p>
<h3 id="简述kube-proxy作用？">0.0.14. 简述kube-proxy作用？</h3><p>kube-proxy 运行在所有节点上，它监听 apiserver 中 service 和 endpoint 的变化情况，创建路由规则以提供服务 IP 和负载均衡功能。简单理解此进程是Service的透明代理兼负载均衡器，其核心功能是将到某个Service的访问请求转发到后端的多个Pod实例上。</p>
<h3 id="简述kube-proxy-iptables原理？">0.0.15. 简述kube-proxy iptables原理？</h3><p>Kubernetes从1.2版本开始，将iptables作为kube-proxy的默认模式。iptables模式下的kube-proxy不再起到Proxy的作用，其核心功能：通过API Server的Watch接口实时跟踪Service与Endpoint的变更信息，并更新对应的iptables规则，Client的请求流量则通过iptables的NAT机制“直接路由”到目标Pod。</p>
<h3 id="简述kube-proxy-ipvs原理？">0.0.16. 简述kube-proxy ipvs原理？</h3><p>IPVS在Kubernetes1.11中升级为GA稳定版。IPVS则专门用于高性能负载均衡，并使用更高效的数据结构（Hash表），允许几乎无限的规模扩张，因此被kube-proxy采纳为最新模式。</p>
<p>在IPVS模式下，使用iptables的扩展ipset，而不是直接调用iptables来生成规则链。iptables规则链是一个线性的数据结构，ipset则引入了带索引的数据结构，因此当规则很多时，也可以很高效地查找和匹配。</p>
<p>可以将ipset简单理解为一个IP（段）的集合，这个集合的内容可以是IP地址、IP网段、端口等，iptables可以直接添加规则对这个“可变的集合”进行操作，这样做的好处在于可以大大减少iptables规则的数量，从而减少性能损耗。</p>
<h3 id="简述kube-proxy-ipvs和iptables的异同？">0.0.17. 简述kube-proxy ipvs和iptables的异同？</h3><p>iptables与IPVS都是基于Netfilter实现的，但因为定位不同，二者有着本质的差别：iptables是为防火墙而设计的；IPVS则专门用于高性能负载均衡，并使用更高效的数据结构（Hash表），允许几乎无限的规模扩张。</p>
<p>与iptables相比，IPVS拥有以下明显优势：</p>
<ul>
<li><p>1、为大型集群提供了更好的可扩展性和性能；</p>
</li>
<li><p>2、支持比iptables更复杂的复制均衡算法（最小负载、最少连接、加权等）；</p>
</li>
<li><p>3、支持服务器健康检查和连接重试等功能；</p>
</li>
<li><p>4、可以动态修改ipset的集合，即使iptables的规则正在使用这个集合。</p>
</li>
</ul>
<h3 id="简述Kubernetes中什么是静态Pod？">0.0.18. 简述Kubernetes中什么是静态Pod？</h3><p>静态pod是由kubelet进行管理的仅存在于特定Node的Pod上，他们不能通过API Server进行管理，无法与ReplicationController、Deployment或者DaemonSet进行关联，并且kubelet无法对他们进行健康检查。静态Pod总是由kubelet进行创建，并且总是在kubelet所在的Node上运行。</p>
<h3 id="简述Kubernetes中Pod可能位于的状态？">0.0.19. 简述Kubernetes中Pod可能位于的状态？</h3><ul>
<li><p>Pending：API Server已经创建该Pod，且Pod内还有一个或多个容器的镜像没有创建，包括正在下载镜像的过程。</p>
</li>
<li><p>Running：Pod内所有容器均已创建，且至少有一个容器处于运行状态、正在启动状态或正在重启状态。</p>
</li>
<li><p>Succeeded：Pod内所有容器均成功执行退出，且不会重启。</p>
</li>
<li><p>Failed：Pod内所有容器均已退出，但至少有一个容器退出为失败状态。</p>
</li>
<li><p>Unknown：由于某种原因无法获取该Pod状态，可能由于网络通信不畅导致。</p>
</li>
</ul>
<h3 id="简述Kubernetes创建一个Pod的主要流程？">0.0.20. 简述Kubernetes创建一个Pod的主要流程？</h3><p>Kubernetes中创建一个Pod涉及多个组件之间联动，主要流程如下：</p>
<ul>
<li><p>1、客户端提交Pod的配置信息（可以是yaml文件定义的信息）到kube-apiserver。</p>
</li>
<li><p>2、Apiserver收到指令后，通知给controller-manager创建一个资源对象。</p>
</li>
<li><p>3、Controller-manager通过api-server将pod的配置信息存储到ETCD数据中心中。</p>
</li>
<li><p>4、Kube-scheduler检测到pod信息会开始调度预选，会先过滤掉不符合Pod资源配置要求的节点，然后开始调度调优，主要是挑选出更适合运行pod的节点，然后将pod的资源配置单发送到node节点上的kubelet组件上。</p>
</li>
<li><p>5、Kubelet根据scheduler发来的资源配置单运行pod，运行成功后，将pod的运行信息返回给scheduler，scheduler将返回的pod运行状况的信息存储到etcd数据中心。</p>
</li>
</ul>
<h3 id="简述Kubernetes中Pod的重启策略？">0.0.21. 简述Kubernetes中Pod的重启策略？</h3><p>Pod重启策略（RestartPolicy）应用于Pod内的所有容器，并且仅在Pod所处的Node上由kubelet进行判断和重启操作。当某个容器异常退出或者健康检查失败时，kubelet将根据RestartPolicy的设置来进行相应操作。</p>
<p>Pod的重启策略包括Always、OnFailure和Never，默认值为Always。</p>
<ul>
<li><p>Always：当容器失效时，由kubelet自动重启该容器；</p>
</li>
<li><p>OnFailure：当容器终止运行且退出码不为0时，由kubelet自动重启该容器；</p>
</li>
<li><p>Never：不论容器运行状态如何，kubelet都不会重启该容器。</p>
</li>
</ul>
<p>同时Pod的重启策略与控制方式关联，当前可用于管理Pod的控制器包括ReplicationController、Job、DaemonSet及直接管理kubelet管理（静态Pod）。</p>
<p>不同控制器的重启策略限制如下：</p>
<ul>
<li><p>RC和DaemonSet：必须设置为Always，需要保证该容器持续运行；</p>
</li>
<li><p>Job：OnFailure或Never，确保容器执行完成后不再重启；</p>
</li>
<li><p>kubelet：在Pod失效时重启，不论将RestartPolicy设置为何值，也不会对Pod进行健康检查。</p>
</li>
</ul>
<h3 id="简述Kubernetes中Pod的健康检查方式？">0.0.22. 简述Kubernetes中Pod的健康检查方式？</h3><p>对Pod的健康检查可以通过两类探针来检查：LivenessProbe和ReadinessProbe。</p>
<ul>
<li><p>LivenessProbe探针：用于判断容器是否存活（running状态），如果LivenessProbe探针探测到容器不健康，则kubelet将杀掉该容器，并根据容器的重启策略做相应处理。若一个容器不包含LivenessProbe探针，kubelet认为该容器的LivenessProbe探针返回值用于是“Success”。</p>
</li>
<li><p>ReadineeProbe探针：用于判断容器是否启动完成（ready状态）。如果ReadinessProbe探针探测到失败，则Pod的状态将被修改。Endpoint Controller将从Service的Endpoint中删除包含该容器所在Pod的Eenpoint。</p>
</li>
<li><p>startupProbe探针：启动检查机制，应用一些启动缓慢的业务，避免业务长时间启动而被上面两类探针kill掉。</p>
</li>
</ul>
<h3 id="简述Kubernetes-Pod的LivenessProbe探针的常见方式？">0.0.23. 简述Kubernetes Pod的LivenessProbe探针的常见方式？</h3><p>kubelet定期执行LivenessProbe探针来诊断容器的健康状态，通常有以下三种方式：</p>
<ul>
<li><p>ExecAction：在容器内执行一个命令，若返回码为0，则表明容器健康。</p>
</li>
<li><p>TCPSocketAction：通过容器的IP地址和端口号执行TCP检查，若能建立TCP连接，则表明容器健康。</p>
</li>
<li><p>HTTPGetAction：通过容器的IP地址、端口号及路径调用HTTP Get方法，若响应的状态码大于等于200且小于400，则表明容器健康。</p>
</li>
</ul>
<h3 id="简述Kubernetes-Pod的常见调度方式？">0.0.24. 简述Kubernetes Pod的常见调度方式？</h3><p>Kubernetes中，Pod通常是容器的载体，主要有如下常见调度方式：</p>
<ul>
<li><p>Deployment或RC：该调度策略主要功能就是自动部署一个容器应用的多份副本，以及持续监控副本的数量，在集群内始终维持用户指定的副本数量。</p>
</li>
<li><p>NodeSelector：定向调度，当需要手动指定将Pod调度到特定Node上，可以通过Node的标签（Label）和Pod的nodeSelector属性相匹配。</p>
</li>
<li><p>NodeAffinity亲和性调度：亲和性调度机制极大的扩展了Pod的调度能力，目前有两种节点亲和力表达：</p>
</li>
<li><p>requiredDuringSchedulingIgnoredDuringExecution：硬规则，必须满足指定的规则，调度器才可以调度Pod至Node上（类似nodeSelector，语法不同）。</p>
</li>
<li><p>preferredDuringSchedulingIgnoredDuringExecution：软规则，优先调度至满足的Node的节点，但不强求，多个优先级规则还可以设置权重值。</p>
</li>
<li><p>Taints和Tolerations（污点和容忍）：</p>
</li>
<li><p>Taint：使Node拒绝特定Pod运行；</p>
</li>
<li><p>Toleration：为Pod的属性，表示Pod能容忍（运行）标注了Taint的Node。</p>
</li>
</ul>
<h3 id="简述Kubernetes初始化容器（init-container）？">0.0.25. 简述Kubernetes初始化容器（init container）？</h3><p>init container的运行方式与应用容器不同，它们必须先于应用容器执行完成，当设置了多个init container时，将按顺序逐个运行，并且只有前一个init container运行成功后才能运行后一个init container。当所有init container都成功运行后，Kubernetes才会初始化Pod的各种信息，并开始创建和运行应用容器。</p>
<h3 id="简述Kubernetes-deployment升级过程？">0.0.26. 简述Kubernetes deployment升级过程？</h3><ul>
<li><p>初始创建Deployment时，系统创建了一个ReplicaSet，并按用户的需求创建了对应数量的Pod副本。</p>
</li>
<li><p>当更新Deployment时，系统创建了一个新的ReplicaSet，并将其副本数量扩展到1，然后将旧ReplicaSet缩减为2。</p>
</li>
<li><p>之后，系统继续按照相同的更新策略对新旧两个ReplicaSet进行逐个调整。</p>
</li>
<li><p>最后，新的ReplicaSet运行了对应个新版本Pod副本，旧的ReplicaSet副本数量则缩减为0。</p>
</li>
</ul>
<h3 id="简述Kubernetes-deployment升级策略？">0.0.27. 简述Kubernetes deployment升级策略？</h3><p>在Deployment的定义中，可以通过spec.strategy指定Pod更新的策略，目前支持两种策略：Recreate（重建）和RollingUpdate（滚动更新），默认值为RollingUpdate。</p>
<ul>
<li>Recreate：设置spec.strategy.type=Recreate，表示Deployment在更新Pod时，会先杀掉所有正在运行的Pod，然后创建新的Pod。</li>
<li>RollingUpdate：设置spec.strategy.type=RollingUpdate，表示Deployment会以滚动更新的方式来逐个更新Pod。同时，可以通过设置spec.strategy.rollingUpdate下的两个参数（maxUnavailable和maxSurge）来控制滚动更新的过程。</li>
</ul>
<h3 id="简述Kubernetes-DaemonSet类型的资源特性？">0.0.28. 简述Kubernetes DaemonSet类型的资源特性？</h3><p>DaemonSet资源对象会在每个Kubernetes集群中的节点上运行，并且每个节点只能运行一个pod，这是它和deployment资源对象的最大也是唯一的区别。因此，在定义yaml文件中，不支持定义replicas。</p>
<p>它的一般使用场景如下：</p>
<ul>
<li>在去做每个节点的日志收集工作。</li>
<li>监控每个节点的的运行状态。</li>
</ul>
<h3 id="简述Kubernetes自动扩容机制？">0.0.29. 简述Kubernetes自动扩容机制？</h3><p>Kubernetes使用Horizontal Pod Autoscaler（HPA）的控制器实现基于CPU使用率进行自动Pod扩缩容的功能。HPA控制器周期性地监测目标Pod的资源性能指标，并与HPA资源对象中的扩缩容条件进行对比，在满足条件时对Pod副本数量进行调整。</p>
<ul>
<li>HPA原理</li>
</ul>
<p>Kubernetes中的某个Metrics Server（Heapster或自定义Metrics Server）持续采集所有Pod副本的指标数据。HPA控制器通过Metrics Server的API（Heapster的API或聚合API）获取这些数据，基于用户定义的扩缩容规则进行计算，得到目标Pod副本数量。</p>
<p>当目标Pod副本数量与当前副本数量不同时，HPA控制器就向Pod的副本控制器（Deployment、RC或ReplicaSet）发起scale操作，调整Pod的副本数量，完成扩缩容操作。</p>
<h3 id="简述Kubernetes-Service类型？">0.0.30. 简述Kubernetes Service类型？</h3><p>通过创建Service，可以为一组具有相同功能的容器应用提供一个统一的入口地址，并且将请求负载分发到后端的各个容器应用上。其主要类型有：</p>
<ul>
<li><p>ClusterIP：虚拟的服务IP地址，该地址用于Kubernetes集群内部的Pod访问，在Node上kube-proxy通过设置的iptables规则进行转发；</p>
</li>
<li><p>NodePort：使用宿主机的端口，使能够访问各Node的外部客户端通过Node的IP地址和端口号就能访问服务；</p>
</li>
<li><p>LoadBalancer：使用外接负载均衡器完成到服务的负载分发，需要在spec.status.loadBalancer字段指定外部负载均衡器的IP地址，通常用于公有云。</p>
</li>
</ul>
<h3 id="简述Kubernetes-Service分发后端的策略？">0.0.31. 简述Kubernetes Service分发后端的策略？</h3><p>Service负载分发的策略有：RoundRobin和SessionAffinity</p>
<ul>
<li>RoundRobin：默认为轮询模式，即轮询将请求转发到后端的各个Pod上。</li>
<li>SessionAffinity：基于客户端IP地址进行会话保持的模式，即第1次将某个客户端发起的请求转发到后端的某个Pod上，之后从相同的客户端发起的请求都将被转发到后端相同的Pod上。</li>
</ul>
<h3 id="简述Kubernetes-Headless-Service？">0.0.32. 简述Kubernetes Headless Service？</h3><p>在某些应用场景中，若需要人为指定负载均衡器，不使用Service提供的默认负载均衡的功能，或者应用程序希望知道属于同组服务的其他实例。Kubernetes提供了Headless Service来实现这种功能，即不为Service设置ClusterIP（入口IP地址），仅通过Label Selector将后端的Pod列表返回给调用的客户端。</p>
<h3 id="简述Kubernetes外部如何访问集群内的服务？">0.0.33. 简述Kubernetes外部如何访问集群内的服务？</h3><p>对于Kubernetes，集群外的客户端默认情况，无法通过Pod的IP地址或者Service的虚拟IP地址:虚拟端口号进行访问。通常可以通过以下方式进行访问Kubernetes集群内的服务：</p>
<ul>
<li><p>映射Pod到物理机：将Pod端口号映射到宿主机，即在Pod中采用hostPort方式，以使客户端应用能够通过物理机访问容器应用。</p>
</li>
<li><p>映射Service到物理机：将Service端口号映射到宿主机，即在Service中采用nodePort方式，以使客户端应用能够通过物理机访问容器应用。</p>
</li>
<li><p>映射Sercie到LoadBalancer：通过设置LoadBalancer映射到云服务商提供的LoadBalancer地址。这种用法仅用于在公有云服务提供商的云平台上设置Service的场景。</p>
</li>
</ul>
<h3 id="简述Kubernetes-ingress？">0.0.34. 简述Kubernetes ingress？</h3><p>Kubernetes的Ingress资源对象，用于将不同URL的访问请求转发到后端不同的Service，以实现HTTP层的业务路由机制。</p>
<p>Kubernetes使用了Ingress策略和Ingress Controller，两者结合并实现了一个完整的Ingress负载均衡器。使用Ingress进行负载分发时，Ingress Controller基于Ingress规则将客户端请求直接转发到Service对应的后端Endpoint（Pod）上，从而跳过kube-proxy的转发功能，kube-proxy不再起作用，全过程为：ingress controller + ingress 规则 —-&gt; services。</p>
<p>同时当Ingress Controller提供的是对外服务，则实际上实现的是边缘路由器的功能。</p>
<h3 id="简述Kubernetes镜像的下载策略？">0.0.35. 简述Kubernetes镜像的下载策略？</h3><p>K8s的镜像下载策略有三种：Always、Never、IFNotPresent。</p>
<ul>
<li><p>Always：镜像标签为latest时，总是从指定的仓库中获取镜像。</p>
</li>
<li><p>Never：禁止从仓库中下载镜像，也就是说只能使用本地镜像。</p>
</li>
<li><p>IfNotPresent：仅当本地没有对应镜像时，才从目标仓库中下载。默认的镜像下载策略是：当镜像标签是latest时，默认策略是Always；当镜像标签是自定义时（也就是标签不是latest），那么默认策略是IfNotPresent。</p>
</li>
</ul>
<h3 id="简述Kubernetes的负载均衡器？">0.0.36. 简述Kubernetes的负载均衡器？</h3><p>负载均衡器是暴露服务的最常见和标准方式之一。</p>
<p>根据工作环境使用两种类型的负载均衡器，即内部负载均衡器或外部负载均衡器。内部负载均衡器自动平衡负载并使用所需配置分配容器，而外部负载均衡器将流量从外部负载引导至后端容器。</p>
<h3 id="简述Kubernetes各模块如何与API-Server通信？">0.0.37. 简述Kubernetes各模块如何与API Server通信？</h3><p>Kubernetes API Server作为集群的核心，负责集群各功能模块之间的通信。集群内的各个功能模块通过API Server将信息存入etcd，当需要获取和操作这些数据时，则通过API Server提供的REST接口（用GET、LIST或WATCH方法）来实现，从而实现各模块之间的信息交互。</p>
<p>如kubelet进程与API Server的交互：每个Node上的kubelet每隔一个时间周期，就会调用一次API Server的REST接口报告自身状态，API Server在接收到这些信息后，会将节点状态信息更新到etcd中。</p>
<p>如kube-controller-manager进程与API Server的交互：kube-controller-manager中的Node Controller模块通过API Server提供的Watch接口实时监控Node的信息，并做相应处理。</p>
<p>如kube-scheduler进程与API Server的交互：Scheduler通过API Server的Watch接口监听到新建Pod副本的信息后，会检索所有符合该Pod要求的Node列表，开始执行Pod调度逻辑，在调度成功后将Pod绑定到目标节点上。</p>
<h3 id="简述Kubernetes-Scheduler作用及实现原理？">0.0.38. 简述Kubernetes Scheduler作用及实现原理？</h3><p>Kubernetes Scheduler是负责Pod调度的重要功能模块，Kubernetes Scheduler在整个系统中承担了“承上启下”的重要功能，“承上”是指它负责接收Controller Manager创建的新Pod，为其调度至目标Node；“启下”是指调度完成后，目标Node上的kubelet服务进程接管后继工作，负责Pod接下来生命周期。</p>
<p>Kubernetes Scheduler的作用是将待调度的Pod（API新创建的Pod、Controller Manager为补足副本而创建的Pod等）按照特定的调度算法和调度策略绑定（Binding）到集群中某个合适的Node上，并将绑定信息写入etcd中。</p>
<p>在整个调度过程中涉及三个对象，分别是待调度Pod列表、可用Node列表，以及调度算法和策略。</p>
<p>Kubernetes Scheduler通过调度算法调度为待调度Pod列表中的每个Pod从Node列表中选择一个最适合的Node来实现Pod的调度。随后，目标节点上的kubelet通过API Server监听到Kubernetes Scheduler产生的Pod绑定事件，然后获取对应的Pod清单，下载Image镜像并启动容器。</p>
<h3 id="简述Kubernetes-Scheduler使用哪两种算法将Pod绑定到worker节点？">0.0.39. 简述Kubernetes Scheduler使用哪两种算法将Pod绑定到worker节点？</h3><p>Kubernetes Scheduler根据如下两种调度算法将 Pod 绑定到最合适的工作节点：</p>
<ul>
<li>预选（Predicates）：输入是所有节点，输出是满足预选条件的节点。kube-scheduler根据预选策略过滤掉不满足策略的Nodes。如果某节点的资源不足或者不满足预选策略的条件则无法通过预选。如“Node的label必须与Pod的Selector一致”。</li>
<li>优选（Priorities）：输入是预选阶段筛选出的节点，优选会根据优先策略为通过预选的Nodes进行打分排名，选择得分最高的Node。例如，资源越富裕、负载越小的Node可能具有越高的排名。</li>
</ul>
<h3 id="简述Kubernetes-kubelet的作用？">0.0.40. 简述Kubernetes kubelet的作用？</h3><p>在Kubernetes集群中，在每个Node（又称Worker）上都会启动一个kubelet服务进程。该进程用于处理Master下发到本节点的任务，管理Pod及Pod中的容器。每个kubelet进程都会在API Server上注册节点自身的信息，定期向Master汇报节点资源的使用情况，并通过cAdvisor监控容器和节点资源。</p>
<h3 id="简述Kubernetes-kubelet监控Worker节点资源是使用什么组件来实现的？">0.0.41. 简述Kubernetes kubelet监控Worker节点资源是使用什么组件来实现的？</h3><p>kubelet使用cAdvisor对worker节点资源进行监控。在 Kubernetes 系统中，cAdvisor 已被默认集成到 kubelet 组件内，当 kubelet 服务启动时，它会自动启动 cAdvisor 服务，然后 cAdvisor 会实时采集所在节点的性能指标及在节点上运行的容器的性能指标。</p>
<h3 id="简述Kubernetes如何保证集群的安全性？">0.0.42. 简述Kubernetes如何保证集群的安全性？</h3><p>Kubernetes通过一系列机制来实现集群的安全控制，主要有如下不同的维度：</p>
<ul>
<li><p>基础设施方面：保证容器与其所在宿主机的隔离；</p>
</li>
<li><p>权限方面：</p>
</li>
<li><ul>
<li>最小权限原则：合理限制所有组件的权限，确保组件只执行它被授权的行为，通过限制单个组件的能力来限制它的权限范围。</li>
<li>用户权限：划分普通用户和管理员的角色。</li>
</ul>
</li>
<li><p>集群方面：</p>
</li>
<li><ul>
<li>API Server的认证授权：Kubernetes集群中所有资源的访问和变更都是通过Kubernetes API Server来实现的，因此需要建议采用更安全的HTTPS或Token来识别和认证客户端身份（Authentication），以及随后访问权限的授权（Authorization）环节。</li>
<li>API Server的授权管理：通过授权策略来决定一个API调用是否合法。对合法用户进行授权并且随后在用户访问时进行鉴权，建议采用更安全的RBAC方式来提升集群安全授权。</li>
</ul>
</li>
<li><ul>
<li>敏感数据引入Secret机制：对于集群敏感数据建议使用Secret方式进行保护。</li>
<li>AdmissionControl（准入机制）：对kubernetes api的请求过程中，顺序为：先经过认证 &amp; 授权，然后执行准入操作，最后对目标对象进行操作。</li>
</ul>
</li>
</ul>
<h3 id="简述Kubernetes准入机制？">0.0.43. 简述Kubernetes准入机制？</h3><p>在对集群进行请求时，每个准入控制代码都按照一定顺序执行。如果有一个准入控制拒绝了此次请求，那么整个请求的结果将会立即返回，并提示用户相应的error信息。</p>
<p>准入控制（AdmissionControl）准入控制本质上为一段准入代码，在对kubernetes api的请求过程中，顺序为：先经过认证 &amp; 授权，然后执行准入操作，最后对目标对象进行操作。常用组件（控制代码）如下：</p>
<ul>
<li><p>AlwaysAdmit：允许所有请求</p>
</li>
<li><p>AlwaysDeny：禁止所有请求，多用于测试环境。</p>
</li>
<li><p>ServiceAccount：它将serviceAccounts实现了自动化，它会辅助serviceAccount做一些事情，比如如果pod没有serviceAccount属性，它会自动添加一个default，并确保pod的serviceAccount始终存在。</p>
</li>
<li><p>LimitRanger：观察所有的请求，确保没有违反已经定义好的约束条件，这些条件定义在namespace中LimitRange对象中。</p>
</li>
<li><p>NamespaceExists：观察所有的请求，如果请求尝试创建一个不存在的namespace，则这个请求被拒绝。</p>
</li>
</ul>
<h3 id="简述Kubernetes-RBAC及其特点（优势）？">0.0.44. 简述Kubernetes RBAC及其特点（优势）？</h3><p>RBAC是基于角色的访问控制，是一种基于个人用户的角色来管理对计算机或网络资源的访问的方法。</p>
<p>相对于其他授权模式，RBAC具有如下优势：</p>
<ul>
<li><p>对集群中的资源和非资源权限均有完整的覆盖。</p>
</li>
<li><p>整个RBAC完全由几个API对象完成， 同其他API对象一样， 可以用kubectl或API进行操作。</p>
</li>
<li><p>可以在运行时进行调整，无须重新启动API Server。</p>
</li>
</ul>
<h3 id="简述Kubernetes-Secret作用？">0.0.45. 简述Kubernetes Secret作用？</h3><p>Secret对象，主要作用是保管私密数据，比如密码、OAuth Tokens、SSH Keys等信息。将这些私密信息放在Secret对象中比直接放在Pod或Docker Image中更安全，也更便于使用和分发。</p>
<h3 id="简述Kubernetes-Secret有哪些使用方式？">0.0.46. 简述Kubernetes Secret有哪些使用方式？</h3><p>创建完secret之后，可通过如下三种方式使用：</p>
<ul>
<li><p>在创建Pod时，通过为Pod指定Service Account来自动使用该Secret。</p>
</li>
<li><p>通过挂载该Secret到Pod来使用它。</p>
</li>
<li><p>在Docker镜像下载时使用，通过指定Pod的spc.ImagePullSecrets来引用它。</p>
</li>
</ul>
<h3 id="简述Kubernetes-PodSecurityPolicy机制？">0.0.47. 简述Kubernetes PodSecurityPolicy机制？</h3><p>Kubernetes PodSecurityPolicy是为了更精细地控制Pod对资源的使用方式以及提升安全策略。在开启PodSecurityPolicy准入控制器后，Kubernetes默认不允许创建任何Pod，需要创建PodSecurityPolicy策略和相应的RBAC授权策略（Authorizing Policies），Pod才能创建成功。</p>
<h3 id="简述Kubernetes-PodSecurityPolicy机制能实现哪些安全策略？">0.0.48. 简述Kubernetes PodSecurityPolicy机制能实现哪些安全策略？</h3><p>在PodSecurityPolicy对象中可以设置不同字段来控制Pod运行时的各种安全策略，常见的有：</p>
<ul>
<li><p>特权模式：privileged是否允许Pod以特权模式运行。</p>
</li>
<li><p>宿主机资源：控制Pod对宿主机资源的控制，如hostPID：是否允许Pod共享宿主机的进程空间。</p>
</li>
<li><p>用户和组：设置运行容器的用户ID（范围）或组（范围）。</p>
</li>
<li><p>提升权限：AllowPrivilegeEscalation：设置容器内的子进程是否可以提升权限，通常在设置非root用户（MustRunAsNonRoot）时进行设置。</p>
</li>
<li><p>SELinux：进行SELinux的相关配置。</p>
</li>
</ul>
<h3 id="简述Kubernetes网络模型？">0.0.49. 简述Kubernetes网络模型？</h3><p>Kubernetes网络模型中每个Pod都拥有一个独立的IP地址，并假定所有Pod都在一个可以直接连通的、扁平的网络空间中。所以不管它们是否运行在同一个Node（宿主机）中，都要求它们可以直接通过对方的IP进行访问。设计这个原则的原因是，用户不需要额外考虑如何建立Pod之间的连接，也不需要考虑如何将容器端口映射到主机端口等问题。</p>
<p>同时为每个Pod都设置一个IP地址的模型使得同一个Pod内的不同容器会共享同一个网络命名空间，也就是同一个Linux网络协议栈。这就意味着同一个Pod内的容器可以通过localhost来连接对方的端口。</p>
<p>在Kubernetes的集群里，IP是以Pod为单位进行分配的。一个Pod内部的所有容器共享一个网络堆栈（相当于一个网络命名空间，它们的IP地址、网络设备、配置等都是共享的）。</p>
<h3 id="简述Kubernetes-CNI模型？">0.0.50. 简述Kubernetes CNI模型？</h3><p>CNI提供了一种应用容器的插件化网络解决方案，定义对容器网络进行操作和配置的规范，通过插件的形式对CNI接口进行实现。CNI仅关注在创建容器时分配网络资源，和在销毁容器时删除网络资源。在CNI模型中只涉及两个概念：容器和网络。</p>
<ul>
<li>容器（Container）：是拥有独立Linux网络命名空间的环境，例如使用Docker或rkt创建的容器。容器需要拥有自己的Linux网络命名空间，这是加入网络的必要条件。</li>
<li>网络（Network）：表示可以互连的一组实体，这些实体拥有各自独立、唯一的IP地址，可以是容器、物理机或者其他网络设备（比如路由器）等。</li>
</ul>
<p>对容器网络的设置和操作都通过插件（Plugin）进行具体实现，CNI插件包括两种类型：CNI Plugin和IPAM（IP Address  Management）Plugin。CNI Plugin负责为容器配置网络资源，IPAM Plugin负责对容器的IP地址进行分配和管理。IPAM Plugin作为CNI Plugin的一部分，与CNI Plugin协同工作。</p>
<h3 id="简述Kubernetes网络策略？">0.0.51. 简述Kubernetes网络策略？</h3><p>为实现细粒度的容器间网络访问隔离策略，Kubernetes引入Network Policy。</p>
<p>Network Policy的主要功能是对Pod间的网络通信进行限制和准入控制，设置允许访问或禁止访问的客户端Pod列表。Network Policy定义网络策略，配合策略控制器（Policy Controller）进行策略的实现。</p>
<h3 id="简述Kubernetes网络策略原理？">0.0.52. 简述Kubernetes网络策略原理？</h3><p>Network Policy的工作原理主要为：policy controller需要实现一个API Listener，监听用户设置的Network Policy定义，并将网络访问规则通过各Node的Agent进行实际设置（Agent则需要通过CNI网络插件实现）。</p>
<h3 id="简述Kubernetes中flannel的作用？">0.0.53. 简述Kubernetes中flannel的作用？</h3><p>Flannel可以用于Kubernetes底层网络的实现，主要作用有：</p>
<ul>
<li>它能协助Kubernetes，给每一个Node上的Docker容器都分配互相不冲突的IP地址。</li>
<li>它能在这些IP地址之间建立一个覆盖网络（Overlay Network），通过这个覆盖网络，将数据包原封不动地传递到目标容器内。</li>
</ul>
<h3 id="简述Kubernetes-Calico网络组件实现原理？">0.0.54. 简述Kubernetes Calico网络组件实现原理？</h3><p>Calico是一个基于BGP的纯三层的网络方案，与OpenStack、Kubernetes、AWS、GCE等云平台都能够良好地集成。</p>
<p>Calico在每个计算节点都利用Linux Kernel实现了一个高效的vRouter来负责数据转发。每个vRouter都通过BGP协议把在本节点上运行的容器的路由信息向整个Calico网络广播，并自动设置到达其他节点的路由转发规则。</p>
<p>Calico保证所有容器之间的数据流量都是通过IP路由的方式完成互联互通的。Calico节点组网时可以直接利用数据中心的网络结构（L2或者L3），不需要额外的NAT、隧道或者Overlay Network，没有额外的封包解包，能够节约CPU运算，提高网络效率。</p>
<h3 id="简述Kubernetes共享存储的作用？">0.0.55. 简述Kubernetes共享存储的作用？</h3><p>Kubernetes对于有状态的容器应用或者对数据需要持久化的应用，因此需要更加可靠的存储来保存应用产生的重要数据，以便容器应用在重建之后仍然可以使用之前的数据。因此需要使用共享存储。</p>
<h3 id="简述Kubernetes数据持久化的方式有哪些？">0.0.56. 简述Kubernetes数据持久化的方式有哪些？</h3><p>Kubernetes通过数据持久化来持久化保存重要数据，常见的方式有：</p>
<ul>
<li><p>EmptyDir（空目录）：没有指定要挂载宿主机上的某个目录，直接由Pod内保部映射到宿主机上。类似于docker中的manager volume。</p>
</li>
<li><p>场景：</p>
</li>
<li><ul>
<li>只需要临时将数据保存在磁盘上，比如在合并/排序算法中；</li>
<li>作为两个容器的共享存储。</li>
</ul>
</li>
<li><p>特性：</p>
</li>
<li><ul>
<li>同个pod里面的不同容器，共享同一个持久化目录，当pod节点删除时，volume的数据也会被删除。</li>
<li>emptyDir的数据持久化的生命周期和使用的pod一致，一般是作为临时存储使用。</li>
</ul>
</li>
<li><p>Hostpath：将宿主机上已存在的目录或文件挂载到容器内部。类似于docker中的bind mount挂载方式。</p>
</li>
<li><ul>
<li>特性：增加了pod与节点之间的耦合。</li>
</ul>
</li>
</ul>
<p>PersistentVolume（简称PV）：如基于NFS服务的PV，也可以基于GFS的PV。它的作用是统一数据持久化目录，方便管理。</p>
<h3 id="简述Kubernetes-PV和PVC？">0.0.57. 简述Kubernetes PV和PVC？</h3><p>PV是对底层网络共享存储的抽象，将共享存储定义为一种“资源”。</p>
<p>PVC则是用户对存储资源的一个“申请”。</p>
<h3 id="简述Kubernetes-PV生命周期内的阶段？">0.0.58. 简述Kubernetes PV生命周期内的阶段？</h3><p>某个PV在生命周期中可能处于以下4个阶段（Phaes）之一。</p>
<ul>
<li><p>Available：可用状态，还未与某个PVC绑定。</p>
</li>
<li><p>Bound：已与某个PVC绑定。</p>
</li>
<li><p>Released：绑定的PVC已经删除，资源已释放，但没有被集群回收。</p>
</li>
<li><p>Failed：自动资源回收失败。</p>
</li>
</ul>
<h3 id="简述Kubernetes所支持的存储供应模式？">0.0.59. 简述Kubernetes所支持的存储供应模式？</h3><p>Kubernetes支持两种资源的存储供应模式：静态模式（Static）和动态模式（Dynamic）。</p>
<ul>
<li>静态模式：集群管理员手工创建许多PV，在定义PV时需要将后端存储的特性进行设置。</li>
<li>动态模式：集群管理员无须手工创建PV，而是通过StorageClass的设置对后端存储进行描述，标记为某种类型。此时要求PVC对存储的类型进行声明，系统将自动完成PV的创建及与PVC的绑定。</li>
</ul>
<h3 id="简述Kubernetes-CSI模型？">0.0.60. 简述Kubernetes CSI模型？</h3><p>Kubernetes CSI是Kubernetes推出与容器对接的存储接口标准，存储提供方只需要基于标准接口进行存储插件的实现，就能使用Kubernetes的原生存储机制为容器提供存储服务。CSI使得存储提供方的代码能和Kubernetes代码彻底解耦，部署也与Kubernetes核心组件分离，显然，存储插件的开发由提供方自行维护，就能为Kubernetes用户提供更多的存储功能，也更加安全可靠。</p>
<p>CSI包括CSI Controller和CSI Node：</p>
<ul>
<li>CSI Controller的主要功能是提供存储服务视角对存储资源和存储卷进行管理和操作。</li>
<li>CSI Node的主要功能是对主机（Node）上的Volume进行管理和操作。</li>
</ul>
<h3 id="简述Kubernetes-Worker节点加入集群的过程？">0.0.61. 简述Kubernetes Worker节点加入集群的过程？</h3><p>通常需要对Worker节点进行扩容，从而将应用系统进行水平扩展。主要过程如下：</p>
<ul>
<li><p>1、在该Node上安装Docker、kubelet和kube-proxy服务；</p>
</li>
<li><p>2、然后配置kubelet和kubeproxy的启动参数，将Master URL指定为当前Kubernetes集群Master的地址，最后启动这些服务；</p>
</li>
<li><p>3、通过kubelet默认的自动注册机制，新的Worker将会自动加入现有的Kubernetes集群中；</p>
</li>
<li><p>4、Kubernetes Master在接受了新Worker的注册之后，会自动将其纳入当前集群的调度范围。</p>
</li>
</ul>
<h3 id="简述Kubernetes-Pod如何实现对节点的资源控制？">0.0.62. 简述Kubernetes Pod如何实现对节点的资源控制？</h3><p>Kubernetes集群里的节点提供的资源主要是计算资源，计算资源是可计量的能被申请、分配和使用的基础资源。当前Kubernetes集群中的计算资源主要包括CPU、GPU及Memory。CPU与Memory是被Pod使用的，因此在配置Pod时可以通过参数CPU Request及Memory Request为其中的每个容器指定所需使用的CPU与Memory量，Kubernetes会根据Request的值去查找有足够资源的Node来调度此Pod。</p>
<p>通常，一个程序所使用的CPU与Memory是一个动态的量，确切地说，是一个范围，跟它的负载密切相关：负载增加时，CPU和Memory的使用量也会增加。</p>
<h3 id="简述Kubernetes-Requests和Limits如何影响Pod的调度？">0.0.63. 简述Kubernetes Requests和Limits如何影响Pod的调度？</h3><p>当一个Pod创建成功时，Kubernetes调度器（Scheduler）会为该Pod选择一个节点来执行。对于每种计算资源（CPU和Memory）而言，每个节点都有一个能用于运行Pod的最大容量值。调度器在调度时，首先要确保调度后该节点上所有Pod的CPU和内存的Requests总和，不超过该节点能提供给Pod使用的CPU和Memory的最大容量值。</p>
<h3 id="简述Kubernetes-Metric-Service？">0.0.64. 简述Kubernetes Metric Service？</h3><p>在Kubernetes从1.10版本后采用Metrics Server作为默认的性能数据采集和监控，主要用于提供核心指标（Core Metrics），包括Node、Pod的CPU和内存使用指标。</p>
<p>对其他自定义指标（Custom Metrics）的监控则由Prometheus等组件来完成。</p>
<h3 id="简述Kubernetes中，如何使用EFK实现日志的统一管理？">0.0.65. 简述Kubernetes中，如何使用EFK实现日志的统一管理？</h3><p>在Kubernetes集群环境中，通常一个完整的应用或服务涉及组件过多，建议对日志系统进行集中化管理，通常采用EFK实现。</p>
<p>EFK是 Elasticsearch、Fluentd 和 Kibana 的组合，其各组件功能如下：</p>
<ul>
<li><p>Elasticsearch：是一个搜索引擎，负责存储日志并提供查询接口；</p>
</li>
<li><p>Fluentd：负责从 Kubernetes 搜集日志，每个node节点上面的fluentd监控并收集该节点上面的系统日志，并将处理过后的日志信息发送给Elasticsearch；</p>
</li>
<li><p>Kibana：提供了一个 Web GUI，用户可以浏览和搜索存储在 Elasticsearch 中的日志。</p>
</li>
</ul>
<p>通过在每台node上部署一个以DaemonSet方式运行的fluentd来收集每台node上的日志。Fluentd将docker日志目录/var/lib/docker/containers和/var/log目录挂载到Pod中，然后Pod会在node节点的/var/log/pods目录中创建新的目录，可以区别不同的容器日志输出，该目录下有一个日志文件链接到/var/lib/docker/contianers目录下的容器日志输出。</p>
<h3 id="简述Kubernetes如何进行优雅的节点关机维护？">0.0.66. 简述Kubernetes如何进行优雅的节点关机维护？</h3><p>由于Kubernetes节点运行大量Pod，因此在进行关机维护之前，建议先使用kubectl drain将该节点的Pod进行驱逐，然后进行关机维护。</p>
<h3 id="简述Kubernetes集群联邦？">0.0.67. 简述Kubernetes集群联邦？</h3><p>Kubernetes集群联邦可以将多个Kubernetes集群作为一个集群进行管理。因此，可以在一个数据中心/云中创建多个Kubernetes集群，并使用集群联邦在一个地方控制/管理所有集群。</p>
<h3 id="简述Helm及其优势？">0.0.68. 简述Helm及其优势？</h3><p>Helm 是 Kubernetes 的软件包管理工具。类似 Ubuntu 中使用的apt、Centos中使用的yum 或者Python中的 pip 一样。</p>
<p>Helm能够将一组K8S资源打包统一管理, 是查找、共享和使用为Kubernetes构建的软件的最佳方式。</p>
<p>Helm中通常每个包称为一个Chart，一个Chart是一个目录（一般情况下会将目录进行打包压缩，形成name-version.tgz格式的单一文件，方便传输和存储）。</p>
<ul>
<li>Helm优势</li>
</ul>
<p>在 Kubernetes中部署一个可以使用的应用，需要涉及到很多的 Kubernetes 资源的共同协作。使用helm则具有如下优势：</p>
<ul>
<li><p>统一管理、配置和更新这些分散的 k8s 的应用资源文件；</p>
</li>
<li><p>分发和复用一套应用模板；</p>
</li>
<li><p>将应用的一系列资源当做一个软件包管理。</p>
</li>
<li><p>对于应用发布者而言，可以通过 Helm 打包应用、管理应用依赖关系、管理应用版本并发布应用到软件仓库。对于使用者而言，使用 Helm 后不用需要编写复杂的应用部署文件，可以以简单的方式在 Kubernetes 上查找、安装、升级、回滚、卸载应用程序。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
</search>
